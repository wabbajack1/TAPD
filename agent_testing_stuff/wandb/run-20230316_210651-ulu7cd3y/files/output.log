Max Steps:   0%|          | 0/1000000 [00:00<?, ?steps/s]/tmp/ipykernel_59759/2492226513.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  action_pred = F.softmax(action_pred_logit)
Max Steps:   0%|          | 259/1000000 [00:01<1:04:44, 257.35steps/s]
Run model on cuda
==================TRAIN TASK 0======================
====> Progress train task 0
tensor([[[0.0296],
         [0.0295],
         [0.0285],
         [0.0289],
         [0.0284],
         [0.0284],
         [0.0284],
         [0.0283],
         [0.0284],
         [0.0284],
         [0.0283],
         [0.0284],
         [0.0283],
         [0.0284],
         [0.0284],
         [0.0284],
         [0.0283],
         [0.0283],
         [0.0283],
         [0.0286],
         [0.0280],
         [0.0284],
         [0.0284],
         [0.0282],
         [0.0284],
         [0.0284],
         [0.0282],
         [0.0282],
         [0.0281],
         [0.0281],
         [0.0282],
         [0.0284],
         [0.0282],
         [0.0283],
         [0.0283],
         [0.0284],
         [0.0284],
         [0.0283],
         [0.0283],
         [0.0284],
         [0.0280],
         [0.0283],
         [0.0284],
         [0.0285],
         [0.0284],
         [0.0284],
         [0.0285],
         [0.0285],
         [0.0283],
         [0.0282],
         [0.0284],
         [0.0285],
         [0.0283],
         [0.0282],
         [0.0280],
         [0.0284],
         [0.0282],
         [0.0283],
         [0.0284],
         [0.0285],
         [0.0282],
         [0.0284],
         [0.0284],
         [0.0285],
         [0.0284],
         [0.0283],
         [0.0284],
         [0.0284],
         [0.0283],
         [0.0282],
         [0.0282],
         [0.0284],
         [0.0283],
         [0.0284],
         [0.0283],
         [0.0283],
         [0.0284],
         [0.0285],
         [0.0284],
         [0.0284],
         [0.0283],
         [0.0285],
         [0.0287],
         [0.0284],
         [0.0284],
         [0.0285],
         [0.0282],
         [0.0284],
         [0.0282],
         [0.0283],
         [0.0284],
         [0.0286],
         [0.0283],
         [0.0282],
         [0.0283],
         [0.0283],
         [0.0283],
         [0.0283],
         [0.0283],
         [0.0284],
         [0.0283],
         [0.0284],
         [0.0284],
         [0.0283],
         [0.0284],
         [0.0283],
         [0.0283],
         [0.0284],
         [0.0283],
         [0.0284],
         [0.0283],
         [0.0282],
         [0.0283],
         [0.0283],
         [0.0283],
         [0.0283],
         [0.0285],
         [0.0288],
         [0.0285],
         [0.0285],
         [0.0285],
         [0.0282],
         [0.0283],
         [0.0282],
         [0.0283],
         [0.0284],
         [0.0286],
         [0.0283],
         [0.0282],
         [0.0282]]], device='cuda:0', grad_fn=<StackBackward0>)
actor loss: -1.9873932600021362 - critic loss 0.5168532133102417
tensor([[[0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0114],
         [0.0113],
         [0.0114],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0112],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0114],
         [0.0118],
         [0.0114],
         [0.0114],
         [0.0114],
         [0.0112],
         [0.0113],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0115],
         [0.0112],
         [0.0112],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0114],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0112],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0112],
         [0.0114],
         [0.0117],
         [0.0114],
         [0.0114],
         [0.0114],
         [0.0111],
         [0.0113],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0115],
         [0.0112],
         [0.0111],
         [0.0111],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0114],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0112],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0115],
         [0.0118],
         [0.0114],
         [0.0114],
         [0.0114],
         [0.0112],
         [0.0113],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0116],
         [0.0112],
         [0.0112],
         [0.0112],
         [0.0112],
         [0.0112],
         [0.0113],
         [0.0113],
         [0.0114],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0113],
         [0.0114],
         [0.0114],
         [0.0113],
         [0.0112],
         [0.0112],
         [0.0113],
         [0.0112],
         [0.0113],
         [0.0112],
         [0.0114],
         [0.0118],
         [0.0115],
