{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wabbajack1/agnostic_rl/blob/main/P%26C_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W2A-SymhJs7v",
      "metadata": {
        "id": "W2A-SymhJs7v"
      },
      "source": [
        "#Init Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "OmfCidyHFRRr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmfCidyHFRRr",
        "outputId": "b82552a8-ddbb-437b-cd40-9b92a405609b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "username = \"wabbajack1\"\n",
        "repository = \"agnostic_rl\"\n",
        "git_token = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c2sBV7xRJ-eC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "c2sBV7xRJ-eC",
        "outputId": "428ad0cb-bd83-4eb6-ebe6-996202a68f6e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!cd /content/drive/MyDrive/Github\\n!git clone https://{git_token}@github.com/{username}/{repository}\\n!cd {repository}\\n!ls -a\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "!cd /content/drive/MyDrive/Github\n",
        "!git clone https://{git_token}@github.com/{username}/{repository}\n",
        "!cd {repository}\n",
        "!ls -a\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "VfTXwcwqmiHV",
      "metadata": {
        "id": "VfTXwcwqmiHV"
      },
      "outputs": [],
      "source": [
        "!cd /content/drive/MyDrive/Github/agnostic_rl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "TkJH6a5JRPCP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkJH6a5JRPCP",
        "outputId": "70f51586-e9a4-47af-897d-cfc7acb7293f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gBQStAtnJ0Ww",
      "metadata": {
        "id": "gBQStAtnJ0Ww"
      },
      "source": [
        "# Start Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "y6n-XG8HGJKF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6n-XG8HGJKF",
        "outputId": "d9405e0d-0abc-4fd9-906a-c8f183df124c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python38.zip',\n",
              " '/usr/lib/python3.8',\n",
              " '/usr/lib/python3.8/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.8/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.8/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/drive/MyDrive/Github/agnostic_rl/agent/']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(\"/content/drive/MyDrive/Github/agnostic_rl/agent/\")\n",
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c167d31a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c167d31a",
        "outputId": "47b528e7-4dc3-41f5-e7f2-97a0f42f0e91",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kidimerek/Desktop/agnostic_rl-main/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/kidimerek/Desktop/agnostic_rl-main/lib/python3.9/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "from ProgressCompress import ActorCritic\n",
        "from ProgNetAbstract import ProgNet\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from EWC import EWC, EWC_online\n",
        "import random\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac80f85",
      "metadata": {
        "id": "4ac80f85"
      },
      "source": [
        "# Random Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a95fdddf",
      "metadata": {
        "id": "a95fdddf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 18]), torch.Size([32, 1]))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ProgNetAbstract import ProgColumnGenerator\n",
        "from blocks import ProgDenseBlock, ProgConv2DBlock, MultiProgDenseBlock\n",
        "from ProgNetAbstract import ProgNet\n",
        "from ProgNetAbstract import ProgColumn\n",
        "import torch\n",
        "import gym\n",
        "from EWC import EWC\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "import torch.nn as nn\n",
        "\n",
        "class ActorCritic(ProgColumnGenerator):\n",
        "    def __init__(self):\n",
        "        self.ids = 0\n",
        "\n",
        "    \"\"\"def generateColumn(self, parentCols, msg = None):\n",
        "        b1 = ProgDenseBlock(28*28, 400, 0)\n",
        "        b2 = ProgDenseBlock(400, 400, len(parentCols))\n",
        "        b3 = ProgDenseBlock(400, 10, len(parentCols), activation=None)\n",
        "        column = ProgColumn(self.__genID(), [b1, b2, b3], parentCols = parentCols)\n",
        "        return column\"\"\"\n",
        "        \n",
        "    def generateColumn(self, parentCols, msg = None):\n",
        "        params_b1 = {\"stride\": 4, \"padding\":0}\n",
        "        params_b2 = {\"stride\": 2, \"padding\":0}\n",
        "        params_b3 = {\"stride\": 1, \"padding\":0}\n",
        "        \n",
        "        b1 = ProgConv2DBlock(4, 32, kernelSize=8, numLaterals=0, layerArgs=params_b1)\n",
        "        b2 = ProgConv2DBlock(32, 64, kernelSize=4, numLaterals=len(parentCols), layerArgs=params_b2)\n",
        "        b3 = ProgConv2DBlock(64, 64, kernelSize=3, numLaterals=len(parentCols), layerArgs=params_b3)\n",
        "        b4 = ProgDenseBlock(24576, 100, numLaterals=len(parentCols), after_conv=True)\n",
        "        b5 = MultiProgDenseBlock(100, 18, numLaterals=len(parentCols) , activation=None, after_conv=False)\n",
        "        column = ProgColumn(self.__genID(), [b1, b2, b3, b4, b5], parentCols = parentCols)\n",
        "\n",
        "        \"\"\"b1 = ProgDenseBlock(28*28, 1000, numLaterals=0 , activation=None, after_conv=True)\n",
        "        b4 = MultiProgDenseBlock(1000, 18, numLaterals=len(parentCols), activation=None, after_conv=False)\n",
        "        column = ProgColumn(self.__genID(), [b1, b4], parentCols = parentCols)\"\"\"\n",
        "        \n",
        "        return column\n",
        "\n",
        "    def __genID(self):\n",
        "        ids = self.ids\n",
        "        self.ids += 1\n",
        "        return ids\n",
        "\n",
        "# define the model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 400)\n",
        "        self.fc2 = nn.Linear(400, 400)\n",
        "        self.fc3 = nn.Linear(400, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "x = torch.randn(32, 4, 128, 128)\n",
        "net = ProgNet(colGen = ActorCritic())\n",
        "\n",
        "kb_column = net.addColumn() # net_0\n",
        "active_column = net.addColumn() # net_1\n",
        "\n",
        "m = Net()\n",
        "o1, o2 = net(kb_column, x)\n",
        "o1_, o2_ = net(active_column, x)\n",
        "o1.size(), o2.size()#, o1_.size(), o2_.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1372e481",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64\n",
            "torch.Size([100, 64, 12, 12])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (76800x12 and 64x18)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m input_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m100\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39m# pass the input tensor through the network\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m output_tensor \u001b[39m=\u001b[39m net(input_tensor)\n\u001b[1;32m     45\u001b[0m \u001b[39m# print the shape of the output tensor\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mprint\u001b[39m(output_tensor\u001b[39m.\u001b[39mshape)\n",
            "File \u001b[0;32m~/Desktop/agnostic_rl-main/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[2], line 31\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnn(x)\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 31\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin(x)\n\u001b[1;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m~/Desktop/agnostic_rl-main/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Desktop/agnostic_rl-main/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (76800x12 and 64x18)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        \n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(4, 32, kernel_size=8, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        x = torch.randn(2, 4, 128, 128)\n",
        "        with torch.no_grad():\n",
        "            n_flatten = self.cnn(x).shape[1]\n",
        "            print(n_flatten)\n",
        "\n",
        "        self.lin = nn.Linear(n_flatten, 18)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # input x has shape (batch_size, 3, 224, 224)\n",
        "        x = self.cnn(x)\n",
        "        print(x.shape)\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# create an instance of the ConvNet class\n",
        "net = ConvNet()\n",
        "\n",
        "# create an input tensor of shape (batch_size, channels, height, width)\n",
        "input_tensor = torch.randn(100, 4, 128, 128)\n",
        "\n",
        "# pass the input tensor through the network\n",
        "output_tensor = net(input_tensor)\n",
        "\n",
        "\n",
        "# print the shape of the output tensor\n",
        "print(output_tensor.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8d5db420",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d5db420",
        "outputId": "d97a92e4-be62-48f8-889e-8217b8f6e902",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# switch to False to use CPU\n",
        "use_cuda = True\n",
        "\n",
        "use_cuda = use_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n",
        "torch.manual_seed(1);\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "72723fec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72723fec",
        "outputId": "09deaad0-145b-4559-daa3-881d32926107",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"# Get MNIST data\n",
        "!git clone https://github.com/ContinualAI/colab.git continualai/colab\n",
        "\n",
        "from continualai.colab.scripts import mnist\n",
        "mnist.init()\"\"\"\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad09c2d4",
      "metadata": {
        "id": "ad09c2d4"
      },
      "source": [
        "# Problem Task 1: split data into groups\n",
        "Consider to change output layer neurons!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9be64b2",
      "metadata": {
        "id": "d9be64b2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# we will construct 5 tasks of MNIST, where every task is responsible for 2 digits\n",
        "x_train, t_train, x_test, t_test = mnist.load()\n",
        "# tasks to use\n",
        "task_classes_arr = [(0, 1, 2, 3, 4), (5, 6, 7, 8, 9)]\n",
        "tasks_num = len(task_classes_arr) # 2\n",
        "\n",
        "task_data = []\n",
        "sub = 4\n",
        "for i, task_classes in enumerate(task_classes_arr):\n",
        "    train_mask = np.isin(t_train, task_classes)\n",
        "    test_mask = np.isin(t_test, task_classes)\n",
        "    x_train_task, t_train_task = x_train[train_mask], t_train[train_mask]\n",
        "    x_test_task, t_test_task = x_test[test_mask], t_test[test_mask]\n",
        "\n",
        "    task_data.append((x_train_task, t_train_task - (i * sub), x_test_task, t_test_task - (i * sub)))\n",
        "    sub += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b53bd507",
      "metadata": {
        "id": "b53bd507",
        "outputId": "299fdbb5-5aef-45b7-b96a-f621709e32a4",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AxesImage(size=(28, 28)) 4\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(plt.imshow(task_data[0][0][1][0]), task_data[0][1][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0291cfac",
      "metadata": {
        "id": "0291cfac",
        "outputId": "922317c6-f6ca-4671-e910-8e2fba7a4c15",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train, t_train, _, _ = task_data[1]\n",
        "t_train.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd90b2a2",
      "metadata": {
        "id": "bd90b2a2"
      },
      "source": [
        "# Problem Task 2: permute data\n",
        "Consider to change output layer neurons!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d0f1a4d1",
      "metadata": {
        "id": "d0f1a4d1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "\n",
        "class PermutedMNIST(datasets.MNIST):\n",
        "\n",
        "    def __init__(self, root=\"~/.torch/data/mnist\", train=True, permute_idx=None):\n",
        "        super(PermutedMNIST, self).__init__(root, train, download=True)\n",
        "        assert len(permute_idx) == 28 * 28\n",
        "        if self.train:\n",
        "            self.train_data_my = torch.stack([img.float().view(-1)[permute_idx] / 255 for img in self.train_data])\n",
        "        else:\n",
        "            self.test_data_my = torch.stack([img.float().view(-1)[permute_idx] / 255 for img in self.test_data])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        if self.train:\n",
        "            img, target = self.train_data_my[index], self.train_labels[index]\n",
        "        else:\n",
        "            img, target = self.test_data_my[index], self.test_labels[index]\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def get_sample(self, sample_size):\n",
        "        sample_idx = random.sample(range(len(self)), sample_size)\n",
        "        img = [img for img in self.train_data_my[sample_idx]]\n",
        "        label = [label for label in self.train_labels[sample_idx]]\n",
        "        return list(zip(img, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5c7c98cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514,
          "referenced_widgets": [
            "550a323bda5444789bcc59ed903b0b98",
            "31f35d2658d94615bd60d2d18d8d31d7",
            "d28fe18c4066491591877777b03f8bb6",
            "a1923562a7054eb4ab776d94576dabd9",
            "29e6cbd49228457e95073797b6e5c56f",
            "b739c15228614c678afef94a14e13b8b",
            "fb03a2af703f46d99672779c4254a806",
            "9bb60b035b3f4a018a1fecc0f2836808",
            "ce7e6b203e5947c3a89367946c016095",
            "6b9801ac1ac74782851718dca9562479",
            "df0414933e6442c0893cf29d72ce4896",
            "531fa795e5ce4b82876504f7e9ee1eab",
            "aa9592a862a04782a24d731d90689b34",
            "445c868a7e914c47a02a5a655afc984a",
            "69beb033160b402688c97c489cd97c45",
            "1fde7ada1938404fa1f3d0bd0a6c450b",
            "549d26470dc64768ac56f5dbb81488f4",
            "5c1669bd3633468d8c405e6497bb1dff",
            "783cc61bd86741ceb363a87e3ecedaf4",
            "995c9028b5db4a399b9c34954f77b75c",
            "96fec34223fa44ddab4cda7e056f877c",
            "bb177cea95804a2abe9c45ddb735d7f7",
            "2fc22a16b3164e0abd3d7c4ad728c761",
            "d1415c77594f414a8f5de4a00fec93f3",
            "f8b7547fc6b24d73a63800d5def3ce05",
            "6c746cfdad5f4ee0a328e039b97f836a",
            "16600b22f5ef4e6b88547f18e7c96860",
            "5ec86b25a34b4ef983266b9778d59d53",
            "f017d13ab03141fabc8fb001a42efc64",
            "88342cff85f24d0a906c3e780ee5f623",
            "ea1caf853dd0443a9ca98d613ea1efd5",
            "f580eecb64e94394b997fb5c36ba001a",
            "e64cdf0ba4a44369b618e113ad182f78",
            "04c4e52f9aea4f869ec678c19246e922",
            "43458cae45314802a58ed05e24a33e47",
            "95887d5eeebd41518f8da1ed5172e008",
            "350e745e1df34139b6a371bdce1857ac",
            "533f6f11d3e8458e81cc23f96bcc2eab",
            "8a894c0f09704541b8f21cf1903f379f",
            "95105b931a5e43c8861442c57f85b84a",
            "958480c361034004a3242b3ab5ffd7e1",
            "229467a7f3cc455cafe2e1592992e97e",
            "8e4f095cd7cf4d3abf1c3a13db47821f",
            "69580ab47e8f4215951201011e469ea9"
          ]
        },
        "id": "5c7c98cf",
        "outputId": "e328add6-1c4b-4451-957f-fded20482bf4",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.torch/data/mnist/PermutedMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "550a323bda5444789bcc59ed903b0b98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.torch/data/mnist/PermutedMNIST/raw/train-images-idx3-ubyte.gz to /root/.torch/data/mnist/PermutedMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.torch/data/mnist/PermutedMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "531fa795e5ce4b82876504f7e9ee1eab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.torch/data/mnist/PermutedMNIST/raw/train-labels-idx1-ubyte.gz to /root/.torch/data/mnist/PermutedMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.torch/data/mnist/PermutedMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fc22a16b3164e0abd3d7c4ad728c761",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.torch/data/mnist/PermutedMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.torch/data/mnist/PermutedMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.torch/data/mnist/PermutedMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04c4e52f9aea4f869ec678c19246e922",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.torch/data/mnist/PermutedMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.torch/data/mnist/PermutedMNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ]
        }
      ],
      "source": [
        "task_num = 5\n",
        "sample_size = 250\n",
        "def get_permute_mnist():\n",
        "    train_loader = {}\n",
        "    test_loader = {}\n",
        "    idx = list(range(28 * 28))\n",
        "    for i in range(task_num):\n",
        "        train_loader[i] = torch.utils.data.DataLoader(PermutedMNIST(train=True, permute_idx=idx), batch_size=32, shuffle=True)\n",
        "        test_loader[i] = torch.utils.data.DataLoader(PermutedMNIST(train=False, permute_idx=idx), batch_size=32, shuffle=True)\n",
        "        random.shuffle(idx)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = get_permute_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9fe82b7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "9fe82b7d",
        "outputId": "58299379-3287-46ce-a4b8-e0add6470462",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "tensor(8)\n",
            "tensor(9)\n",
            "tensor(4)\n",
            "tensor(4)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "for x, y in train_loader.items():\n",
        "    plt.subplot(1, 20, x+1)\n",
        "    img, label = y.dataset.get_sample(2)[0]\n",
        "    plt.imshow(img.reshape(28, 28))\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6dbef14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6dbef14",
        "outputId": "72cf67e4-d783-45b9-8e3c-477e4c19d29c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n",
            "torch.Size([784]) torch.Size([])\n"
          ]
        }
      ],
      "source": [
        "old = []\n",
        "for x, y in train_loader[0].dataset.get_sample(10):\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be112701",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be112701",
        "outputId": "5890607d-5e5f-429c-e7bb-78e6ceb560eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.2902, 0.6549, 0.0353, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4706, 0.9961, 0.3608, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4706, 0.9961, 0.9569,\n",
            "        0.8471, 0.4510, 0.4510, 0.0471, 0.0235, 0.0235, 0.0118, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4706, 0.9961,\n",
            "        0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.7843, 0.1922,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333,\n",
            "        0.9961, 0.7412, 0.2549, 0.2549, 0.2549, 0.2549, 0.2549, 0.2549, 0.2549,\n",
            "        0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0431, 0.9961, 0.6549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0431, 0.9961, 0.6549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0431, 0.9961, 0.6549, 0.0000, 0.0000, 0.0000, 0.1765,\n",
            "        0.1176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0431, 0.9961, 0.8235, 0.1294, 0.5804, 0.9176,\n",
            "        0.9569, 0.9451, 0.5686, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.9961, 0.9961, 0.9961, 0.9529,\n",
            "        0.4510, 0.3608, 0.4627, 0.9569, 0.7373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.9961, 0.9961, 0.9961,\n",
            "        0.6275, 0.0000, 0.0000, 0.0000, 0.4745, 0.9765, 0.2510, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.9961, 0.9961,\n",
            "        0.9020, 0.0235, 0.0000, 0.0000, 0.0000, 0.0235, 0.9608, 0.5569, 0.0157,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.9961,\n",
            "        0.9961, 0.5059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9608, 0.9961,\n",
            "        0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431,\n",
            "        0.9961, 0.9961, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9725,\n",
            "        0.9961, 0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.3647,\n",
            "        0.0392, 0.8902, 0.7451, 0.0392, 0.0000, 0.0000, 0.0000, 0.1294, 0.8941,\n",
            "        0.9961, 0.9725, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725,\n",
            "        0.8980, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3451,\n",
            "        0.9961, 0.9961, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1020, 0.8941, 0.8314, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.2471,\n",
            "        0.9412, 0.9961, 0.7373, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1529, 0.8863, 0.9882, 0.6510, 0.1647, 0.1294, 0.4667,\n",
            "        0.9647, 0.9961, 0.9490, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.1412, 0.7294, 0.9961, 0.9961, 0.9961,\n",
            "        0.9961, 0.9961, 0.9333, 0.2627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.4745, 0.9647,\n",
            "        0.9961, 0.9961, 0.7804, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(5)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0196, 0.0275, 0.3961, 0.5098, 0.6667, 0.9961, 0.5804, 0.5098, 0.0706,\n",
            "        0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.4784, 0.0196, 0.0118,\n",
            "        0.1451, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.3529, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.8157, 0.9922, 0.7176,\n",
            "        0.6353, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.7922, 0.2863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.8157, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9725, 0.7765, 0.4118, 0.4118, 0.4118, 0.4118,\n",
            "        0.4118, 0.4118, 0.8510, 0.8941, 0.8941, 0.4588, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.4039, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.8745, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4078, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9216, 0.6314, 0.2784, 0.1098, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9020,\n",
            "        0.6549, 0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8980, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.8941, 0.5137, 0.1961, 0.0235, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.5373, 0.7725, 0.7373, 0.2902, 0.2902, 0.2902, 0.1490, 0.2902, 0.2902,\n",
            "        0.6431, 0.9412, 0.9922, 0.9922, 0.9922, 0.9922, 0.7373, 0.5020, 0.0157,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.2039, 0.4078, 0.9451, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.7490, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.7373, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.2157,\n",
            "        0.7569, 0.9922, 0.9922, 0.8941, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0784, 0.9176, 0.9922, 0.9922, 0.5059, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.7333, 0.9922, 0.9922, 0.5059, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.5922, 0.4902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9922, 0.9922, 0.3294, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.6078, 0.9765, 0.5529, 0.1255, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9804, 0.9922, 0.9922, 0.0196,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.1176, 0.8431, 0.9922, 0.8353, 0.4157, 0.1098,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.9255, 0.9922, 0.9922, 0.3725,\n",
            "        0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.8431, 0.9922, 0.9922,\n",
            "        0.9412, 0.5529, 0.4392, 0.4392, 0.6039, 0.9843, 0.9922, 0.9922, 0.9922,\n",
            "        0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.3804,\n",
            "        0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8000,\n",
            "        0.0784, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0157, 0.3804, 0.5059, 0.6471, 0.9922, 0.9922, 0.8157, 0.3176,\n",
            "        0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(5)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.3765, 0.3176, 0.3647, 0.2784, 0.5098, 0.0627, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0784, 0.4353, 0.8784, 0.9922, 0.9922, 0.9922, 0.9922, 0.6588, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.6431, 0.8510, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.6824,\n",
            "        0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.5294, 0.9843, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9373, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.7961, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.8980, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.6627, 0.9922, 0.9922, 0.9922, 0.8941, 0.5765, 0.5765,\n",
            "        0.9569, 0.9922, 0.9333, 0.1647, 0.3059, 0.5686, 0.8824, 0.6863, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1647, 0.9216, 0.9922, 0.9922, 0.9176, 0.1961, 0.0078,\n",
            "        0.0000, 0.4863, 0.9843, 0.9882, 0.6471, 0.6353, 0.9922, 0.9922, 0.5294,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.6353, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.6549, 0.5569, 0.9529, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9569,\n",
            "        0.3098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0235, 0.1647, 0.2941, 0.6275, 0.7804, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9176, 0.9922, 0.8627,\n",
            "        0.5333, 0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.4863, 0.7373, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8588, 0.4510, 0.8157,\n",
            "        0.0627, 0.1216, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.9961, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7725, 0.0431,\n",
            "        0.3882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 1.0000, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8549, 0.6196, 0.3843, 0.1412,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.6196, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.7333, 0.8235, 0.9922, 0.9922, 0.6000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 0.5373, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.4314,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.2510,\n",
            "        0.8078, 0.9451, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.4078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.6235, 0.7843, 0.9647, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.8510, 0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0588, 0.0392, 0.5922, 0.9804, 0.9922, 0.9922,\n",
            "        0.9922, 0.7529, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3608, 0.6353,\n",
            "        0.9922, 0.6078, 0.0941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0078, 0.0667, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(8)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2902,\n",
            "        0.7098, 0.4510, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667,\n",
            "        0.9412, 0.9961, 0.9961, 0.6667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.6863, 0.9961, 0.9961, 0.9961, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.5333, 0.9961, 0.9961, 0.9961, 0.8863, 0.1922, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1176, 0.8902, 0.9961, 0.9961, 0.9961, 0.2314, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.4902, 0.9961, 0.9961, 0.9961, 0.9961, 0.0863, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.2510, 0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.1255, 0.8392, 0.9961, 0.9961, 0.9569, 0.3490, 0.0078, 0.0000,\n",
            "        0.0000, 0.0941, 0.7412, 0.9686, 0.8039, 0.1216, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.3686, 0.9961, 0.9961, 0.9961, 0.4353, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.3490, 0.9961, 0.9961, 0.9961, 0.3608, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.1765, 0.8745, 0.9961, 0.9961, 0.2706, 0.0000,\n",
            "        0.0000, 0.0000, 0.2549, 0.9412, 0.9961, 0.9961, 0.8706, 0.1765, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7608, 0.9961, 0.9961, 0.4941,\n",
            "        0.3059, 0.3059, 0.7294, 0.9529, 0.9961, 0.9961, 0.9961, 0.7529, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3373, 0.9961, 0.9961,\n",
            "        0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.3294,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.7765,\n",
            "        0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.7765,\n",
            "        0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4000, 0.9843, 0.9961, 0.9961, 0.7294, 0.7333, 0.9961, 0.9961, 0.9961,\n",
            "        0.5412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.3137, 0.7725, 0.6196, 0.2314, 0.6980, 0.9961, 0.9961,\n",
            "        0.9961, 0.5059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6980, 0.9961,\n",
            "        0.8745, 0.5059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4118, 0.9529,\n",
            "        0.9961, 0.7255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5412,\n",
            "        0.9961, 0.9961, 0.7059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.9137, 0.9961, 0.9961, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.7843, 0.9961, 0.5961, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.3059, 0.9961, 0.5098, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(4)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.3490,\n",
            "        0.6118, 0.6118, 1.0000, 0.8157, 0.4980, 0.0196, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.2275, 0.6980, 0.9098,\n",
            "        0.9922, 0.9922, 0.9922, 0.9961, 0.9922, 0.9922, 0.5725, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4824, 0.8510, 0.9922, 0.9961,\n",
            "        0.9922, 0.9922, 0.9412, 0.6824, 0.6863, 0.9451, 0.9922, 0.8353, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6275, 0.9922, 0.9294,\n",
            "        0.4588, 0.4275, 0.0745, 0.0627, 0.0000, 0.0000, 0.8392, 0.9922, 0.8353,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.2275,\n",
            "        0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.9569, 0.9922,\n",
            "        0.5412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6118, 0.9961,\n",
            "        0.9961, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392,\n",
            "        0.9922, 0.7294, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.9961, 0.9922, 0.5647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.5608, 0.9961, 0.9490, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0627, 0.8510, 0.9961, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.7725, 0.9961, 0.9451, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.1451, 0.9529, 0.9922, 0.4431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0275, 0.6627, 0.9922, 0.8706, 0.1176, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.3451, 0.9922, 0.9922, 0.2549, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.6471,\n",
            "        0.7647, 0.7647, 0.7686, 0.9569, 0.9922, 0.8706, 0.0549, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392, 0.5255, 1.0000, 0.9961,\n",
            "        0.9961, 0.9961, 0.9961, 1.0000, 0.9961, 0.9961, 0.9333, 0.4667, 0.0902,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725, 0.6863, 0.9922, 0.9961,\n",
            "        0.9843, 0.9137, 0.9569, 0.9922, 0.9961, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.9020, 0.3412, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3216, 0.8980, 0.9922, 0.9922,\n",
            "        0.4549, 0.2824, 0.0000, 0.6510, 0.9922, 0.9961, 0.7020, 0.3059, 0.7020,\n",
            "        0.9922, 0.9961, 0.9922, 0.6627, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.8941, 0.9922, 0.6431,\n",
            "        0.1608, 0.0000, 0.1020, 0.8000, 0.9843, 0.9922, 0.5137, 0.0118, 0.0000,\n",
            "        0.0118, 0.3725, 0.9333, 0.9922, 0.9922, 0.8039, 0.0941, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9059, 0.9922, 0.6039,\n",
            "        0.0196, 0.0000, 0.0902, 0.8118, 0.9922, 0.9922, 0.5451, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.1412, 0.5804, 0.9922, 0.9922, 0.9020, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(2)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.1020, 0.4784, 0.8941, 0.9961, 0.9961, 0.7804,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.4235, 0.8863, 0.9922, 0.9255, 0.7647, 0.5804,\n",
            "        0.9765, 0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0588, 0.6353, 0.9961, 0.8039, 0.3412, 0.0784, 0.0000,\n",
            "        0.0000, 0.7333, 0.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1176, 0.9176, 0.9725, 0.4902, 0.0157, 0.0000, 0.0000,\n",
            "        0.0000, 0.2588, 0.3373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.2078, 0.9255, 0.9137, 0.3137, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0588, 0.9020, 0.8510, 0.1294, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0627, 0.7686, 0.8627, 0.1176, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.4902, 0.9922, 0.2314, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.1176, 0.9490, 0.5451, 0.0118, 0.1569, 0.2118,\n",
            "        0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.3647, 0.9451, 0.2039, 0.6863, 0.9686,\n",
            "        0.9922, 0.9922, 0.8784, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6941, 0.5412, 0.4549, 0.9843,\n",
            "        0.6039, 0.6039, 0.8784, 1.0000, 0.8863, 0.0745, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.9686, 0.5373, 0.3529,\n",
            "        0.9647, 0.1333, 0.0000, 0.0000, 0.3725, 0.9922, 0.8706, 0.2235, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2745, 0.9922, 0.2745,\n",
            "        0.0000, 0.2980, 0.0353, 0.0000, 0.0000, 0.0118, 0.5529, 0.9922, 0.6314,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2745, 0.9922,\n",
            "        0.2392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.8039,\n",
            "        0.6314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2745,\n",
            "        0.9922, 0.3765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4392, 0.8588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.2745, 0.9922, 0.7059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.5255, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0196, 0.7647, 0.9843, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0706, 0.8039, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.2353, 0.9922, 0.9255, 0.2471, 0.0000, 0.0000,\n",
            "        0.0000, 0.2706, 0.8549, 0.8745, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7333, 0.9922, 0.9882, 0.7765,\n",
            "        0.5098, 0.7882, 0.9961, 0.8902, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.3294, 0.6980,\n",
            "        0.9922, 0.9922, 0.8078, 0.5725, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(6)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4235, 0.9961, 0.4078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4549, 0.9647, 0.9922, 0.6784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196,\n",
            "        0.3686, 0.9451, 0.9922, 0.8549, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.2235, 0.9922, 0.9961, 0.9922, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0863, 0.9059, 0.9922, 0.9961, 0.5176, 0.0235, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.4980, 0.9922, 0.9922, 0.6471, 0.0157, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.1922, 0.8784, 0.9922, 0.9922, 0.4431, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0235, 0.7137, 0.9922, 0.9882, 0.6078, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.2118, 0.9922, 0.9922, 0.9412, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.4902, 0.9922, 0.9922, 0.6627, 0.0000, 0.0000,\n",
            "        0.0000, 0.4745, 0.5255, 0.3882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.5137, 0.9961, 0.9961, 0.8941, 0.0000, 0.0000,\n",
            "        0.0000, 0.2039, 0.9451, 0.9961, 0.9961, 0.5098, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.7882, 0.9922, 0.9922, 0.3882, 0.0000,\n",
            "        0.0000, 0.4549, 0.9647, 0.9922, 0.9922, 0.9922, 0.9843, 0.5176, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.8627, 0.9922, 0.9333, 0.2314,\n",
            "        0.0196, 0.3686, 0.9451, 0.9922, 0.4706, 0.1020, 0.2431, 0.8980, 0.8353,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9922, 0.9922, 0.6667,\n",
            "        0.0000, 0.0549, 0.9922, 0.9961, 0.4745, 0.0157, 0.0000, 0.0863, 0.8157,\n",
            "        0.8353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4588, 0.9922, 0.9922,\n",
            "        0.3137, 0.0000, 0.1922, 0.9922, 0.6235, 0.0118, 0.0000, 0.0000, 0.2667,\n",
            "        0.9922, 0.8353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7294, 0.9922,\n",
            "        0.9922, 0.3137, 0.0000, 0.5765, 0.9922, 0.5255, 0.0000, 0.0000, 0.3490,\n",
            "        0.8039, 0.9922, 0.7216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667,\n",
            "        0.9608, 0.9922, 0.6941, 0.0745, 0.6431, 0.9922, 0.6000, 0.1608, 0.6275,\n",
            "        0.9451, 0.9922, 0.9608, 0.2627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.7333, 0.9922, 0.9922, 0.8000, 0.9922, 0.9922, 1.0000, 0.9922,\n",
            "        0.9922, 0.9922, 0.9098, 0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1137, 0.8157, 0.9922, 0.9922, 0.9922, 0.9922, 1.0000,\n",
            "        0.9686, 0.9412, 0.7725, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.1020, 0.4706, 0.8000, 0.9922, 0.7137,\n",
            "        0.7490, 0.2706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(6)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.3882, 0.9922, 0.7529, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.7098, 0.9882, 0.9922, 0.6235, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.7098, 0.9882, 0.9922, 0.7020, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1647, 0.8667, 0.9882, 0.9922, 0.7020, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.5255, 0.9882, 0.9882, 0.9922, 0.7020, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.8510, 0.9882, 0.9882, 0.9922, 0.7020,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4471, 0.9882, 0.9882, 0.9922,\n",
            "        0.7020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9882, 0.9882,\n",
            "        0.9922, 0.3804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9922,\n",
            "        0.9922, 1.0000, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7725,\n",
            "        0.9882, 0.9882, 0.9922, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "        0.8706, 0.9882, 0.9882, 0.9922, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4275, 0.9882, 0.9882, 0.9882, 0.9922, 0.1373, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 1.0000, 0.9922, 0.9922, 0.9922, 0.5686, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.9922, 0.9882, 0.9882, 0.9882, 0.0784, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0235, 0.4706, 0.9922, 0.9882, 0.9882, 0.5804, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.4706, 0.9882, 0.9922, 0.9882, 0.9882, 0.4235, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.7137, 0.9922, 1.0000, 0.9922, 0.9294, 0.2431,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.7098, 0.9882, 0.9922, 0.9882, 0.6824,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7098, 0.9882, 0.9922, 0.9451,\n",
            "        0.2392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3843, 0.9882, 0.9922,\n",
            "        0.7020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(1)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1608,\n",
            "        0.4392, 0.6118, 0.8510, 0.9961, 0.9961, 0.9961, 0.9961, 0.9098, 0.6118,\n",
            "        0.4275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.4627, 0.7843,\n",
            "        0.9451, 0.9922, 0.9922, 0.9765, 0.9137, 0.9137, 0.9137, 0.6196, 0.9176,\n",
            "        0.9804, 0.9451, 0.0941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.7176, 0.9961,\n",
            "        0.9922, 0.9922, 0.7647, 0.3059, 0.2353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.5765, 0.9922, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.9020, 0.9922,\n",
            "        0.9961, 0.6824, 0.1922, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.4627, 0.9922, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.7176, 0.9922,\n",
            "        0.9922, 0.3765, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.4627, 0.9922, 0.1608, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.9961,\n",
            "        0.9569, 0.3255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.2314, 0.9373, 0.6863, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4627,\n",
            "        0.9922, 0.8353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0314, 0.7882, 0.9255, 0.2235, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4627, 0.9922, 0.8863, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.6471, 0.9961, 0.7020, 0.6863, 0.3176,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0667, 0.7686, 0.9922, 0.7843, 0.1216, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7647, 0.9961, 0.9922, 0.9922,\n",
            "        0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.1882, 0.8157, 0.9922, 0.9412, 0.5882, 0.2667,\n",
            "        0.0000, 0.0000, 0.0902, 0.3843, 0.3843, 0.7373, 0.9373, 0.9961, 0.9922,\n",
            "        0.9922, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.6784, 1.0000, 0.9961,\n",
            "        0.9961, 0.9961, 0.9961, 1.0000, 0.9961, 0.9961, 0.9961, 0.9059, 0.6118,\n",
            "        0.9961, 0.6863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392,\n",
            "        0.5294, 0.5294, 0.5294, 0.5294, 0.5333, 0.5294, 0.5294, 0.3255, 0.0941,\n",
            "        0.6118, 0.9922, 0.6824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.8784, 0.9922, 0.5647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.9961, 0.9804, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.2980, 0.9961, 0.7647, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.2980, 1.0000, 0.7686, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.9137, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.9137, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.6196,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6980,\n",
            "        0.9137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(9)), (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.4627, 0.2627, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5529, 0.9961, 0.7294, 0.3843,\n",
            "        0.3843, 0.1020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3020, 0.7608,\n",
            "        0.9216, 0.6275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1412, 0.9961, 0.9961,\n",
            "        0.9961, 0.9961, 0.8824, 0.8392, 0.8392, 0.8392, 0.8392, 0.8392, 0.9647,\n",
            "        0.9961, 0.9961, 0.8353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7804,\n",
            "        0.9922, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "        0.9961, 0.8431, 0.7373, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.3137, 0.3216, 0.3216, 0.3216, 0.3804, 0.9412, 0.9961, 0.9961,\n",
            "        0.9529, 0.4392, 0.0941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.8235, 0.9961,\n",
            "        0.9765, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1020, 0.8314, 0.9961,\n",
            "        0.9961, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4275, 0.9961,\n",
            "        0.9961, 0.7843, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4392, 0.9686,\n",
            "        0.9961, 0.9961, 0.9490, 0.3804, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.4667, 0.9647,\n",
            "        0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.5725, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.9961,\n",
            "        0.9961, 0.9961, 0.8745, 0.8078, 0.8078, 0.9882, 0.9098, 0.1569, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3882,\n",
            "        0.8902, 0.8902, 0.4941, 0.1216, 0.0000, 0.0000, 0.9490, 0.9961, 0.5647,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9490, 0.9961,\n",
            "        0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9490,\n",
            "        0.9961, 0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.6706,\n",
            "        0.9961, 0.9961, 0.5333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5765, 0.6627, 0.2314, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392, 0.6392,\n",
            "        0.9961, 0.9961, 0.7137, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961, 0.9333,\n",
            "        0.6667, 0.2471, 0.1137, 0.1216, 0.0000, 0.0902, 0.2471, 0.3490, 0.8078,\n",
            "        0.9961, 0.9961, 0.7647, 0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.7922,\n",
            "        0.9725, 0.9961, 0.9961, 0.8392, 0.8471, 0.7059, 0.8078, 0.9961, 0.9961,\n",
            "        0.9961, 0.9059, 0.5686, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.3176, 0.4941, 0.9176, 0.9176, 0.9176, 0.9176, 0.9176, 0.9176,\n",
            "        0.5176, 0.3765, 0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]), tensor(3))]\n"
          ]
        }
      ],
      "source": [
        "old = old + train_loader[0].dataset.get_sample(10)\n",
        "print(old)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98585fb8",
      "metadata": {
        "id": "98585fb8",
        "outputId": "84891463-a9c2-4a0c-a8d6-19013da5aef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.2784, 0.3608, 0.6196, 0.6196,\n",
            "        0.7843, 0.9647, 0.9412, 0.6196, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.1098, 0.5020, 0.8353, 0.9294, 0.9765, 0.9961, 0.9961, 0.9961,\n",
            "        0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176,\n",
            "        0.2078, 0.4941, 0.8706, 0.9961, 0.9961, 0.8510, 0.7922, 0.7882, 0.7882,\n",
            "        0.7098, 0.9961, 0.9961, 0.9373, 0.1843, 0.2314, 0.4471, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.6941,\n",
            "        0.9333, 0.9961, 0.9098, 0.6667, 0.4824, 0.2314, 0.0431, 0.0000, 0.0000,\n",
            "        0.1255, 0.7333, 0.9961, 0.9961, 0.8314, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.7412,\n",
            "        0.9961, 0.9176, 0.5020, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.5725, 0.9961, 0.9961, 0.7843, 0.0941, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8078,\n",
            "        0.9961, 0.8157, 0.2471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0353, 0.4157, 0.9804, 0.9725, 0.6510, 0.0353, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.9961, 0.9961, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1451, 0.7137, 0.9961, 0.8706, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.8549, 0.9961, 0.8353, 0.3451, 0.0196, 0.0000, 0.0000, 0.0000,\n",
            "        0.0275, 0.7098, 0.9961, 0.7804, 0.1137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0980, 0.7333, 0.9961, 0.9961, 0.8353, 0.3569, 0.0000,\n",
            "        0.1451, 0.7098, 0.9961, 0.8902, 0.1294, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2039, 0.6000, 0.9961, 0.9961,\n",
            "        0.8431, 0.7961, 1.0000, 0.8902, 0.3608, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.2118,\n",
            "        0.7686, 0.9961, 0.9961, 0.9961, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4510, 0.9843, 0.9961, 0.8941, 0.9294, 0.9725, 0.7176, 0.0941, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.4510, 0.9804, 0.9961, 0.6745, 0.1412, 0.3373, 0.9294, 1.0000, 0.7412,\n",
            "        0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.5647, 0.9804, 0.9961, 0.5176, 0.0314, 0.0000, 0.0000, 0.3333, 0.9373,\n",
            "        0.9961, 0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941,\n",
            "        0.6863, 0.9843, 0.9961, 0.5176, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.3725, 0.9961, 0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.8078, 0.9961, 0.9961, 0.9216, 0.2980, 0.1059, 0.2588, 0.4510, 0.4510,\n",
            "        0.4510, 0.6196, 0.9961, 0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.9725, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "        0.9961, 0.9961, 0.9765, 0.8314, 0.3255, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.2902, 0.6157, 0.9373, 0.9608, 0.9608, 0.9137, 0.6157,\n",
            "        0.4745, 0.2745, 0.2745, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(8)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for x, y in old:\n",
        "    print(x, y)\n",
        "    plt.imshow(x.reshape(-1, 28))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8801e5",
      "metadata": {
        "id": "dc8801e5"
      },
      "source": [
        "# P&C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "96b290d1",
      "metadata": {
        "id": "96b290d1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# basic training and testing loops\n",
        "def train_progress(model, net_id, task_id, device, train_loader, optimizer, epoch, log_training=False):\n",
        "    print(f\"Progress train task {task_id}\\n\")\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    #for start in range(0, len(t_test)-1, 256):\n",
        "    for x, y in train_loader:\n",
        "        \"\"\"if task_id == 0:\n",
        "            print(f\"task id is {task_id}\")\n",
        "            print(plt.imshow(x[0].reshape(28, 28)))\n",
        "            print(y[0])\n",
        "        break\n",
        "        \"\"\"\n",
        "        #end = start + 256\n",
        "        #x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        #x = x.view(x.size(0), -1) # transform image into one vector\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(net_id, x)\n",
        "        loss = F.cross_entropy(output, y)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if log_training:\n",
        "          print('Train Epoch: {} \\tLoss: {:.3f}'.format(epoch, loss.item()))\n",
        "    print(f\"Epoch {epoch} loss {epoch_loss / len(train_loader)} - unnormilized epoch loss {epoch_loss}\")\n",
        "    \n",
        "    return epoch_loss / len(train_loader)\n",
        "        \n",
        "def train_compress_ewc(model, ewc, ewc_lambda, active_column, kb_column, task_id, device, train_loader, optimizer, epoch, old_penalties=0, log_training=False):\n",
        "    print(f\"Compress train task {task_id} with lambda={ewc_lambda}\\n\")\n",
        "    ewc_lambda = ewc_lambda # importance\n",
        "    penalty_task = 0\n",
        "    recorded_pen = []\n",
        "    \n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    #for start in range(0, len(t_test)-1, 256):\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        #end = start + 256\n",
        "        #x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        #x = x.view(x.size(0), -1) # transform image into one vector\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output_active_column = F.log_softmax(model(active_column, x), dim=1)\n",
        "        output_active_column = output_active_column.detach()\n",
        "        \n",
        "        output_kb_column = F.log_softmax(model(kb_column, x), dim=1)\n",
        "\n",
        "        penalty = ewc.penalty(model.columns[kb_column])\n",
        "        penalty_task += penalty\n",
        "        recorded_pen.append(penalty)\n",
        "\n",
        "        if penalty > 1:\n",
        "          #print(\"---------------->>>>>>>> before\", penalty)\n",
        "          penalty = (penalty - torch.tensor(recorded_pen).mean())/torch.tensor(recorded_pen).std()\n",
        "          penalty = penalty/1000\n",
        "          #print(\"---------------->>>>>>>> after\", penalty)\n",
        "\n",
        "        loss = F.kl_div(output_kb_column, output_active_column, reduction=\"batchmean\", log_target=True) + ewc_lambda * penalty\n",
        "        #output = model(kb_column, x)\n",
        "        #loss = F.cross_entropy(output, y) + ewc_lambda * penalty\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if log_training:\n",
        "          print('Train Epoch: {} \\tLoss: {:.3f}'.format(epoch, loss.item()))\n",
        "        \n",
        "        epoch_loss /= len(train_loader)\n",
        "        \n",
        "    print(f\"Epoch {epoch}; loss {epoch_loss}; sum(penalty) = {penalty_task}\")\n",
        "    #f = open(f\"recorded_penalty_lambda_{ewc_lambda}.txt\", \"a\")\n",
        "    #f.write(f\"Task {task_id} with penalties\\n{recorded_pen}\\n\\n\")\n",
        "    #f.close()\n",
        "    \n",
        "    return epoch_loss / len(train_loader), penalty_task\n",
        "\n",
        "\n",
        "def train_compress_normal(model, active_column, kb_column, task_id, device, train_loader, optimizer, epoch, log_training=False):\n",
        "    print(f\"Compress train task {task_id}\\n\")\n",
        "\n",
        "    \"\"\"print(\"=============================\")\n",
        "    for param in model.columns[active_column].parameters():\n",
        "        print(param.requires_grad)\n",
        "    \n",
        "    for param in model.columns[kb_column].parameters():\n",
        "        print(param.requires_grad)\n",
        "    \n",
        "    print(\"=============================\")\"\"\"\n",
        "    \n",
        "    model.columns[kb_column].train()\n",
        "    epoch_loss = 0\n",
        "    print(model.isColumnFrozen(active_column), model.isColumnFrozen(kb_column))\n",
        "    #for start in range(0, len(t_test)-1, 256):\n",
        "    for x, y in train_loader:\n",
        "        #end = start + 256\n",
        "        #x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        #x = x.view(x.size(0), -1) # transform image into one vector\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output_active_column = F.log_softmax(model(active_column, x), dim=1)\n",
        "        output_active_column = output_active_column.detach()\n",
        "\n",
        "        output_kb_column = F.log_softmax(model(kb_column, x), dim=1)\n",
        "\n",
        "        loss = F.kl_div(output_kb_column, output_active_column, reduction=\"batchmean\", log_target=True)\n",
        "        #output = model(kb_column, x)\n",
        "        #loss = F.cross_entropy(output_kb_column, output_active_column)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if log_training:\n",
        "          print('Train Epoch: {} \\tLoss: {:.3f}'.format(epoch, loss.item()))\n",
        "\n",
        "        epoch_loss /= len(train_loader)\n",
        "    print(model.isColumnFrozen(active_column), model.isColumnFrozen(kb_column))    \n",
        "    print(f\"Epoch {epoch} loss {epoch_loss}\")\n",
        "    return epoch_loss / len(train_loader)\n",
        "        \n",
        "\n",
        "'''def test(model, net_id, task_id, device, x_test, t_test):\n",
        "    print(f\"Test task {task_id}\\n\")\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for start in range(0, len(t_test)-1, 256):\n",
        "      end = start + 256\n",
        "      with torch.no_grad():\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x = x.view(x.size(0), -1) # transform image into one vector\n",
        "        \n",
        "        output = model(net_id, x)\n",
        "        #test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
        "        #pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += (F.softmax(output, dim=1).max(dim=1)[1] == y).data.sum()\n",
        "        #print(correct, len(t_test))\n",
        "\n",
        "    #test_loss /= len(t_test)\n",
        "    return None, 100 * correct / len(t_test)'''\n",
        "\n",
        "def test(model, net_id, device, test_loader):\n",
        "    if net_id == 0:\n",
        "        model_name = \"kb_column\"\n",
        "    else:\n",
        "        model_name = \"active_column\"\n",
        "    \n",
        "    print(f\"Test task with model_id {model_name}-{net_id}\\n\")\n",
        "    \n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    #for start in range(0, len(t_test)-1, 256):   \n",
        "    for x, y in test_loader:\n",
        "        #plt.imshow(x[0].reshape(28, 28))\n",
        "        #end = start + 256\n",
        "        with torch.no_grad():\n",
        "            #x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            #x = x.view(x.size(0), -1) # transform image into one vector\n",
        "            output = model(net_id, x)\n",
        "            correct += (F.softmax(output, dim=1).max(dim=1)[1] == y).data.sum() # sum up batch loss\n",
        "    #test_loss /= len(test_loader.dataset)\n",
        "    print('Test set: Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "    return correct / len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "adf01b25",
      "metadata": {
        "id": "adf01b25",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def fisher_update(model, F_old, ewc):\n",
        "    gamma = 0.8\n",
        "    for n, p in model.named_parameters():\n",
        "        ewc.precision_matrices[n].data += gamma*F_old[n].data\n",
        "\"\"\"\n",
        "\n",
        "def train_PC(ewc_lambda=1000, epochs=10, logs=False):\n",
        "    \"Train all 5 taks using PNN\"\n",
        "    loss_kb, acc_kb, loss_ac, acc_ac, ewc = {}, {}, {}, {}, None\n",
        "    \n",
        "    net = ProgNet(colGen = ActorCritic())\n",
        "\n",
        "    kb_column = net.addColumn() # net_0\n",
        "    active_column = net.addColumn() # net_1\n",
        "    \n",
        "    #optimizer_kb = optim.SGD(net.getColumn(kb_column).parameters(), lr=0.01)\n",
        "    #optimizer_active = optim.SGD(net.getColumn(active_column).parameters(), lr=0.01)\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "    if torch.cuda.is_available() and use_cuda:\n",
        "        net.cuda()\n",
        "        print(f\"Run model on cuda:{net}\\n\")\n",
        "    \n",
        "    \"\"\"F_old = None\n",
        "    F_new = None\"\"\"\n",
        "    \n",
        "    for task_id in range(task_num):\n",
        "        print(f\"==================TRAIN TASK {task_id}======================\\n\")\n",
        "        loss_kb[task_id] = []\n",
        "        loss_ac[task_id] = []\n",
        "        acc_kb[task_id] = []\n",
        "        acc_ac[task_id] = []\n",
        "        penalty = 0    \n",
        "        \n",
        "        # train on current task\n",
        "        #x_train, t_train, _, _ = task_data[task_id]\n",
        "        \n",
        "        # switch grad for progress and compress phase\n",
        "        net.unfreezeColumn(active_column)\n",
        "        net.freezeColumn(kb_column)\n",
        "        #net.network_reset(kb_column)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            loss_ac[task_id].append(train_progress(net, active_column, task_id, device, train_loader[task_id], optimizer, epoch, log_training=logs))\n",
        "            for sub_task in range(task_id + 1):\n",
        "              acc_ac[sub_task].append(test(net, active_column, device, test_loader[sub_task]))\n",
        "        \n",
        "        # switch grad for compress phase\n",
        "        net.unfreezeColumn(kb_column)\n",
        "        net.freezeColumn(active_column)      \n",
        "        \n",
        "        if task_id == 0:\n",
        "          for epoch in range(epochs):\n",
        "            train_compress_normal(net, active_column, kb_column, task_id, device, train_loader[task_id], optimizer, epoch=epoch, log_training=logs)\n",
        "            acc_kb[task_id].append(test(net, kb_column, device, test_loader[task_id]))\n",
        "            #test(net, active_column, device, test_loader[task_id])\n",
        "            #ewc = EWC(net.columns[kb_column], x_train)\n",
        "        else:\n",
        "            old_tasks = []\n",
        "            for sub_task in range(task_id):\n",
        "                old_tasks = old_tasks + train_loader[sub_task].dataset.get_sample(10000)\n",
        "            old_tasks = random.sample(old_tasks, k=10000)\n",
        "            #F_old = ewc.precision_matrices\n",
        "            for epoch in range(epochs):\n",
        "              loss_ewc, pen = train_compress_ewc(net, EWC(net.columns[kb_column], old_tasks), ewc_lambda, active_column, kb_column, task_id, device, train_loader[task_id], optimizer, epoch, log_training=logs)\n",
        "              loss_kb[task_id].append(loss_ewc)\n",
        "              penalty += pen\n",
        "            #train_compress_normal(net, active_column, kb_column, task_id, device, x_train, t_train, optimizer, epochs=epochs, log_training=logs)\n",
        "            #ewc = EWC(net.columns[kb_column], train_loader[task_id])\n",
        "            #fisher_update(net.columns[kb_column], F_old, ewc)\n",
        "              for sub_task in range(task_id + 1):\n",
        "                acc_kb[sub_task].append(test(net, kb_column, device, test_loader[sub_task]))\n",
        "                #test(net, active_column, device, test_loader[task_id])\n",
        "                    \n",
        "        print(f\"{penalty} ----------- {penalty/epochs}\")\n",
        "        \n",
        "        net.unfreezeColumn(kb_column)\n",
        "        net.unfreezeColumn(active_column)\n",
        "      \n",
        "        # test on all tasks with lateral connections\n",
        "        #acc_test = []\n",
        "        #net.freezeColumn(kb_column)\n",
        "        #net.freezeColumn(active_column)\n",
        "        \n",
        "        \"\"\"for test_task_id in range(0, tasks_num):\n",
        "            #_, _, x_test, t_test = task_data[test_task_id]\n",
        "            print(f\"Testing .... Task {test_task_id}\\n\")\n",
        "            test_acc = test(model, device, test_loader[test_task_id])\n",
        "            acc_test.append(test_acc)\n",
        "        print(f\"Avg acc over all tasks: {np.mean(np.array(acc_test))}\\n\")\n",
        "\n",
        "        if test_task_id < (tasks_num - 1):\n",
        "            acc_test.extend([np.nan] * (4 - test_task_id))\n",
        "        acc_grid_test.append(acc_test)\"\"\"\n",
        "        \n",
        "        '''print(f\"=========================================================\")\n",
        "        print(f\"Acc after trained on task {task_id} : {acc_grid_test}\\n\")\n",
        "        print(f\"Loss after trained on task {task_id} : {loss_grid_test}\\n\")\n",
        "        print(f\"=========================================================\")'''\n",
        "        \n",
        "        #net.unfreezeColumn(kb_column)\n",
        "        #net.unfreezeColumn(active_column)\n",
        "\n",
        "        # Serializing json\n",
        "        json_kb = json.dumps(convert(acc_kb), indent=4)\n",
        "        json_ac = json.dumps(convert(acc_ac), indent=4)\n",
        "        \n",
        "        # Writing to sample.json\n",
        "        with open(f\"/content/drive/MyDrive/Github/agnostic_rl/agent/acc_kb_{ewc_lambda}.json\", \"w\") as outfile:\n",
        "            outfile.write(f\"{net}\\n\\n{json_kb}\")\n",
        "\n",
        "        with open(f\"/content/drive/MyDrive/Github/agnostic_rl/agent/acc_ac_{ewc_lambda}.json\", \"w\") as outfile:\n",
        "            outfile.write(f\"{net}\\n\\n{json_ac}\")\n",
        "        \n",
        "        \n",
        "    return loss_kb, loss_ac, acc_kb, acc_ac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f5db8b51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5db8b51",
        "outputId": "20b3f126-a9fd-423a-ac0e-22c170d010ac",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run model on cuda:ProgNet(\n",
            "  (columns): ModuleList(\n",
            "    (0): ProgColumn(\n",
            "      (blocks): ModuleList(\n",
            "        (0): ProgDenseBlock(\n",
            "          (module): Linear(in_features=784, out_features=400, bias=True)\n",
            "          (laterals): ModuleList()\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (1): ProgDenseBlock(\n",
            "          (module): Linear(in_features=400, out_features=400, bias=True)\n",
            "          (laterals): ModuleList()\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (2): ProgDenseBlock(\n",
            "          (module): Linear(in_features=400, out_features=10, bias=True)\n",
            "          (laterals): ModuleList()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): ProgColumn(\n",
            "      (blocks): ModuleList(\n",
            "        (0): ProgDenseBlock(\n",
            "          (module): Linear(in_features=784, out_features=400, bias=True)\n",
            "          (laterals): ModuleList()\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (1): ProgDenseBlock(\n",
            "          (module): Linear(in_features=400, out_features=400, bias=True)\n",
            "          (laterals): ModuleList(\n",
            "            (0): Linear(in_features=400, out_features=400, bias=True)\n",
            "          )\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (2): ProgDenseBlock(\n",
            "          (module): Linear(in_features=400, out_features=10, bias=True)\n",
            "          (laterals): ModuleList(\n",
            "            (0): Linear(in_features=400, out_features=10, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "==================TRAIN TASK 0======================\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 0 loss 1.0002803208589555 - unnormilized epoch loss 1875.5256016105413\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8923/10000 (89%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 1 loss 0.3516901148557663 - unnormilized epoch loss 659.4189653545618\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9148/10000 (91%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 2 loss 0.29217133055726685 - unnormilized epoch loss 547.8212447948754\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9231/10000 (92%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 3 loss 0.25581649954319 - unnormilized epoch loss 479.65593664348125\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9338/10000 (93%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 4 loss 0.22656496430138748 - unnormilized epoch loss 424.8093080651015\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9390/10000 (94%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 5 loss 0.2007579049984614 - unnormilized epoch loss 376.42107187211514\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9462/10000 (95%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 6 loss 0.17988071480840445 - unnormilized epoch loss 337.27634026575834\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9498/10000 (95%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 7 loss 0.1616191948061188 - unnormilized epoch loss 303.03599026147276\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9550/10000 (96%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 8 loss 0.14699517608781656 - unnormilized epoch loss 275.61595516465604\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9571/10000 (96%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 9 loss 0.13369214172338445 - unnormilized epoch loss 250.67276573134586\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9610/10000 (96%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 10 loss 0.12246494963020087 - unnormilized epoch loss 229.62178055662662\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9634/10000 (96%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 11 loss 0.1125563960303863 - unnormilized epoch loss 211.0432425569743\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9664/10000 (97%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 12 loss 0.10383233129059274 - unnormilized epoch loss 194.6856211698614\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 13 loss 0.09613654950583975 - unnormilized epoch loss 180.25603032344952\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9679/10000 (97%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 14 loss 0.08912271944036086 - unnormilized epoch loss 167.10509895067662\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9709/10000 (97%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 15 loss 0.08263662485728661 - unnormilized epoch loss 154.9436716074124\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9703/10000 (97%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 16 loss 0.0773628614589572 - unnormilized epoch loss 145.05536523554474\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9726/10000 (97%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 17 loss 0.07221140526706973 - unnormilized epoch loss 135.39638487575576\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9732/10000 (97%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 18 loss 0.06769504886120557 - unnormilized epoch loss 126.92821661476046\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9742/10000 (97%)\n",
            "\n",
            "Progress train task 0\n",
            "\n",
            "Epoch 19 loss 0.06328234290406108 - unnormilized epoch loss 118.65439294511452\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 0 loss 0.0001797939604490573\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 8879/10000 (89%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 1 loss 0.00010642107532569957\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9100/10000 (91%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 2 loss 9.825363329945314e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9207/10000 (92%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 3 loss 5.3927264006546856e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9303/10000 (93%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 4 loss 6.931979778067386e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9368/10000 (94%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 5 loss 6.931333064306461e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9408/10000 (94%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 6 loss 2.439935388701009e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9451/10000 (95%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 7 loss 2.2792370596947107e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9483/10000 (95%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 8 loss 1.2828358587673489e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9518/10000 (95%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 9 loss 4.767027920760114e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9528/10000 (95%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 10 loss 3.332844273744464e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9548/10000 (95%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 11 loss 6.8257090126035286e-06\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9561/10000 (96%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 12 loss 3.0957597634387875e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9575/10000 (96%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 13 loss 6.73206030726716e-06\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9586/10000 (96%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 14 loss 1.4589895374168661e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9596/10000 (96%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 15 loss 1.629554947750712e-05\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9599/10000 (96%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 16 loss 8.489412826984577e-06\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9614/10000 (96%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 17 loss 1.7732623160972291e-06\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9617/10000 (96%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 18 loss 8.597256952599115e-06\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9623/10000 (96%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "True False\n",
            "True False\n",
            "Epoch 19 loss 4.245131924789793e-06\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9626/10000 (96%)\n",
            "\n",
            "0 ----------- 0.0\n",
            "==================TRAIN TASK 1======================\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 0 loss 0.3251435384690762 - unnormilized epoch loss 609.6441346295178\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9331/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9440/10000 (94%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 1 loss 0.17205907517373561 - unnormilized epoch loss 322.6107659507543\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9293/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9568/10000 (96%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 2 loss 0.1337243346368273 - unnormilized epoch loss 250.7331274440512\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9318/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9630/10000 (96%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 3 loss 0.11178362825239697 - unnormilized epoch loss 209.59430297324434\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9341/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9635/10000 (96%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 4 loss 0.09661378742580612 - unnormilized epoch loss 181.15085142338648\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9353/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9685/10000 (97%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 5 loss 0.08483692790195346 - unnormilized epoch loss 159.06923981616274\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9462/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9705/10000 (97%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 6 loss 0.07573678014886875 - unnormilized epoch loss 142.00646277912892\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9399/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9717/10000 (97%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 7 loss 0.06788688823729754 - unnormilized epoch loss 127.28791544493288\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9447/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9734/10000 (97%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 8 loss 0.061371062712495525 - unnormilized epoch loss 115.07074258592911\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9411/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9740/10000 (97%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 9 loss 0.05603373022004962 - unnormilized epoch loss 105.06324416259304\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9429/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9752/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 10 loss 0.05125678149027129 - unnormilized epoch loss 96.10646529425867\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9399/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9762/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 11 loss 0.04729687740604083 - unnormilized epoch loss 88.68164513632655\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9352/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9761/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 12 loss 0.04337933741702388 - unnormilized epoch loss 81.33625765691977\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9402/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9767/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 13 loss 0.04016121309548616 - unnormilized epoch loss 75.30227455403656\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9355/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9760/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 14 loss 0.0372649973316739 - unnormilized epoch loss 69.87186999688856\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9310/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9769/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 15 loss 0.034260013139992954 - unnormilized epoch loss 64.23752463748679\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9314/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9778/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 16 loss 0.03194725580889111 - unnormilized epoch loss 59.90110464167083\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9250/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9784/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 17 loss 0.029731700510531665 - unnormilized epoch loss 55.74693845724687\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9185/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9776/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 18 loss 0.027381317387738576 - unnormilized epoch loss 51.33997010200983\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9237/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9781/10000 (98%)\n",
            "\n",
            "Progress train task 1\n",
            "\n",
            "Epoch 19 loss 0.025819088936845463 - unnormilized epoch loss 48.41079175658524\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9125/10000 (91%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9789/10000 (98%)\n",
            "\n",
            "---- EWC ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Github/agnostic_rl/agent/EWC.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = variable(torch.tensor(x))\n",
            "/content/drive/MyDrive/Github/agnostic_rl/agent/EWC.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  precision_matrices[n].data += ((p.grad.data.clone()**2) / len(self.dataset))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 0; loss 0.00012744448425200562; sum(penalty) = 0.03333541750907898\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9629/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9197/10000 (92%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 1; loss 5.268195419248192e-05; sum(penalty) = 0.004484609700739384\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9626/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9370/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 2; loss 4.0665010434732916e-05; sum(penalty) = 0.0027656839229166508\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9613/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9434/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 3; loss 5.901572856553987e-05; sum(penalty) = 0.0020915288478136063\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9612/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9473/10000 (95%)\n",
            "\n",
            "---- EWC ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Github/agnostic_rl/agent/EWC.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss.backward()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 4; loss 1.772002260030749e-05; sum(penalty) = 0.0017893248004838824\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9616/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9526/10000 (95%)\n",
            "\n",
            "---- EWC ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Github/agnostic_rl/agent/EWC.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output = self.model(x).view(1, -1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 5; loss 5.399183018595223e-05; sum(penalty) = 0.0015479574212804437\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9626/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9547/10000 (95%)\n",
            "\n",
            "---- EWC ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Github/agnostic_rl/agent/EWC.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.model.zero_grad()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 6; loss 2.2110190818638793e-05; sum(penalty) = 0.0013504602247849107\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9624/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9580/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 7; loss 2.4016610297242242e-05; sum(penalty) = 0.0012444672174751759\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9621/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9599/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 8; loss 2.432254408299179e-05; sum(penalty) = 0.001138509251177311\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9622/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9605/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 9; loss 1.654289196735533e-05; sum(penalty) = 0.0010436660377308726\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9617/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9599/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 10; loss 6.0119896430172305e-05; sum(penalty) = 0.000976023031398654\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9629/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9612/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 11; loss 1.1869882372543791e-05; sum(penalty) = 0.000912012008484453\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9629/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9638/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 12; loss 3.690146304226679e-05; sum(penalty) = 0.0008627649513073266\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9628/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9627/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 13; loss 1.3399908298605923e-05; sum(penalty) = 0.0007985485717654228\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9620/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9665/10000 (97%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 14; loss 2.2082335991488798e-05; sum(penalty) = 0.0007400248432531953\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9630/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9628/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 15; loss 2.0245374562763144e-05; sum(penalty) = 0.0007136075291782618\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9629/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9653/10000 (97%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 16; loss 7.213566859590112e-05; sum(penalty) = 0.0006714662304148078\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9637/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9648/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 17; loss 2.317192553324366e-05; sum(penalty) = 0.000630956026725471\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9644/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9630/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 18; loss 2.381025815196883e-05; sum(penalty) = 0.0006329737370833755\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9637/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9650/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 19; loss 2.540724222009464e-05; sum(penalty) = 0.0005820770747959614\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9633/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9659/10000 (97%)\n",
            "\n",
            "0.058312077075242996 ----------- 0.002915603807196021\n",
            "==================TRAIN TASK 2======================\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 0 loss 0.28956363703906535 - unnormilized epoch loss 542.9318194482476\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8167/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9370/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9539/10000 (95%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 1 loss 0.13901255289912223 - unnormilized epoch loss 260.6485366858542\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8320/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9401/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9636/10000 (96%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 2 loss 0.10426925921142101 - unnormilized epoch loss 195.5048610214144\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8559/10000 (86%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9368/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9700/10000 (97%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 3 loss 0.08504014260110755 - unnormilized epoch loss 159.45026737707667\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8419/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9391/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9706/10000 (97%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 4 loss 0.07171167469794551 - unnormilized epoch loss 134.45939005864784\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8495/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9374/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9727/10000 (97%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 5 loss 0.062167907327165206 - unnormilized epoch loss 116.56482623843476\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8289/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9204/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9744/10000 (97%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 6 loss 0.0544063886033992 - unnormilized epoch loss 102.0119786313735\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8635/10000 (86%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9317/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9759/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 7 loss 0.048243673635584614 - unnormilized epoch loss 90.45688806672115\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8432/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9255/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9774/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 8 loss 0.0431834020242095 - unnormilized epoch loss 80.96887879539281\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8559/10000 (86%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9289/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9778/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 9 loss 0.038143628428162386 - unnormilized epoch loss 71.51930330280447\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8666/10000 (87%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9354/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9776/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 10 loss 0.034677795397304 - unnormilized epoch loss 65.020866369945\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8482/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9260/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9782/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 11 loss 0.031370342531738184 - unnormilized epoch loss 58.81939224700909\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8493/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9231/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9785/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 12 loss 0.02854694487620145 - unnormilized epoch loss 53.52552164287772\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8416/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9174/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 13 loss 0.026108256572143485 - unnormilized epoch loss 48.952981072769035\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8551/10000 (86%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9273/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9799/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 14 loss 0.023624189411352078 - unnormilized epoch loss 44.29535514628515\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8519/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9207/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9790/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 15 loss 0.02161843691257139 - unnormilized epoch loss 40.53456921107136\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8424/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9156/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 16 loss 0.01981319698590475 - unnormilized epoch loss 37.1497443485714\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8417/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9163/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 17 loss 0.018342472401478637 - unnormilized epoch loss 34.39213575277245\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8434/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9166/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 18 loss 0.01686199561438213 - unnormilized epoch loss 31.61624177696649\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8390/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9091/10000 (91%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Progress train task 2\n",
            "\n",
            "Epoch 19 loss 0.015557895405683666 - unnormilized epoch loss 29.171053885656875\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8389/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9098/10000 (91%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9805/10000 (98%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 0; loss 0.00018081621378351; sum(penalty) = 0.07153619825839996\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9600/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9134/10000 (91%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 1; loss 8.976580672946106e-05; sum(penalty) = 0.01037214882671833\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9582/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9662/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9303/10000 (93%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 2; loss 0.0001302447906082013; sum(penalty) = 0.005845217499881983\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9605/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9671/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9415/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 3; loss 7.865291208898641e-05; sum(penalty) = 0.0043087312951684\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9599/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9671/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9472/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 4; loss 5.378766536217513e-05; sum(penalty) = 0.003434307174757123\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9586/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9658/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9515/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 5; loss 0.000156605130851688; sum(penalty) = 0.0030214914586395025\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9594/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9663/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9526/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 6; loss 8.610600638107727e-05; sum(penalty) = 0.002689548535272479\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9604/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9664/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9564/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 7; loss 6.314935928554503e-05; sum(penalty) = 0.0024076057597994804\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9588/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9660/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9570/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 8; loss 0.00011385202225526272; sum(penalty) = 0.0022045609075576067\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9586/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9663/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9568/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 9; loss 3.291588774328318e-05; sum(penalty) = 0.002099329838529229\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9590/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9664/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9605/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 10; loss 9.620542387463224e-05; sum(penalty) = 0.0019431206164881587\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9586/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9663/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9623/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 11; loss 8.932154416731774e-05; sum(penalty) = 0.0018248676788061857\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9584/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9671/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9606/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 12; loss 3.7796629232483455e-05; sum(penalty) = 0.0017506266012787819\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9597/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9671/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9635/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 13; loss 3.8684185463855236e-05; sum(penalty) = 0.0016365780029445887\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9590/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9648/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 14; loss 4.7015985238103656e-05; sum(penalty) = 0.0015831689815968275\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9588/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9665/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9648/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 15; loss 0.00010976425015851268; sum(penalty) = 0.0015245059039443731\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9578/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9664/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9673/10000 (97%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 16; loss 3.54250010487724e-05; sum(penalty) = 0.001455593155696988\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9589/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9674/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9666/10000 (97%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 17; loss 1.532230573400824e-05; sum(penalty) = 0.0014033035840839148\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9593/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9676/10000 (97%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 18; loss 6.01512535904926e-05; sum(penalty) = 0.0013519988860934973\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9587/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9666/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9657/10000 (97%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 19; loss 3.270329752252307e-05; sum(penalty) = 0.0013183357659727335\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9601/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9672/10000 (97%)\n",
            "\n",
            "0.1237112283706665 ----------- 0.006185561418533325\n",
            "==================TRAIN TASK 3======================\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 0 loss 0.26088026548897225 - unnormilized epoch loss 489.150497791823\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7377/10000 (74%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8651/10000 (87%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9436/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9550/10000 (96%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 1 loss 0.1220129476470252 - unnormilized epoch loss 228.77427683817223\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7073/10000 (71%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8399/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9302/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9634/10000 (96%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 2 loss 0.09101971736885607 - unnormilized epoch loss 170.66197006660514\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7605/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8570/10000 (86%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9426/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9707/10000 (97%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 3 loss 0.07291720407630006 - unnormilized epoch loss 136.71975764306262\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7691/10000 (77%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8516/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9452/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9727/10000 (97%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 4 loss 0.06041206542874376 - unnormilized epoch loss 113.27262267889455\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8012/10000 (80%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8680/10000 (87%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9500/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9739/10000 (97%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 5 loss 0.05108241060512761 - unnormilized epoch loss 95.77951988461427\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7958/10000 (80%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8536/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9392/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9770/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 6 loss 0.044311049296086036 - unnormilized epoch loss 83.08321743016131\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8117/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8599/10000 (86%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9425/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9756/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 7 loss 0.03841043382504334 - unnormilized epoch loss 72.01956342195626\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8075/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8661/10000 (87%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9452/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9792/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 8 loss 0.03370838436853762 - unnormilized epoch loss 63.20322069100803\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8187/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8711/10000 (87%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9443/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9776/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 9 loss 0.029484589945711195 - unnormilized epoch loss 55.28360614820849\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8196/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8585/10000 (86%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9355/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9798/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 10 loss 0.02606803785916418 - unnormilized epoch loss 48.877570985932834\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8134/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8505/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9375/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9777/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 11 loss 0.023108834893194336 - unnormilized epoch loss 43.32906542473938\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8202/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8378/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9289/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9779/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 12 loss 0.020789623772446066 - unnormilized epoch loss 38.980544573336374\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8153/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8529/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9362/10000 (94%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9797/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 13 loss 0.01891865919221503 - unnormilized epoch loss 35.47248598540318\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8133/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8407/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9325/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 14 loss 0.016868860442036143 - unnormilized epoch loss 31.629113328817766\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8163/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8548/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9340/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9796/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 15 loss 0.015275586287522068 - unnormilized epoch loss 28.641724289103877\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8171/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8536/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9334/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 16 loss 0.013999070397671311 - unnormilized epoch loss 26.24825699563371\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8183/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8473/10000 (85%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9295/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9810/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 17 loss 0.012749462799712395 - unnormilized epoch loss 23.90524274946074\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8100/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8401/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9293/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9811/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 18 loss 0.01158168444315282 - unnormilized epoch loss 21.715658330911538\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8074/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8397/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9252/10000 (93%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9809/10000 (98%)\n",
            "\n",
            "Progress train task 3\n",
            "\n",
            "Epoch 19 loss 0.010715810345113277 - unnormilized epoch loss 20.092144397087395\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8053/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8412/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9239/10000 (92%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9810/10000 (98%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 0; loss 0.0002399817460450455; sum(penalty) = 0.1162915974855423\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9550/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9644/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9690/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 8800/10000 (88%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 1; loss 0.00017904171831104374; sum(penalty) = 0.016943516209721565\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9532/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9635/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9687/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9207/10000 (92%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 2; loss 5.013794162408711e-05; sum(penalty) = 0.009303160011768341\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9505/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9639/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9689/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9325/10000 (93%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 3; loss 0.00010081554189982215; sum(penalty) = 0.006849118508398533\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9518/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9628/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9683/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9391/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 4; loss 0.00015369842616735687; sum(penalty) = 0.005595969036221504\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9528/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9629/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9678/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9451/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 5; loss 4.304255734453263e-05; sum(penalty) = 0.004837592598050833\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9513/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9632/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9677/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9492/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 6; loss 5.652713315748003e-05; sum(penalty) = 0.004294686950743198\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9511/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9625/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9679/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9500/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 7; loss 7.331105967632024e-05; sum(penalty) = 0.003936356399208307\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9495/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9611/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9676/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9515/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 8; loss 0.00011308003568261265; sum(penalty) = 0.003654635278508067\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9495/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9601/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9681/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9542/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 9; loss 2.477128197814904e-05; sum(penalty) = 0.0033640919718891382\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9481/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9597/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9669/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9549/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 10; loss 3.7533477575165715e-05; sum(penalty) = 0.0032330655958503485\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9478/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9597/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9674/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9584/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 11; loss 1.3034467469852838e-05; sum(penalty) = 0.002967079635709524\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9477/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9598/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9676/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9596/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 12; loss 3.839435754727052e-05; sum(penalty) = 0.0028708726167678833\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9463/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9593/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9678/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9582/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 13; loss 7.054424045598537e-05; sum(penalty) = 0.0027758730575442314\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9459/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9589/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9603/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 14; loss 1.468650952955986e-05; sum(penalty) = 0.002625140594318509\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9485/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9663/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9616/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 15; loss 2.899007816559248e-05; sum(penalty) = 0.002526586875319481\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9455/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9658/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9628/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 16; loss 2.1387342263361723e-05; sum(penalty) = 0.002479202812537551\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9469/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9605/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9663/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9631/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 17; loss 2.5760993375828594e-05; sum(penalty) = 0.0023595739621669054\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9460/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9610/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9672/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9643/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 18; loss 1.9591601392069332e-05; sum(penalty) = 0.002284697024151683\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9460/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9612/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9652/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9640/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 19; loss 6.75375904857353e-05; sum(penalty) = 0.002233765786513686\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9447/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9607/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9656/10000 (97%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9663/10000 (97%)\n",
            "\n",
            "0.20142653584480286 ----------- 0.010071326978504658\n",
            "==================TRAIN TASK 4======================\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 0 loss 0.2491240550806125 - unnormilized epoch loss 467.10760327614844\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7448/10000 (74%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8178/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8331/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9484/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9606/10000 (96%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 1 loss 0.11010808787631492 - unnormilized epoch loss 206.45266476809047\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7395/10000 (74%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8084/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8161/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9537/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9665/10000 (97%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 2 loss 0.07987425109346707 - unnormilized epoch loss 149.76422080025077\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7216/10000 (72%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8185/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8053/10000 (81%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9519/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9710/10000 (97%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 3 loss 0.06315979793233176 - unnormilized epoch loss 118.42462112312205\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7624/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8278/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8391/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9614/10000 (96%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 4 loss 0.0516747560095042 - unnormilized epoch loss 96.89016751782037\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7622/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8329/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8191/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9576/10000 (96%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9755/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 5 loss 0.043157741202786565 - unnormilized epoch loss 80.92076475522481\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7624/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8384/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8304/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9573/10000 (96%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9770/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 6 loss 0.036784812198330956 - unnormilized epoch loss 68.97152287187055\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7585/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8288/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8399/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9549/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9788/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 7 loss 0.031661534031045935 - unnormilized epoch loss 59.365376308211125\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7576/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8261/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8297/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9519/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9792/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 8 loss 0.027382708357088267 - unnormilized epoch loss 51.3425781695405\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7454/10000 (75%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8253/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8220/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9547/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 9 loss 0.023825348744448274 - unnormilized epoch loss 44.672528895840514\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7483/10000 (75%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8212/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8349/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9509/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 10 loss 0.021376787121159334 - unnormilized epoch loss 40.08147585217375\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7518/10000 (75%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8284/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8261/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9545/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9810/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 11 loss 0.01909190851749542 - unnormilized epoch loss 35.79732847030391\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7597/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8319/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8291/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9520/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 12 loss 0.01686047872044146 - unnormilized epoch loss 31.61339760082774\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7578/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8277/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8351/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9511/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9816/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 13 loss 0.01489155555649971 - unnormilized epoch loss 27.921666668436956\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7571/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8309/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8393/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9502/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9815/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 14 loss 0.013553862194049483 - unnormilized epoch loss 25.41349161384278\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7639/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8308/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8359/10000 (84%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9515/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 15 loss 0.012129096589609981 - unnormilized epoch loss 22.742056105518714\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7578/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8257/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8301/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9481/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 16 loss 0.011031189561604211 - unnormilized epoch loss 20.683480428007897\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7615/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8287/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8291/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9483/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 17 loss 0.010108811704985177 - unnormilized epoch loss 18.954021946847206\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7509/10000 (75%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8255/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8294/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9451/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 18 loss 0.00930031336307681 - unnormilized epoch loss 17.438087555769016\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7580/10000 (76%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8290/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8209/10000 (82%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9480/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9816/10000 (98%)\n",
            "\n",
            "Progress train task 4\n",
            "\n",
            "Epoch 19 loss 0.008566281647561118 - unnormilized epoch loss 16.061778089177096\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 7663/10000 (77%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8290/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 8282/10000 (83%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9461/10000 (95%)\n",
            "\n",
            "Test task with model_id active_column-1\n",
            "\n",
            "Test set: Accuracy: 9816/10000 (98%)\n",
            "\n",
            "---- EWC ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Github/agnostic_rl/agent/EWC.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss = F.nll_loss(F.log_softmax(output, dim=1), label)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 0; loss 0.0003875599789195257; sum(penalty) = 0.15459688007831573\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9327/10000 (93%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9486/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9624/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9590/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 8703/10000 (87%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 1; loss 0.00014473133010400695; sum(penalty) = 0.025243237614631653\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9334/10000 (93%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9498/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9620/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9601/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9068/10000 (91%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 2; loss 0.0001578364174533936; sum(penalty) = 0.014108195900917053\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9341/10000 (93%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9498/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9609/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9585/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9199/10000 (92%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 3; loss 0.00013661382908730334; sum(penalty) = 0.010365897789597511\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9347/10000 (93%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9482/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9616/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9586/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9269/10000 (93%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 4; loss 6.0173280848414614e-05; sum(penalty) = 0.008593214675784111\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9341/10000 (93%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9501/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9605/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9589/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9320/10000 (93%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 5; loss 0.00014736495561654456; sum(penalty) = 0.007396084256470203\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9355/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9503/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9614/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9593/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9381/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 6; loss 0.00014914579779413782; sum(penalty) = 0.006724991369992495\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9338/10000 (93%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9507/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9600/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9594/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9391/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 7; loss 0.0001500656321211872; sum(penalty) = 0.006092041730880737\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9342/10000 (93%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9499/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9590/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9397/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 8; loss 0.00016605338132794098; sum(penalty) = 0.00585533119738102\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9322/10000 (93%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9510/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9561/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9564/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9435/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 9; loss 8.693326088149692e-05; sum(penalty) = 0.005667481571435928\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9354/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9509/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9581/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9552/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9484/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 10; loss 0.00010635036831865358; sum(penalty) = 0.005185658577829599\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9354/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9516/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9595/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9564/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9478/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 11; loss 0.00020723039596498935; sum(penalty) = 0.004906327463686466\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9355/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9504/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9604/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9597/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9447/10000 (94%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 12; loss 4.661966336972958e-05; sum(penalty) = 0.004768958315253258\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9389/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9528/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9611/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9580/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9512/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 13; loss 0.0001713953498720655; sum(penalty) = 0.0045210206881165504\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9369/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9510/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9593/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9583/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9529/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 14; loss 2.897073585970506e-05; sum(penalty) = 0.004310783464461565\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9414/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9534/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9560/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9530/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 15; loss 6.0609201950516696e-05; sum(penalty) = 0.004195045214146376\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9405/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9527/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9562/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9530/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 16; loss 5.966068969766648e-05; sum(penalty) = 0.004090548027306795\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9422/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9538/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9587/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9550/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9568/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 17; loss 7.721947254747532e-05; sum(penalty) = 0.00393791776150465\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9423/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9537/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9581/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9547/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9552/10000 (96%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 18; loss 2.370801993969755e-05; sum(penalty) = 0.0038185289595276117\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9446/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9551/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9605/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9550/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9543/10000 (95%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 4 with lambda=3000\n",
            "\n",
            "Epoch 19; loss 2.0084196694114805e-05; sum(penalty) = 0.0037600731011480093\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9438/10000 (94%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9543/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9594/10000 (96%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9548/10000 (95%)\n",
            "\n",
            "Test task with model_id kb_column-0\n",
            "\n",
            "Test set: Accuracy: 9559/10000 (96%)\n",
            "\n",
            "0.2881382703781128 ----------- 0.01440691389143467\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "loss_kb, loss_ac, acc_kb, acc_ac = train_PC(3000, epochs, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d9424746",
      "metadata": {
        "id": "d9424746",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def accuracy_plot(x):\n",
        "    for t, v in x.items():\n",
        "        plt.plot(list(range(t * epochs, task_num * epochs)), v)\n",
        "        #plt.yticks(np.arange(0, 1, step=0.2), rotation=20)\n",
        "        plt.xticks(np.arange(0, 100, step=20), rotation=20)\n",
        "    plt.ylim(0.9, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "813baca5",
      "metadata": {
        "id": "813baca5"
      },
      "outputs": [],
      "source": [
        "#print(list(range(0, tasks_num)))\n",
        "def convert(acc):\n",
        "    acc_plot_normal = {}\n",
        "    for i, x in acc.items():\n",
        "        acc_plot_normal[i] = []\n",
        "        for j in x:\n",
        "            acc_plot_normal[i].append(j.cpu().detach().numpy().tolist())\n",
        "    return acc_plot_normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cc935a97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "cc935a97",
        "outputId": "d7b5a495-1600-4fc0-c319-24cdbd0c224e",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ed2707a471a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_ac\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o-r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sgd+activecolumn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_kb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o-g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ewc+kb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "ax1=plt.subplot(2, 2, 1)\n",
        "plt.plot(torch.tensor(acc_ac[0]).numpy(), 'o-r', label=\"sgd+activecolumn\")\n",
        "plt.plot(torch.tensor(acc_kb[0]).numpy(), 'o-g', label=\"ewc+kb\")\n",
        "plt.yticks(np.arange(0, 1, step=0.2), rotation=20)\n",
        "plt.xticks(np.arange(0, 100, step=20), rotation=20)\n",
        "plt.legend()\n",
        "plt.ylim(0.5, 1)\n",
        "\n",
        "ax2=plt.subplot(2, 2, 3)\n",
        "accuracy_plot(convert(acc_kb))\n",
        "\n",
        "ax3=plt.subplot(2, 2, 4, sharey=\"row\")\n",
        "accuracy_plot(convert(acc_ac))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "a52411fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "a52411fa",
        "outputId": "8ac4a903-ce3e-4150-9439-88eed42e435c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.animation as animation\n",
        "fig, ax = plt.subplots()\n",
        "line, = ax.plot(torch.tensor(acc_ac[0]).numpy())\n",
        "\n",
        "def animate(i):\n",
        "    line.set_ydata(torch.tensor(acc_ac[0]).numpy()[i])  # update the data.\n",
        "    return line,\n",
        "\n",
        "ani = animation.FuncAnimation(\n",
        "    fig, animate, interval=20, blit=True, save_count=50)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd49dc5c",
      "metadata": {
        "id": "dd49dc5c"
      },
      "source": [
        "# Only EWC vs. Normal training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "21cf3230",
      "metadata": {
        "id": "21cf3230"
      },
      "outputs": [],
      "source": [
        "def standard_process(epochs, model, use_cuda=True, weight=True):\n",
        "    kb_column = model.addColumn() # net_0\n",
        "    print(model.columns[kb_column])\n",
        "    if torch.cuda.is_available() and use_cuda:\n",
        "        model.cuda()\n",
        "        print(f\"Model on cuda: {next(model.parameters()).is_cuda}\")\n",
        "    optimizer = optim.SGD(params=model.parameters(), lr = 1e-3)\n",
        "\n",
        "    loss, acc = {}, {}\n",
        "    for task_id in range(task_num):\n",
        "        print(f\"========== Task {task_id}\")\n",
        "        loss[task_id] = []\n",
        "        acc[task_id] = []\n",
        "        for epoch in range(epochs):\n",
        "            loss[task_id].append(train_progress(model, kb_column, task_id, device, train_loader[task_id], optimizer, epoch, log_training=False))\n",
        "            for sub_task in range(task_id + 1):\n",
        "                acc[sub_task].append(test(model, kb_column, device, test_loader[sub_task]))\n",
        "        if task_id == 0 and weight:\n",
        "            weight = model.state_dict()\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5d9c1414",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "5d9c1414",
        "outputId": "c7232178-4535-48ad-e0fb-bac428b61995",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7604f99665cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolGen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActorCritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'standard_process' is not defined"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "net = ProgNet(colGen = ActorCritic())\n",
        "loss, acc = standard_process(epochs, net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "8aeaba28",
      "metadata": {
        "id": "8aeaba28"
      },
      "outputs": [],
      "source": [
        "def ewc_process(model, epochs, ewc_lambda, use_cuda=True, weight=None):\n",
        "    kb_column = model.addColumn() # net_0\n",
        "    if torch.cuda.is_available() and use_cuda:\n",
        "        model.cuda()\n",
        "        print(f\"Run model on cuda:{model}\")\n",
        "\n",
        "    optimizer = optim.SGD(params=model.parameters(), lr=1e-3)\n",
        "\n",
        "    loss, acc, ewc = {}, {}, None\n",
        "    for task_id in range(task_num):\n",
        "        print(f\"========== Task {task_id}\")\n",
        "        loss[task_id] = []\n",
        "        acc[task_id] = []\n",
        "        old_penalties = []\n",
        "        penalty = 0\n",
        "\n",
        "        if task_id == 0:\n",
        "            if weight:\n",
        "                model.load_state_dict(weight)\n",
        "            else:\n",
        "                for epoch in range(epochs):\n",
        "                    loss[task_id].append(train_compress_normal(model, None, kb_column, task_id, device, train_loader[task_id], optimizer, epoch, log_training=False))\n",
        "                    acc[task_id].append(test(model, kb_column, device, test_loader[task_id]))\n",
        "\n",
        "        else:\n",
        "            old_tasks = []\n",
        "            for sub_task in range(task_id):\n",
        "              old_tasks = old_tasks + train_loader[sub_task].dataset.get_sample(10000)\n",
        "            print(f\"len of old dataset={len(old_tasks)}\")\n",
        "            old_tasks = random.sample(old_tasks, k=10000)\n",
        "            for epoch in range(epochs):\n",
        "                loss_ewc, pen = train_compress_ewc(model, EWC(model.columns[kb_column], old_tasks), ewc_lambda, None, kb_column, task_id, device, train_loader[task_id], optimizer, epoch, log_training=False)\n",
        "                loss[task_id].append(loss_ewc)\n",
        "                penalty += pen\n",
        "                for sub_task in range(task_id + 1):\n",
        "                    acc[sub_task].append(test(model, kb_column, device, test_loader[sub_task]))\n",
        "                    \n",
        "        old_penalties.append(penalty/epochs)\n",
        "        print(f\"{penalty} ----------- {penalty/epochs}\")\n",
        "                    \n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "73c55c95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73c55c95",
        "outputId": "defcacb8-8199-4a7f-b04f-2bf6d980afc1",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run model on cuda:ProgNet(\n",
            "  (columns): ModuleList(\n",
            "    (0): ProgColumn(\n",
            "      (blocks): ModuleList(\n",
            "        (0): ProgDenseBlock(\n",
            "          (module): Linear(in_features=784, out_features=400, bias=True)\n",
            "          (laterals): ModuleList()\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (1): ProgDenseBlock(\n",
            "          (module): Linear(in_features=400, out_features=400, bias=True)\n",
            "          (laterals): ModuleList()\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (2): ProgDenseBlock(\n",
            "          (module): Linear(in_features=400, out_features=10, bias=True)\n",
            "          (laterals): ModuleList()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "========== Task 0\n",
            "Compress train task 0\n",
            "\n",
            "Epoch 0 loss 0.0011787878505080736\n",
            "Test set: Average loss: 0.0000, Accuracy: 5866/10000 (59%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "Epoch 1 loss 0.0010688821308633652\n",
            "Test set: Average loss: 0.0000, Accuracy: 6788/10000 (68%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "Epoch 2 loss 0.0006600380654128809\n",
            "Test set: Average loss: 0.0000, Accuracy: 7385/10000 (74%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "Epoch 3 loss 0.0005289789796715987\n",
            "Test set: Average loss: 0.0000, Accuracy: 8062/10000 (81%)\n",
            "\n",
            "Compress train task 0\n",
            "\n",
            "Epoch 4 loss 0.0004734008793483775\n",
            "Test set: Average loss: 0.0000, Accuracy: 8389/10000 (84%)\n",
            "\n",
            "0 ----------- 0.0\n",
            "========== Task 1\n",
            "len of old dataset=10000\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 0; loss 0.0006303438441823688; sum(penalty) = 0.047203030437231064\n",
            "Test set: Average loss: 0.0000, Accuracy: 8349/10000 (83%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 7711/10000 (77%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 1; loss 0.00039327579833617457; sum(penalty) = 0.013415881432592869\n",
            "Test set: Average loss: 0.0000, Accuracy: 8357/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8111/10000 (81%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 2; loss 0.0003286743702132441; sum(penalty) = 0.006862320471554995\n",
            "Test set: Average loss: 0.0000, Accuracy: 8367/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8341/10000 (83%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 3; loss 0.0003428614165705066; sum(penalty) = 0.004372579511255026\n",
            "Test set: Average loss: 0.0000, Accuracy: 8367/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8496/10000 (85%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 1 with lambda=3000\n",
            "\n",
            "Epoch 4; loss 0.00035796600180475034; sum(penalty) = 0.0030925730243325233\n",
            "Test set: Average loss: 0.0000, Accuracy: 8368/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8597/10000 (86%)\n",
            "\n",
            "0.07494638860225677 ----------- 0.0149892782792449\n",
            "========== Task 2\n",
            "len of old dataset=20000\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 0; loss 0.0006534559785277298; sum(penalty) = 0.06639956682920456\n",
            "Test set: Average loss: 0.0000, Accuracy: 8312/10000 (83%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8500/10000 (85%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 7629/10000 (76%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 1; loss 0.0004933108899357945; sum(penalty) = 0.014572499319911003\n",
            "Test set: Average loss: 0.0000, Accuracy: 8270/10000 (83%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8505/10000 (85%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8130/10000 (81%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 2; loss 0.00030371566226968156; sum(penalty) = 0.007075456436723471\n",
            "Test set: Average loss: 0.0000, Accuracy: 8241/10000 (82%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8509/10000 (85%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8354/10000 (84%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 3; loss 0.0002621324828818012; sum(penalty) = 0.004407238215208054\n",
            "Test set: Average loss: 0.0000, Accuracy: 8226/10000 (82%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8507/10000 (85%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8484/10000 (85%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 2 with lambda=3000\n",
            "\n",
            "Epoch 4; loss 0.00026112023779259057; sum(penalty) = 0.003076359862461686\n",
            "Test set: Average loss: 0.0000, Accuracy: 8209/10000 (82%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8497/10000 (85%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8574/10000 (86%)\n",
            "\n",
            "0.09553112089633942 ----------- 0.019106224179267883\n",
            "========== Task 3\n",
            "len of old dataset=30000\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 0; loss 0.0007182900997437073; sum(penalty) = 0.10030438005924225\n",
            "Test set: Average loss: 0.0000, Accuracy: 8194/10000 (82%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8405/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8447/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 7526/10000 (75%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 1; loss 0.00040382078334366743; sum(penalty) = 0.01757524348795414\n",
            "Test set: Average loss: 0.0000, Accuracy: 8186/10000 (82%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8433/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8457/10000 (85%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8153/10000 (82%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 2; loss 0.0002918430368088889; sum(penalty) = 0.007829809561371803\n",
            "Test set: Average loss: 0.0000, Accuracy: 8134/10000 (81%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8436/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8454/10000 (85%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8421/10000 (84%)\n",
            "\n",
            "---- EWC ----\n",
            "Compress train task 3 with lambda=3000\n",
            "\n",
            "Epoch 3; loss 0.00029413395213023487; sum(penalty) = 0.004698394797742367\n",
            "Test set: Average loss: 0.0000, Accuracy: 8097/10000 (81%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8420/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8441/10000 (84%)\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 8572/10000 (86%)\n",
            "\n",
            "---- EWC ----\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-0d503308c443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolGen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActorCritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss_ewc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_ewc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mewc_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewc_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-e9cc22b441f8>\u001b[0m in \u001b[0;36mewc_process\u001b[0;34m(model, epochs, ewc_lambda, use_cuda, weight)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_compress_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkb_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkb_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Github/agnostic_rl/agent/EWC.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, dataset)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_matrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_fisher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Github/agnostic_rl/agent/EWC.py\u001b[0m in \u001b[0;36mdiag_fisher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "ewc_lambda = 3000\n",
        "records = {}\n",
        "weight = None\n",
        "\"\"\"for i in range(30):\n",
        "  print(f\"======= {i} with lambda={ewc_lambda} ========\")\n",
        "  records[i] = []\n",
        "  net = ProgNet(colGen = ActorCritic())\n",
        "  loss_ewc, acc_ewc = ewc_process(net, epochs, ewc_lambda)\n",
        "  records[i].append(acc_ewc[0])\n",
        "  weight = net.state_dict()\n",
        "  ewc_lambda += 100\"\"\"\n",
        "\n",
        "net = ProgNet(colGen = ActorCritic())\n",
        "loss_ewc, acc_ewc = ewc_process(net, epochs, ewc_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "rh3fERNs4K_D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "rh3fERNs4K_D",
        "outputId": "b7c930f6-f9ff-412e-98c4-07e83f27e310"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f92038010cf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_ac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-43e11a114448>\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(acc)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0macc_plot_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0macc_plot_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macc_plot_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'cpu'"
          ]
        }
      ],
      "source": [
        "accuracy_plot(convert(loss_ac))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "05b53a42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "05b53a42",
        "outputId": "4d10a43e-2b5d-4877-eade-28e4c7133b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dd3JpNM9oQkBJKw74SwSJBNQEUFBbFai6Ii9Lr2qrVWvbW/6hVtva3V2qoFFApy8bqAqBWpioIgSNnCEvZgCEs2SMi+Z5bv748zhBATGCAwycnn+XjMA+ack3M+Z07yPt/5njPfUVprhBBCtH4WXxcghBCieUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESZwz0JVSC5VSeUqpPU3MV0qpN5RS6UqpXUqpK5q/TCGEEOfiTQt9ETDxLPNvBHp5Hg8Ccy++LCGEEOfrnIGutV4HFJ5lkVuAxdqwCYhQSnVsrgKFEEJ4x68Z1hEPZNZ7nuWZlttwQaXUgxiteIKDg4f27du3GTYvhBBtx7Zt205qrWMam9ccge41rfU8YB5AcnKyTklJuZybF0KIVk8pdbSpec1xl0s20Kne8wTPNCGEEJdRcwT6cuBez90uI4ASrfWPuluEEEJcWufsclFKfQBcDUQrpbKA5wEbgNb6LeAL4CYgHagEfn6pim1LtNYUVzqICLKhlPJ1OUKIVuCcga61nnaO+Rp4pNkqMimtNaXVTvZkl7Arq4Qf8soI8LMQ5O9HkL8Vp1tT63RTWeviUH45acfLKKly8IefDOCeEV18Xb4QohW4rBdFzaba4eJ4STU5JVUcOVnJ/txS9ueWklNcBYBSCq01FbUuKmqcON2nx57vEGbHpTUVNU4qa13YrIoAPysBfha6RAVxU1JH1qblsWr/CQl0IYRXJNDPQ1ZRJZsyCtl6uJAtRwo5fLLijPkhAX707RDKyB7RKAVag1IQ7G8lKMCPiEAb/ePCSIoPJyLIv+7ntNaNdqs8/9kelqZkUet04+8nozQIIc5OAr2BqloXOzOLyS+vodbppsbp4kBuGd+nn6wL8PBAG8O6tuPWIfHERQQSF26nU7sgEiIDG+/vriiAvH1QfAwq/eCwPygLlOZCSSaqNMd47mcHvwDwDwZ7GHeiyHWVcyA1lIEDBkFAyGV+NYQQrYny1VfQtZT70F1uzc7MIr49kMfGQwXszi7B4TrzNQnytzKiexSje0YzumcUvWNCsJQeg+JMcNWAs9YI5OAYCGkPrlo4/B0cWgPHNkFFXtMF+AVCmOeDtc5acFZDbbnxb0O2IAgINR5B0RAaCyEdILoXxA+F2AHg5w9VxVB8FFxOCE8w6rJYTm8DbZw4hBCtjlJqm9Y6ubF5bbKFXlhRy/of8lmbls/atDyKKh34WRQDE8K5b3Q3xkdk06U6jcDidPyLfsCmq7HYIuFEOBwuhJwdUHW20RA8wuKh53gjaNv3hXbdjX4YZw1oF4R2hKAoo1+mIWct1JTy5PzP6eg+zlPDAoxtVpdCTSlUnIQT+yD9W6gtM37GGmC08mtKzlyXNcA4CdSUGScgZYGYfhA/BCK6QEkWFB2B8hNG0NuCwWYHtxNcDtBuCGxnnKxC2kNIrOfkFXt6mn9I4/vhchjvTAoOQUG6sY2aMuPhH2S8NrEDIKIzWG1g8TNqtdrO+7gK0da1mUCvcbpYkZrLe5uPsiOzGK0hMtCPCb1Cub6bjeHt3YQcWw27P4LCDOOH/EMhprcRVuV5cPKgMa3vJIi/Atr18HST+IPbBRX5RmBpN3QdA1E9Gw85b/j5g180HfuNYu53h3ho2PWE2hsJOa2NQM7eBtkp4KiGyC6egPQ35hUfM1r9AaEQEGa0/nN2wIEvjJNEUDS062a09J214Kg0ThynAlap09uoPGns34/qDTS6ik69Ho5qqC4Bx5nXGbDYwB5m1FFdDNsW/XhdQdEw5U3oe9OFvXZCtFGmD/TSagcL1h/mvc1HOVley8AYC7MHHmWkYyMR2WtRB0vh4KmlFXQbC2OehO5XGy1sH98DPqpnFH9fk87mjEKu6x8LQEmlg6AAKzarxagvopPxSPzJ+a1cayPcbYHe/4zbBZUFxgmu/DiU5xtdSuV5xongVLeRzQ72CLCHQ1iccXKL6gVB7U6/plpDaQ6c2AOl2ca63S7Y+R58OA2S74Mb/mC05E+pKoL8g8byEZ0hqgcERp7ffl8Mt9vYdtERKDpsvIvpPdHYx+ZSmguFh4zXtCLfeB2jexmPgNDm244wHdMGusPl5oMtx/jbqh8oqqjmF12OMzNhPTGZX6HSaoxWYL8pRldIYKTxiLvidH92C3FF50jsNgvfp5/kuv6xZOSXc9vcf9M1Kpj37h9OcMCPD6HWmi/3HKfa4eLWIfFNfzBJqfMLcwCL9XQ3CwPOf4cabj883njUl/xz+Pb38O83Ye+nRoseoLbCCLiG7BHGfigrWP3O7A46ddJyVhvLhcUZXV0RnSGyq3GNwVljBHRhBrgdxknIHg61lUY3UUG60WVUmGEs56ppUMAT0GkEdBkFZbnGcmW5EBAOgRHGSSy8k7G9kPbGSawgHUqyofNwGPBTo578g7D+VeNdYmPvgsDooguNM35Po3pC3BDj9zYgxHgHefKgsT/RvSGmj7Hsqf232oz98lZNufEuq7YcHFXGOuufXJviqIKio8aJOmeHp4uyyHgH5x9iND66X2M0moLaeV+POCfTXRStdrj4bGc2q9esIrYklevDshhhTcO/PNP4Axv4MxhwO3S60ginVmD6gs0cL6lm2cOjuHXOBk6W11BR62JE93YsmDEMu+30fqQdL+O/P9vD5sNGH/89Izoz6+ZE/KzGRVGtNW4NVksr+PRpxlpIXWJcbwCjCym6F8T0NYK5JMsIxqKjxoVot8sI24p8KDthvHNQFqM7yM/fCJXKgjO3YfEzWtln42c3rn/UPbpBZDcjoJ01sH857P0n5O2FsARjfmhHIwgrC41uqlMX0E8JCDPCvSDdeB47AE7sNU5Mw+6DntdBcHvj5FRVeDqsizONk0VpNpxMB2fV+b2msUnQfRx0GGi8PiVZxuvlH2yc8Kz+kH8Aju8yuurqs/pD55HGz1cVQ24qHN9tvO4BocaJt6rIqK/uZwKg40DjBFtbbpwkTv5gXOdRFug4yDgZdrrSeG3L86Asx+iy65AEcYON2i4nrY3jVppl1BHiaSDUr8PtgrLjxutXlmucxJxVxr815cZ1Lkel8ZoGRxs/33WMcSPDRTrbRVHTBHp5jZM5a9L5aHMGjzkWcq/fNwDo4PaohGRIvBX63Xz+LdIW4O3vDvHHLw8wpHMEe7JLeP+BERwrqOTJj1K5vn8sL96SyMZDBXx3MJ8Vu3IJtfvx9IQ+ZBZW8dZ3hxjTK5rf3tiPr/cd55Pt2eSX1TB9ZBceHNud6JAAap1uthwuZGdmEX5WC3Y/C4H+VsLsNsIDbbQPs9OzvUlumXTWGC3k4mOebpMjxt1D7boZgWILNMKquti4QBzVy+h6s3jxOQCX03iH0Bi323OiyTXWFxxtvEMpPAx7lsEP3xhhOeoxY543XE4jfHO2G8ET3ctoRfvZ4WQa5KcZAWmzGye16hLj7qvMLadPLv6hRmDVVhrzndVGN1aHgRCbaNTiH2Kc+LK2QvpqyN9vhHv7/kZY24JOX6wPCDt9wovpbSzT8AK3y2nUnL4ajm6ArJSmT0zKYpzAo3oaxyeyi/FuOsBzHSY4yjjp+YcYQeyoNE4cVcXGibCq2FiPX4DxqK00TuqVJ43fgZMHjRNMdYnRwFNWT9dhI3eZWWxGPcpivJM7W0Pg1I0F1SX1llPQZbTRNdr/Fs+73PNn+kA/VlDJ/Yu3UpCXw/vhb9Gneid6xCOokf/ZIvrBL9ae7BImv/k9AK/cPpCfJRuDWy7acJhZn++rWy4yyMbNg+J44rreRAYbH1xaujWT//fpbpxujVIwqkcUkUH+fLE7F38/CyO6R7HtSBFlNWdvpf7upn48MLb7JdpDcVk5qowTWWgHowVZ/+/D7Tr3O9eKAqNF7ud/9uW85XIYLf2SLKOm0I7GSSA31bgQn5tar7urtvF1WGye4DyPPPMPPX0SDGpn7Lt2GSfE8AQjO2xBnmtEJ4xw1m7jxGG1GfMjOhv1+gcZJ02b3VjvqRO71kbjoOgopH1hvJM7mQY3/hmGP3RBL5epA31TRgG/+L9txLmP83HIn7FX5cGUN2DQnc1QZcvgdmtu/vv3jO8Xy6+v733GvBW7csgqquKqntH07xiGpZGulB3HikjNLOaGxA7ERRjvUA7llzP723RSjhYxqkcU1/WLZWSPKJQyPlxV5XBRWuWktNrBOxsO8/W+EyyYkcy1fY23jLVON1/szmVUjyjah9mbbV+rHS5KqxzNuk5hEqe6OapLjNteq0uMlnZFvtFF4hdgtNT9g41rF4GRp09Ypy7W+wcb4R3Yzrie4IvGXt5+owvmAq8fmDbQ1x3M5z8WbWVIZBXvW57H5qyAuz+ChEb3VVygqloXP3v73xw5Wckn/zmK8honv/14N2knyogJDeCte65gaJeLv7iVnlfGg+9u40RJNV//ehzxEa2ve0yIS82UgV5R4+SGv64j1lbJRwG/x1qaBTM+N+4PF80ut6SKW/6+gVqXm5IqBx3C7Dx2bS/mrTtEdnEVs6YkcvfwMwcR25tTwvx1GZTXOOkRE0L3mGDaBQfg1hqtNWGBNnrHhhIdEsBXe47z5NKd2G1WKmtdjO4Zxfx7k+vu0Mkvq+H79HymDIpvHRd0hbhETPlJ0de+OUhhcRErO72JtTAD7l4mYX4JdQwPZN69yTywOIUZI7vy1IQ+hAT4MSmpI48v2cHvPt3Dgu8PM6xLOwZ2CmfNgTxW7c8jNMCPjhF21h08Sa2r8VvxIoNsFFU6GNQpgrfuuYIVqbm89MV+Vu49zsQBHckvq+HOeRs5lF/Bqn15/PWOwTJYmRCNaJUt9N1ZJUyf/RWfRb5Bl6p9MHWxcQeL8AmXW/P+5qOsTcsn5WgRJVUOwgNt3HdVN2aM6kp4oA2XW5NVVElZtROlQKEorKgl7UQZB48bXTePXtsTu82K0+Xm5r9voLCiho8eGsUDi1M4WljB1OROLN54lDG9onl7+lCC/Ftte0SIC2aqLheny83MNz9nVvGz9LAeR/10AfSfcgkqFBfC7dYcKaggNsze6IeevLUzs5hb52wgwM+C1rBw5jBG94xmaUomz3y8i6T4cB4e14OxvWMuajtCtDam6nJZ9s16/qfwSeJsFai7PzI+bSZaDItF0T3m4u9ZH9wpgpmjuvLe5mPMvzeZ0T2Ne7OnJncizG7jt5/s4hfvba+79bJ9aAAhAX4E+htDIliVIsBm4aYBHekc5cWnG4UwgVbXQi9Y+QpBW9/EPvMT4wNDwrS01pRWOQkP+vGgZE6Xm61Hivhm3wn+fegkpVUOyj3f/lT/m6H8rRZmjOrCo9f2IjxQRnAUrZ+pulzQ2rgXtYWNuSJajlPDG5worea1bw7y8fYswgNtXNOnPb1jQ+kdG0JksD82iwWbn6JrVPAZwycI0ZKZK9CFOE97c0p4c3U6qVnF5Jb8+CPdEUE27kjuxD0juhAS4MeatDzWpOUTFezP4+N71X3qVoiWQAJdCI+SKgfpeWWUVjtxujRVDhdf7cll5d4TnPpbcGuIDvGnqNJBmN2P397Uj58NTWh61EohLiMJdCHOIae4iqUpmWgN4/u1Z0BcOAfzynj20z2kHC1icKcIHrmmJ+P7tsdiUdQ4XXyXlk9lrYspg+J+NOSC260bHYYhp7iKjuF2OTmICyaBLsQFcrs1y7Zn8fqqH8gurqJX+xCSEsJZte8EpdXGgGYTEmN5bepgggP8KK9x8tK/9vN5ag5P3tCbGSO7YrEoKmudzFq+l6UpWQzv1o7nJvdnQPx5jE0uhIcEuhAXyeFy869dubz13SGyiqq4oX8sNw+OIyO/gpf+tY++HcJ45Jqe/PHL/WQXV5EYF8ae7FJGdo/ioXHd+f2KfWScrODWIfF8l5ZPYWUttw1J4D+v6UGPZrjNU7QdEuhCNCOt9RldJmvS8vjl+zsoq3HSJSqIv/xsEEO7RLI0JZMXP99HRa2LmNAA/nbHYEb3jKa02sHsNem88/0Ral1uRnRvx13DuzA5qWOj3TRC1CeBLsQllp5XxpoD+dw9ovMZQxJkFlbyyfZs7hremZjQgDN+Jr+sho+2ZfLBlmNkFlbx2xv78tC4Hpe7dNHKSKAL0YK53Zpp8zeRXVzFd09fI6NJirM6W6DLkHVC+JjFopg+sgtZRVWs+6GRL8EWwksS6EK0ADf070B0SADvbTp27oWFaIIEuhAtgL+fhTuGJfDtgRPkFDfxhclCnIMEuhAtxJ3DOqOBD7dm+roU0UpJoAvRQnRqF8TVvWP4cMsxHE18u5MQZyOBLkQLcvfwLuSV1fC7T3fz6Y4s9uaU4HL75k400fq0ui+4EMLMrunbnvF92/PpjmyWpmQBMLpnFPOmJ8s3M4lz8qqFrpSaqJRKU0qlK6WeaWR+Z6XUGqXUDqXULqXUTc1fqhDmZ7UoFswcxr4XJ/LNE2N5dlI/Nh4q4N6FWyipcvi6PNHCnTPQlVJWYDZwI9AfmKaU6t9gsWeBpVrrIcCdwJzmLlSItsRmtdArNpT7x3Rn9l1XsCurmLv/sYnCilpflyZaMG9a6FcC6VrrDK11LfAhcEuDZTQQ5vl/OJDTfCUK0bbdmNSRedOTOXiinCl//55tR4t8XZJoobwJ9Hig/n1UWZ5p9c0C7lFKZQFfAI81tiKl1INKqRSlVEp+vnwiTghvXdO3PUseHAHA1Lc3MntNOm65WCoaaK67XKYBi7TWCcBNwLtKqR+tW2s9T2udrLVOjomJaaZNC9E2DOkcyRePj+HGAR14ZWUajy/Zia/GYhItkzeBng10qvc8wTOtvvuApQBa642AHYhujgKFEKeF2W28OW0IT1zXm89Tc/hke8M/RdGWeRPoW4FeSqluSil/jIueyxsscwwYD6CU6ocR6NKnIsQloJTi0Wt7cmXXdsxavpdsGSpAeJwz0LXWTuBRYCWwH+Nulr1KqReVUlM8iz0JPKCUSgU+AGZqeS8oxCVjtSj+MnUQbq15ammq9KcLQMZDF6JVW7L1GL/5eDc/GRxH+zA71Q4XsWF27rqyM5HB/r4uT1wCZxsPXT56JkQrNjW5E5sPF/LJ9mzsNgt2m5XiSuMr7qaP6MJ9Y7rRPtRet7zWmoUbjrB6/wnemj6UMLvNh9WL5iYtdCFMoP73nB44XsqcNYdYsSsHm9XCHcM68dC4Htj9LDz1USpr0ozLW7Nu7s/M0d18Wba4APIVdEK0QUdOVvDWd4f4eHsWWkOo3Y+KWhfPTurHx9uyKK9xsurX4874wmvR8kmXixBtUNfoYP7004H8cnwv5q3L4EhBBf81oS/948II8vfjqY9S2XiogFE95Q5js5BAF8Lk4iICmTUl8Yxpkwd25A//2se7m45KoJuIjIcuRBtkt1m5I7kTX+87QW7J6fvY3W5NypFCZi3fy42vr2dzRoEPqxTnS1roQrRRdw/vwrz1GXywJZOZo7ry3qajvLf5GMdLq/H3sxAS4Mcj7+/gi19eRfsw406ZGqeLBd8fxu3W9GwfQs/2oXSPDsZikX74lkAuigrRhv38nS1sOVyI062pcboZ2zuGn14Rz7V925NTXM0ts79nUEIE790/nEqHi4cWb2Njg1Z7YlwYz03uz4juUQBUO1z8+9BJYkLsJCWE+2K3TE0uigohGvXQuB5sP1bMzYM6cN9V3egVG1o3r08HGy/9JIknP0rl+eV72Xa0iPS8cl6bOogJiR04lF9OalYJc9ekc+e8TUxIjCXUbmPlnuOU1TgB+MngOJ65sR8dwu3UOF3szSklJiSATu2CfLXLpiYtdCHEWf32k118sCWTYH8rb00fypheZ46UWu1w8Y/1GcxZewirUtyQ2IHJAzuScrSQ+esP42dR9O0Qyp6cUmqdbuw2Cx88MIIhnSN9tEetm9yHLoS4YNUOF29++wM3JXUkMa7pLpSqWhdKGRdcTzlWUMkrX6eRW1zFFV0iSYoP55WVaZTXOPn4F6PoFh18OXbBVCTQhRAtxuGTFfx07r8JCfDj41+MIiY0wNcltSpnC3S5bVEIcVl1iw5mwYxk8sqqeeS97b4ux1Qk0IUQl92QzpH8YlxPthwppKTS4etyTEMCXQjhE0M6RwCwJ6fEx5WYhwS6EMInkuKNC6y7siTQm4sEuhDCJyKD/enULpDd2cW+LsU0JNCFED4zMD6C3dnSQm8uEuhCCJ8ZEB9OZmEVRRW1vi7FFCTQhRA+M9Az1ou00puHBLoQwmcGxEmgNycJdCGEz4QH2egaFcRuudOlWUigCyF8akB8uLTQm4kEuhDCpwYmhJNdXEVBeY2vS2n1JNCFED6VFG98YlRa6RdPAl0I4VMD4sMAzuhH99UosK2dBLoQwqdC7Ta6RweTmlXCqn0nmPr2Rob8/hsy8st9XVqrI4EuhPC5pIRwVu0/wf2LU8gqrERr+OWHO6hxunxdWqsigS6E8Llbh8RzVc9oXr9zMN/91zX8+faB7Mku5dWVab4urVWRL4kWQvjc1X3ac3Wf9nXPJyR2YPqILsxff5jRPaPPmCeaJi10IUSL9LtJ/egTG8pTH6WSdrzM1+W0ChLoQogWyW6zMvvuISiluG3OBlbvP+Hrklo8CXQhRIvVs30oyx8dTfeYEO5fnMLctYfklsazkEAXQrRoHcMDWfrQSG5K6sjLXx1g+oItZBZW+rqsFsmrQFdKTVRKpSml0pVSzzSxzFSl1D6l1F6l1PvNW6YQoi0L9Lfy92lD+MNPBrDjWBET/raOxRuP4HZLa72+cwa6UsoKzAZuBPoD05RS/Rss0wv4LTBaa50I/OoS1CqEaMOUUtwzogsrnxjL0C6R/Pdne3nw3RRKKh11y5RUOVj4/WGOFbTNFrw3LfQrgXStdYbWuhb4ELilwTIPALO11kUAWuu85i1TCCEMCZFBLP6PK3n+5v6sTctn8t/Xs+1oEfPXZTD2z2t4ccU+bp2zgZ2Zbe+7Sr0J9Hggs97zLM+0+noDvZVSG5RSm5RSExtbkVLqQaVUilIqJT8//8IqFkK0eUopfj66G0seGonTpfnp3H/z0hf7Gdwpgvn3JhMUYGXavE2sOdC22pbN9cEiP6AXcDWQAKxTSiVprc84RWqt5wHzAJKTk6XzSwhxUYZ2iWTFY1fx9roMru4Tw6ge0QAM7hTBzxdt4f7FKcwY2ZW7hnemZ/sQH1d76XkT6NlAp3rPEzzT6ssCNmutHcBhpdRBjIDf2ixVCiFEE6JCAvh/N/U7Y1pMaAAfPjiS5/65h8Ubj7Bww2GGdY2kS1QwRRW1FFXWMrJHFL+6rjc26+mOit1ZJdS6XAzt0u4y70XzUOe6p1Mp5QccBMZjBPlW4C6t9d56y0wEpmmtZyilooEdwGCtdUFT601OTtYpKSnNsAtCCNG0/LIaPt6exbJtWVTWOIkM9ifAz8L2Y8UM6xrJ3++6gpAAP15Zmcb/bjyCVSnm3H0FNyR2OGM9WmuUUr7ZiXqUUtu01smNzvPmJn2l1E3A3wArsFBr/ZJS6kUgRWu9XBl7+RdgIuACXtJaf3i2dUqgCyF86bOd2Tzz8W6CA/yw2yxkFVVx78gupGaVsD+nlHn3DuXqPu05cLyUl/61n42HCmgfGkDHiEC6RgVzTd8YxvWOIdRuu6x1X3SgXwoS6EIIX/vhRBm/eG87bq15+acDGda1HSWVDu76xybS88qZOKADn6fmEGq3cdsV8ZRUOcgtrubA8VKKKh34Wy0M6xZJz5gQOkcFkxAZSHigjZAAP8IDbcRFBGK1nG7Va63JKakmxN+P8KALOxFIoAshRBNcbo0CLPWCt7CilmnzNpGeX870EV341XW9iAjyP+Nnth0t4uu9x/n3oQKOFVZSXuP80brtNgu9Y0PpFh1MTnEVB46XUVbt5H9uTeKu4Z0vqF4JdCGEOE8VNU5KqhzERQSec1mtNcWVDrKLqyitclBW46SwopYfTpSTdqKUIycriYuw06dDKH07hHFVz2i6RgdfUF1nC3QZD10IIRoRHOBHcIB3EamUIjLYn8hg/3MvfAnJ4FxCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESEuhCCGESXgW6UmqiUipNKZWulHrmLMv9VCmllVLJzVeiEEIIb5wz0JVSVmA2cCPQH5imlOrfyHKhwOPA5uYuUgghxLl500K/EkjXWmdorWuBD4FbGlnu98DLQHUz1ieEEMJL3gR6PJBZ73mWZ1odpdQVQCet9b/OtiKl1INKqRSlVEp+fv55FyuEEKJpF31RVCllAV4DnjzXslrreVrrZK11ckxMzMVuWgghRD3eBHo20Kne8wTPtFNCgQHAWqXUEWAEsFwujAohxOXlTaBvBXoppboppfyBO4Hlp2ZqrUu01tFa665a667AJmCK1jrlklQshBCiUecMdK21E3gUWAnsB5ZqrfcqpV5USk251AUKIYTwjp83C2mtvwC+aDDtv5tY9uqLL0sIIcT5kk+KCiGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigCyGESUigC4mdA58AAA+QSURBVCGESUigCyGESUigCyGESUigCyGESXgV6EqpiUqpNKVUulLqmUbm/1optU8ptUsptVop1aX5SxVCCHE25wx0pZQVmA3cCPQHpiml+jdYbAeQrLUeCCwD/tzchQohhDg7b1roVwLpWusMrXUt8CFwS/0FtNZrtNaVnqebgITmLVMIIcS5eBPo8UBmvedZnmlNuQ/4srEZSqkHlVIpSqmU/Px876sUQghxTs16UVQpdQ+QDLzS2Hyt9TytdbLWOjkmJqY5Ny2EEG2enxfLZAOd6j1P8Ew7g1LqOuB3wDitdU3zlCeEEMJb3rTQtwK9lFLdlFL+wJ3A8voLKKWGAG8DU7TWec1fphBCiHM5Z6BrrZ3Ao8BKYD+wVGu9Vyn1olJqimexV4AQ4COl1E6l1PImVieEEOIS8abLBa31F8AXDab9d73/X9fMdQkhhDhPXgX65eJwOMjKyqK6utrXpQgfsdvtJCQkYLPZfF2KEK1Oiwr0rKwsQkND6dq1K0opX5cjLjOtNQUFBWRlZdGtWzdflyNEq9OixnKprq4mKipKwryNUkoRFRUl79CEuEAtKtABCfM2To6/EBeuxQW6EEKICyOB3oy6du3KyZMnm329xcXFzJkzp+55Tk4Ot99+e7NvpzFXX301KSkpl2VbQoiLI4F+ia1du5aZM2de1DoaBnpcXBzLli27yMqEEGbTou5yqe+Fz/eyL6e0WdfZPy6M529OPOsyFRUVTJ06laysLFwuF8899xyhoaH8+te/Jjg4mNGjR5ORkcGKFSsoKChg2rRpZGdnM3LkSLTWXtcyf/585s2bR21tLT179uTdd98lKCiIEydO8PDDD5ORkQHA3LlzeeONNzh06BCDBw/m+uuv55FHHmHy5Mns2bOHESNGsGDBAhITjf26+uqrefXVV+nXrx+PPfYYe/bsweFwMGvWLG655RZcLhe/+c1v+Oqrr7BYLDzwwAM89thjrF69mqeeegqn08mwYcOYO3cuAQEBZ9QcEhJCeXk5AMuWLWPFihUsWrSImTNnEhgYyI4dO8jLy2PhwoUsXryYjRs3Mnz4cBYtWlT3848//jgrVqwgMDCQzz77jNjYWK9fMyHE2UkLvYGvvvqKuLg4UlNT2bNnDxMnTuShhx7iyy+/ZNu2bdQfJfKFF17gqquuYu/evdx6660cO3bM6+3cdtttbN26ldTUVPr168eCBQsA+OUvf8m4ceNITU1l+/btJCYm8qc//YkePXqwc+dOXnnlzHHP7rjjDpYuXQpAbm4uubm5JCcn89JLL3HttdeyZcsW1qxZw9NPP01FRQXz5s3jyJEj7Ny5k127dnH33XdTXV3NzJkzWbJkCbt378bpdDJ37tzzet2KiorYuHEjf/3rX5kyZQpPPPEEe/fuZffu3ezcuRMwTpYjRowgNTWVsWPHMn/+/PPahhDi7FpsC/1cLelLJSkpiSeffJLf/OY3TJ48mdDQULp37153X/S0adOYN28eAOvWreOTTz4BYNKkSURGRtatZ/jw4dTU1FBeXk5hYSGDBw8G4OWXX2bChAns2bOHZ599luLiYsrLy5kwYQIA3377LYsXLwbAarUSHh5OUVFRk/VOnTqVG264gRdeeIGlS5fW9a1//fXXLF++nFdffRUwbgk9duwYq1at4uGHH8bPzzj07dq1IzU1lW7dutG7d28AZsyYwezZs/nVr37l9et28803o5QiKSmJ2NhYkpKSAEhMTOTIkSMMHjwYf39/Jk+eDMDQoUP55ptvvF6/EOLcWmyg+0rv3r3Zvn07X3zxBc8++yzjx4+/oPVs3rwZMPrQFy1aVNftcMrMmTP55z//yaBBg1i0aBFr1669oO3Ex8cTFRXFrl27WLJkCW+99RZgfEjn448/pk+fPhe03sbUv6Ww4b3ip7pnLBbLGV01FosFp9MJgM1mq1uH1Wqtmy6EaB7S5dJATk4OQUFB3HPPPTz99NNs2LCBjIwMjhw5AsCSJUvqlh07dizvv/8+AF9++eVZW9INlZWV0bFjRxwOB++9917d9PHjx9d1d7hcLkpKSggNDaWsrKzJdd1xxx38+c9/pqSkhIEDBwIwYcIE3nzzzbp+/R07dgBw/fXX8/bbb9eFaWFhIX369OHIkSOkp6cD8O677zJu3LgfbSc2Npb9+/fjdrv59NNPvd5XIcTlIYHewO7du7nyyisZPHgwL7zwAi+99BJz5sxh4sSJDB06lNDQUMLDwwF4/vnnWbduHYmJiXzyySd07tzZ6+38/ve/Z/jw4YwePZq+ffvWTX/99ddZs2YNSUlJDB06lH379hEVFcXo0aMZMGAATz/99I/Wdfvtt/Phhx8yderUumnPPfccDoeDgQMHkpiYyHPPPQfA/fffT+fOnRk4cCCDBg3i/fffx26388477/Czn/2MpKQkLBYLDz/88I+286c//YnJkyczatQoOnbs6PW+CiEuD3U+d2Y0p+TkZN3w/ub9+/fTr18/n9RzNuXl5YSEhKC15pFHHqFXr1488cQTvi7LtFrq74EQLYFSapvWOrmxedJC98L8+fMZPHgwiYmJlJSU8NBDD/m6JCGE+BG5KOqFJ554QlrkQogWT1roQghhEhLoQghhEhLoQghhEhLoQghhEhLoPhYSEvKjaWvXrq37iLwQQnhLAv0ymTVr1o8+/i+EEM2p5d62+OUzcHx3866zQxLc+KdzLvZ///d/vPHGG9TW1jJ8+HCuvfZaNm/ezGuvvcbrr7/O66+/TkZGBhkZGUyfPp0NGzawdetWHn/8cSoqKggICGD16tWEhoZ6XdrJkye5+eabefbZZwkODqa0tJRJkyaRnp7ONddcw5w5c7BY5PwrhGiaJEQD+/fvZ8mSJWzYsIGdO3ditVqpqalh/fr1AKxfv56oqCiys7NZv349Y8eOpba2ljvuuIPXX3+d1NRUVq1aRWBgoNfbPHHiBJMmTeLFF19k0qRJAGzZsoU333yTffv2cejQobpRHYUQoiktt4XuRUv6Uli9ejXbtm1j2LBhAFRVVdG+fXvKy8spKysjMzOTu+66i3Xr1rF+/Xpuu+020tLS6NixY93PhIWFAca4MNOnTwfg+PHj+Pv787e//a1uO1FRUTgcDsaPH8/s2bPPGBDryiuvpHv37oAxZO/3339/2b52TgjROrXcQPcRrTUzZszgj3/84xnTMzMzeeedd+jTpw9jxoxh4cKFbNy4kb/85S9NfrFFUlJS3Zc7zJo1i65du/7o6+j8/PwYOnQoK1euPCPQ6w9V29hzIYRoSLpcGhg/fjzLli0jLy8PMIaXPXr0KGPGjOHVV19l7NixDBkyhDVr1hAQEEB4eDh9+vQhNzeXrVu3AsbQuN6O9a2UYuHChRw4cICXX365bvqWLVs4fPgwbrebJUuWcNVVVzX/zgohTEVa6A3079+fP/zhD9xwww243W5sNhuzZ89mzJgxZGZmMnbsWKxWK506daob9tbf358lS5bw2GOPUVVVRWBgIKtWrWr0lsTGWK1WPvjgA6ZMmUJoaCj9+/dn2LBhPProo3UXRW+99dZLudtCCBOQ4XNFiyO/B0I0TYbPFUKINkACXQghTKLFBbqvuoBEyyDHX4gL16IC3W63U1BQIH/UbZTWmoKCAux2u69LEaJValF3uSQkJJCVlUV+fr6vSxE+YrfbSUhI8HUZQrRKLSrQbTYb3bp183UZQgjRKnnV5aKUmqiUSlNKpSulnmlkfoBSaoln/malVNfmLlQIIcTZnTPQlVJWYDZwI9AfmKaU6t9gsfuAIq11T+CvwMsIIYS4rLxpoV8JpGutM7TWtcCHwC0NlrkF+F/P/5cB45UMPiKEEJeVN33o8UBmvedZwPCmltFaO5VSJUAUcLL+QkqpB4EHPU/LlVJpF1I0EN1w3W1EW9zvtrjP0Db3uy3uM5z/fndpasZlvSiqtZ4HzLvY9SilUpr66KuZtcX9bov7DG1zv9viPkPz7rc3XS7ZQKd6zxM80xpdRinlB4QDBc1RoBBCCO94E+hbgV5KqW5KKX/gTmB5g2WWAzM8/78d+FbLp4OEEOKyOmeXi6dP/FFgJWAFFmqt9yqlXgRStNbLgQXAu0qpdKAQI/QvpYvutmml2uJ+t8V9hra5321xn6EZ99tnw+cKIYRoXi1qLBchhBAXTgJdCCFMotUF+rmGITADpVQnpdQapdQ+pdRepdTjnuntlFLfKKV+8Pwb6etam5tSyqqU2qGUWuF53s0znES6Z3gJf1/X2NyUUhFKqWVKqQNKqf1KqZFt5Fg/4fn93qOU+kApZTfb8VZKLVRK5Sml9tSb1uixVYY3PPu+Syl1xflur1UFupfDEJiBE3hSa90fGAE84tnPZ4DVWutewGrPc7N5HNhf7/nLwF89w0oUYQwzYTavA19prfsCgzD239THWikVD/wSSNZaD8C44eJOzHe8FwETG0xr6tjeCPTyPB4E5p7vxlpVoOPdMAStntY6V2u93fP/Mow/8HjOHGLhf4Gf+KbCS0MplQBMAv7hea6AazGGkwBz7nM4MBbjTjG01rVa62JMfqw9/IBAz2dXgoBcTHa8tdbrMO78q6+pY3sLsFgbNgERSqmO57O91hbojQ1DEO+jWi4Lz8iVQ4DNQKzWOtcz6zgQ66OyLpW/Af8FuD3Po4BirbXT89yMx7sbkA+84+lq+odSKhiTH2utdTbwKnAMI8hLgG2Y/3hD08f2ovOttQV6m6KUCgE+Bn6ltS6tP8/zwS3T3HOqlJoM5Gmtt/m6lsvMD7gCmKu1HgJU0KB7xWzHGsDTb3wLxgktDgjmx10Tptfcx7a1Bbo3wxCYglLKhhHm72mtP/FMPnHqLZjn3zxf1XcJjAamKKWOYHSlXYvRtxzheUsO5jzeWUCW1nqz5/kyjIA387EGuA44rLXO11o7gE8wfgfMfryh6WN70fnW2gLdm2EIWj1P3/ECYL/W+rV6s+oPsTAD+Oxy13apaK1/q7VO0Fp3xTiu32qt7wbWYAwnASbbZwCt9XEgUynVxzNpPLAPEx9rj2PACKVUkOf3/dR+m/p4ezR1bJcD93rudhkBlNTrmvGO1rpVPYCbgIPAIeB3vq7nEu3jVRhvw3YBOz2PmzD6lFcDPwCrgHa+rvUS7f/VwArP/7sDW4B04CMgwNf1XYL9HQykeI73P4HItnCsgReAA8Ae4F0gwGzHG/gA4xqBA+Pd2H1NHVtAYdzFdwjYjXEH0HltTz76L4QQJtHaulyEEEI0QQJdCCFMQgJdCCFMQgJdCCFMQgJdCCFMQgJdCCFMQgJdCCFM4v8DT+RfbRpJXGQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(torch.tensor(acc_ac[0]).numpy(), label=\"sgd+activecolumn\")\n",
        "plt.plot(torch.tensor(acc_kb[0]).numpy(), label=\"ewc+kb\")\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbab4925",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbab4925",
        "outputId": "a7d67628-2af3-48fe-e7f8-67bdf7bbac9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.1278    , 0.2667    , 0.48659998, 0.58919996, 0.6243    ,\n",
              "       0.6473    , 0.6757    , 0.7043    , 0.7254    , 0.73829997,\n",
              "       0.73149997, 0.72429997, 0.71919996, 0.7143    , 0.7094    ,\n",
              "       0.7075    , 0.70629996, 0.7084    , 0.7089    , 0.71099997,\n",
              "       0.70449996, 0.6994    , 0.6965    , 0.6935    , 0.6969    ,\n",
              "       0.69659996, 0.69659996, 0.7011    , 0.7011    , 0.70559996,\n",
              "       0.7148    , 0.7115    , 0.7119    , 0.7129    , 0.7161    ,\n",
              "       0.71709996, 0.7179    , 0.7173    , 0.7108    , 0.71059996,\n",
              "       0.7306    , 0.7238    , 0.7186    , 0.718     , 0.7204    ,\n",
              "       0.7181    , 0.7165    , 0.7126    , 0.70699996, 0.7043    ],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(acc_ewc[0]).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rA3BC80z-ZKE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA3BC80z-ZKE",
        "outputId": "666b067a-1600-4f77-b534-3dab9c703437"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [[tensor(0.6465, device='cuda:0'),\n",
              "   tensor(0.6742, device='cuda:0'),\n",
              "   tensor(0.7534, device='cuda:0'),\n",
              "   tensor(0.8107, device='cuda:0'),\n",
              "   tensor(0.8396, device='cuda:0'),\n",
              "   tensor(0.8220, device='cuda:0'),\n",
              "   tensor(0.8168, device='cuda:0'),\n",
              "   tensor(0.8097, device='cuda:0'),\n",
              "   tensor(0.8058, device='cuda:0'),\n",
              "   tensor(0.8002, device='cuda:0'),\n",
              "   tensor(0.7844, device='cuda:0'),\n",
              "   tensor(0.7795, device='cuda:0'),\n",
              "   tensor(0.7768, device='cuda:0'),\n",
              "   tensor(0.7735, device='cuda:0'),\n",
              "   tensor(0.7680, device='cuda:0'),\n",
              "   tensor(0.7729, device='cuda:0'),\n",
              "   tensor(0.7690, device='cuda:0'),\n",
              "   tensor(0.7669, device='cuda:0'),\n",
              "   tensor(0.7647, device='cuda:0'),\n",
              "   tensor(0.7676, device='cuda:0'),\n",
              "   tensor(0.7401, device='cuda:0'),\n",
              "   tensor(0.7223, device='cuda:0'),\n",
              "   tensor(0.7249, device='cuda:0'),\n",
              "   tensor(0.7192, device='cuda:0'),\n",
              "   tensor(0.7145, device='cuda:0')]],\n",
              " 1: [[tensor(0.5775, device='cuda:0'),\n",
              "   tensor(0.6984, device='cuda:0'),\n",
              "   tensor(0.7311, device='cuda:0'),\n",
              "   tensor(0.8011, device='cuda:0'),\n",
              "   tensor(0.8351, device='cuda:0'),\n",
              "   tensor(0.8091, device='cuda:0'),\n",
              "   tensor(0.8061, device='cuda:0'),\n",
              "   tensor(0.8039, device='cuda:0'),\n",
              "   tensor(0.7984, device='cuda:0'),\n",
              "   tensor(0.7939, device='cuda:0'),\n",
              "   tensor(0.7864, device='cuda:0'),\n",
              "   tensor(0.7834, device='cuda:0'),\n",
              "   tensor(0.7781, device='cuda:0'),\n",
              "   tensor(0.7755, device='cuda:0'),\n",
              "   tensor(0.7743, device='cuda:0'),\n",
              "   tensor(0.7795, device='cuda:0'),\n",
              "   tensor(0.7750, device='cuda:0'),\n",
              "   tensor(0.7713, device='cuda:0'),\n",
              "   tensor(0.7667, device='cuda:0'),\n",
              "   tensor(0.7642, device='cuda:0'),\n",
              "   tensor(0.7437, device='cuda:0'),\n",
              "   tensor(0.7307, device='cuda:0'),\n",
              "   tensor(0.7240, device='cuda:0'),\n",
              "   tensor(0.7196, device='cuda:0'),\n",
              "   tensor(0.7136, device='cuda:0')]],\n",
              " 2: [[tensor(0.5291, device='cuda:0'),\n",
              "   tensor(0.6587, device='cuda:0'),\n",
              "   tensor(0.7279, device='cuda:0'),\n",
              "   tensor(0.8016, device='cuda:0'),\n",
              "   tensor(0.8274, device='cuda:0'),\n",
              "   tensor(0.8069, device='cuda:0'),\n",
              "   tensor(0.8034, device='cuda:0'),\n",
              "   tensor(0.7999, device='cuda:0'),\n",
              "   tensor(0.7924, device='cuda:0'),\n",
              "   tensor(0.7887, device='cuda:0'),\n",
              "   tensor(0.7862, device='cuda:0'),\n",
              "   tensor(0.7850, device='cuda:0'),\n",
              "   tensor(0.7819, device='cuda:0'),\n",
              "   tensor(0.7793, device='cuda:0'),\n",
              "   tensor(0.7779, device='cuda:0'),\n",
              "   tensor(0.7820, device='cuda:0'),\n",
              "   tensor(0.7776, device='cuda:0'),\n",
              "   tensor(0.7762, device='cuda:0'),\n",
              "   tensor(0.7713, device='cuda:0'),\n",
              "   tensor(0.7679, device='cuda:0'),\n",
              "   tensor(0.7441, device='cuda:0'),\n",
              "   tensor(0.7306, device='cuda:0'),\n",
              "   tensor(0.7223, device='cuda:0'),\n",
              "   tensor(0.7169, device='cuda:0'),\n",
              "   tensor(0.7162, device='cuda:0')]],\n",
              " 3: [[tensor(0.5309, device='cuda:0'),\n",
              "   tensor(0.6914, device='cuda:0'),\n",
              "   tensor(0.7657, device='cuda:0'),\n",
              "   tensor(0.8118, device='cuda:0'),\n",
              "   tensor(0.8398, device='cuda:0'),\n",
              "   tensor(0.8240, device='cuda:0'),\n",
              "   tensor(0.8189, device='cuda:0'),\n",
              "   tensor(0.8153, device='cuda:0'),\n",
              "   tensor(0.8103, device='cuda:0'),\n",
              "   tensor(0.8075, device='cuda:0'),\n",
              "   tensor(0.7993, device='cuda:0'),\n",
              "   tensor(0.7952, device='cuda:0'),\n",
              "   tensor(0.7895, device='cuda:0'),\n",
              "   tensor(0.7863, device='cuda:0'),\n",
              "   tensor(0.7800, device='cuda:0'),\n",
              "   tensor(0.7824, device='cuda:0'),\n",
              "   tensor(0.7819, device='cuda:0'),\n",
              "   tensor(0.7787, device='cuda:0'),\n",
              "   tensor(0.7759, device='cuda:0'),\n",
              "   tensor(0.7775, device='cuda:0'),\n",
              "   tensor(0.7446, device='cuda:0'),\n",
              "   tensor(0.7283, device='cuda:0'),\n",
              "   tensor(0.7223, device='cuda:0'),\n",
              "   tensor(0.7167, device='cuda:0'),\n",
              "   tensor(0.7117, device='cuda:0')]],\n",
              " 4: [[tensor(0.6134, device='cuda:0'),\n",
              "   tensor(0.7042, device='cuda:0'),\n",
              "   tensor(0.7581, device='cuda:0'),\n",
              "   tensor(0.8137, device='cuda:0'),\n",
              "   tensor(0.8396, device='cuda:0'),\n",
              "   tensor(0.8249, device='cuda:0'),\n",
              "   tensor(0.8216, device='cuda:0'),\n",
              "   tensor(0.8181, device='cuda:0'),\n",
              "   tensor(0.8071, device='cuda:0'),\n",
              "   tensor(0.8017, device='cuda:0'),\n",
              "   tensor(0.7913, device='cuda:0'),\n",
              "   tensor(0.7860, device='cuda:0'),\n",
              "   tensor(0.7840, device='cuda:0'),\n",
              "   tensor(0.7811, device='cuda:0'),\n",
              "   tensor(0.7744, device='cuda:0'),\n",
              "   tensor(0.7946, device='cuda:0'),\n",
              "   tensor(0.7918, device='cuda:0'),\n",
              "   tensor(0.7879, device='cuda:0'),\n",
              "   tensor(0.7874, device='cuda:0'),\n",
              "   tensor(0.7834, device='cuda:0'),\n",
              "   tensor(0.7652, device='cuda:0'),\n",
              "   tensor(0.7514, device='cuda:0'),\n",
              "   tensor(0.7436, device='cuda:0'),\n",
              "   tensor(0.7311, device='cuda:0'),\n",
              "   tensor(0.7318, device='cuda:0')]],\n",
              " 5: [[tensor(0.5045, device='cuda:0'),\n",
              "   tensor(0.6717, device='cuda:0'),\n",
              "   tensor(0.7473, device='cuda:0'),\n",
              "   tensor(0.8107, device='cuda:0'),\n",
              "   tensor(0.8414, device='cuda:0'),\n",
              "   tensor(0.8204, device='cuda:0'),\n",
              "   tensor(0.8178, device='cuda:0'),\n",
              "   tensor(0.8134, device='cuda:0'),\n",
              "   tensor(0.8080, device='cuda:0'),\n",
              "   tensor(0.8077, device='cuda:0'),\n",
              "   tensor(0.7946, device='cuda:0'),\n",
              "   tensor(0.7968, device='cuda:0'),\n",
              "   tensor(0.7960, device='cuda:0'),\n",
              "   tensor(0.7935, device='cuda:0'),\n",
              "   tensor(0.7876, device='cuda:0'),\n",
              "   tensor(0.7911, device='cuda:0'),\n",
              "   tensor(0.7882, device='cuda:0'),\n",
              "   tensor(0.7819, device='cuda:0'),\n",
              "   tensor(0.7806, device='cuda:0'),\n",
              "   tensor(0.7800, device='cuda:0'),\n",
              "   tensor(0.7607, device='cuda:0'),\n",
              "   tensor(0.7511, device='cuda:0'),\n",
              "   tensor(0.7483, device='cuda:0'),\n",
              "   tensor(0.7414, device='cuda:0'),\n",
              "   tensor(0.7368, device='cuda:0')]],\n",
              " 6: [[tensor(0.6107, device='cuda:0'),\n",
              "   tensor(0.7168, device='cuda:0'),\n",
              "   tensor(0.7548, device='cuda:0'),\n",
              "   tensor(0.8054, device='cuda:0'),\n",
              "   tensor(0.8345, device='cuda:0'),\n",
              "   tensor(0.8179, device='cuda:0'),\n",
              "   tensor(0.8168, device='cuda:0'),\n",
              "   tensor(0.8140, device='cuda:0'),\n",
              "   tensor(0.8096, device='cuda:0'),\n",
              "   tensor(0.8063, device='cuda:0'),\n",
              "   tensor(0.8002, device='cuda:0'),\n",
              "   tensor(0.7972, device='cuda:0'),\n",
              "   tensor(0.7959, device='cuda:0'),\n",
              "   tensor(0.7942, device='cuda:0'),\n",
              "   tensor(0.7901, device='cuda:0'),\n",
              "   tensor(0.7912, device='cuda:0'),\n",
              "   tensor(0.7881, device='cuda:0'),\n",
              "   tensor(0.7868, device='cuda:0'),\n",
              "   tensor(0.7873, device='cuda:0'),\n",
              "   tensor(0.7846, device='cuda:0'),\n",
              "   tensor(0.7651, device='cuda:0'),\n",
              "   tensor(0.7568, device='cuda:0'),\n",
              "   tensor(0.7478, device='cuda:0'),\n",
              "   tensor(0.7422, device='cuda:0'),\n",
              "   tensor(0.7347, device='cuda:0')]],\n",
              " 7: [[tensor(0.6180, device='cuda:0'),\n",
              "   tensor(0.6424, device='cuda:0'),\n",
              "   tensor(0.7320, device='cuda:0'),\n",
              "   tensor(0.7996, device='cuda:0'),\n",
              "   tensor(0.8365, device='cuda:0'),\n",
              "   tensor(0.8177, device='cuda:0'),\n",
              "   tensor(0.8134, device='cuda:0'),\n",
              "   tensor(0.8110, device='cuda:0'),\n",
              "   tensor(0.8067, device='cuda:0'),\n",
              "   tensor(0.8029, device='cuda:0'),\n",
              "   tensor(0.7980, device='cuda:0'),\n",
              "   tensor(0.7922, device='cuda:0'),\n",
              "   tensor(0.7907, device='cuda:0'),\n",
              "   tensor(0.7902, device='cuda:0'),\n",
              "   tensor(0.7866, device='cuda:0'),\n",
              "   tensor(0.7855, device='cuda:0'),\n",
              "   tensor(0.7838, device='cuda:0'),\n",
              "   tensor(0.7793, device='cuda:0'),\n",
              "   tensor(0.7764, device='cuda:0'),\n",
              "   tensor(0.7745, device='cuda:0'),\n",
              "   tensor(0.7522, device='cuda:0'),\n",
              "   tensor(0.7439, device='cuda:0'),\n",
              "   tensor(0.7396, device='cuda:0'),\n",
              "   tensor(0.7270, device='cuda:0'),\n",
              "   tensor(0.7219, device='cuda:0')]],\n",
              " 8: [[tensor(0.5519, device='cuda:0'),\n",
              "   tensor(0.6575, device='cuda:0'),\n",
              "   tensor(0.7402, device='cuda:0'),\n",
              "   tensor(0.8020, device='cuda:0'),\n",
              "   tensor(0.8380, device='cuda:0'),\n",
              "   tensor(0.8238, device='cuda:0'),\n",
              "   tensor(0.8199, device='cuda:0'),\n",
              "   tensor(0.8172, device='cuda:0'),\n",
              "   tensor(0.8164, device='cuda:0'),\n",
              "   tensor(0.8142, device='cuda:0'),\n",
              "   tensor(0.8072, device='cuda:0'),\n",
              "   tensor(0.8041, device='cuda:0'),\n",
              "   tensor(0.8026, device='cuda:0'),\n",
              "   tensor(0.7994, device='cuda:0'),\n",
              "   tensor(0.7960, device='cuda:0'),\n",
              "   tensor(0.7952, device='cuda:0'),\n",
              "   tensor(0.7926, device='cuda:0'),\n",
              "   tensor(0.7889, device='cuda:0'),\n",
              "   tensor(0.7864, device='cuda:0'),\n",
              "   tensor(0.7835, device='cuda:0'),\n",
              "   tensor(0.7622, device='cuda:0'),\n",
              "   tensor(0.7562, device='cuda:0'),\n",
              "   tensor(0.7492, device='cuda:0'),\n",
              "   tensor(0.7404, device='cuda:0'),\n",
              "   tensor(0.7322, device='cuda:0')]],\n",
              " 9: [[tensor(0.4916, device='cuda:0'),\n",
              "   tensor(0.6362, device='cuda:0'),\n",
              "   tensor(0.7610, device='cuda:0'),\n",
              "   tensor(0.8200, device='cuda:0'),\n",
              "   tensor(0.8448, device='cuda:0'),\n",
              "   tensor(0.8305, device='cuda:0'),\n",
              "   tensor(0.8270, device='cuda:0'),\n",
              "   tensor(0.8236, device='cuda:0'),\n",
              "   tensor(0.8196, device='cuda:0'),\n",
              "   tensor(0.8170, device='cuda:0'),\n",
              "   tensor(0.8097, device='cuda:0'),\n",
              "   tensor(0.8071, device='cuda:0'),\n",
              "   tensor(0.8011, device='cuda:0'),\n",
              "   tensor(0.7987, device='cuda:0'),\n",
              "   tensor(0.7952, device='cuda:0'),\n",
              "   tensor(0.7937, device='cuda:0'),\n",
              "   tensor(0.7888, device='cuda:0'),\n",
              "   tensor(0.7873, device='cuda:0'),\n",
              "   tensor(0.7847, device='cuda:0'),\n",
              "   tensor(0.7816, device='cuda:0'),\n",
              "   tensor(0.7597, device='cuda:0'),\n",
              "   tensor(0.7533, device='cuda:0'),\n",
              "   tensor(0.7456, device='cuda:0'),\n",
              "   tensor(0.7422, device='cuda:0'),\n",
              "   tensor(0.7375, device='cuda:0')]],\n",
              " 10: [[tensor(0.6262, device='cuda:0'),\n",
              "   tensor(0.6840, device='cuda:0'),\n",
              "   tensor(0.7539, device='cuda:0'),\n",
              "   tensor(0.8061, device='cuda:0'),\n",
              "   tensor(0.8363, device='cuda:0'),\n",
              "   tensor(0.8167, device='cuda:0'),\n",
              "   tensor(0.8165, device='cuda:0'),\n",
              "   tensor(0.8170, device='cuda:0'),\n",
              "   tensor(0.8088, device='cuda:0'),\n",
              "   tensor(0.8079, device='cuda:0'),\n",
              "   tensor(0.8090, device='cuda:0'),\n",
              "   tensor(0.8078, device='cuda:0'),\n",
              "   tensor(0.8064, device='cuda:0'),\n",
              "   tensor(0.8072, device='cuda:0'),\n",
              "   tensor(0.8050, device='cuda:0'),\n",
              "   tensor(0.7960, device='cuda:0'),\n",
              "   tensor(0.7926, device='cuda:0'),\n",
              "   tensor(0.7925, device='cuda:0'),\n",
              "   tensor(0.7927, device='cuda:0'),\n",
              "   tensor(0.7924, device='cuda:0'),\n",
              "   tensor(0.7655, device='cuda:0'),\n",
              "   tensor(0.7575, device='cuda:0'),\n",
              "   tensor(0.7525, device='cuda:0'),\n",
              "   tensor(0.7475, device='cuda:0'),\n",
              "   tensor(0.7434, device='cuda:0')]],\n",
              " 11: [[tensor(0.5689, device='cuda:0'),\n",
              "   tensor(0.6753, device='cuda:0'),\n",
              "   tensor(0.7586, device='cuda:0'),\n",
              "   tensor(0.8103, device='cuda:0'),\n",
              "   tensor(0.8390, device='cuda:0'),\n",
              "   tensor(0.8242, device='cuda:0'),\n",
              "   tensor(0.8193, device='cuda:0'),\n",
              "   tensor(0.8189, device='cuda:0'),\n",
              "   tensor(0.8172, device='cuda:0'),\n",
              "   tensor(0.8097, device='cuda:0'),\n",
              "   tensor(0.8061, device='cuda:0'),\n",
              "   tensor(0.8040, device='cuda:0'),\n",
              "   tensor(0.8048, device='cuda:0'),\n",
              "   tensor(0.8032, device='cuda:0'),\n",
              "   tensor(0.8008, device='cuda:0'),\n",
              "   tensor(0.7935, device='cuda:0'),\n",
              "   tensor(0.7893, device='cuda:0'),\n",
              "   tensor(0.7867, device='cuda:0'),\n",
              "   tensor(0.7864, device='cuda:0'),\n",
              "   tensor(0.7834, device='cuda:0'),\n",
              "   tensor(0.7567, device='cuda:0'),\n",
              "   tensor(0.7467, device='cuda:0'),\n",
              "   tensor(0.7436, device='cuda:0'),\n",
              "   tensor(0.7380, device='cuda:0'),\n",
              "   tensor(0.7349, device='cuda:0')]],\n",
              " 12: [[tensor(0.4833, device='cuda:0'),\n",
              "   tensor(0.6708, device='cuda:0'),\n",
              "   tensor(0.7580, device='cuda:0'),\n",
              "   tensor(0.8041, device='cuda:0'),\n",
              "   tensor(0.8351, device='cuda:0'),\n",
              "   tensor(0.8180, device='cuda:0'),\n",
              "   tensor(0.8155, device='cuda:0'),\n",
              "   tensor(0.8160, device='cuda:0'),\n",
              "   tensor(0.8121, device='cuda:0'),\n",
              "   tensor(0.8087, device='cuda:0'),\n",
              "   tensor(0.7990, device='cuda:0'),\n",
              "   tensor(0.7987, device='cuda:0'),\n",
              "   tensor(0.7990, device='cuda:0'),\n",
              "   tensor(0.7950, device='cuda:0'),\n",
              "   tensor(0.7930, device='cuda:0'),\n",
              "   tensor(0.7938, device='cuda:0'),\n",
              "   tensor(0.7945, device='cuda:0'),\n",
              "   tensor(0.7915, device='cuda:0'),\n",
              "   tensor(0.7891, device='cuda:0'),\n",
              "   tensor(0.7855, device='cuda:0'),\n",
              "   tensor(0.7683, device='cuda:0'),\n",
              "   tensor(0.7593, device='cuda:0'),\n",
              "   tensor(0.7540, device='cuda:0'),\n",
              "   tensor(0.7484, device='cuda:0'),\n",
              "   tensor(0.7463, device='cuda:0')]],\n",
              " 13: [[tensor(0.4630, device='cuda:0'),\n",
              "   tensor(0.6692, device='cuda:0'),\n",
              "   tensor(0.7392, device='cuda:0'),\n",
              "   tensor(0.8004, device='cuda:0'),\n",
              "   tensor(0.8305, device='cuda:0'),\n",
              "   tensor(0.8184, device='cuda:0'),\n",
              "   tensor(0.8186, device='cuda:0'),\n",
              "   tensor(0.8134, device='cuda:0'),\n",
              "   tensor(0.8134, device='cuda:0'),\n",
              "   tensor(0.8110, device='cuda:0'),\n",
              "   tensor(0.8020, device='cuda:0'),\n",
              "   tensor(0.7980, device='cuda:0'),\n",
              "   tensor(0.7975, device='cuda:0'),\n",
              "   tensor(0.7945, device='cuda:0'),\n",
              "   tensor(0.7933, device='cuda:0'),\n",
              "   tensor(0.7895, device='cuda:0'),\n",
              "   tensor(0.7859, device='cuda:0'),\n",
              "   tensor(0.7809, device='cuda:0'),\n",
              "   tensor(0.7785, device='cuda:0'),\n",
              "   tensor(0.7771, device='cuda:0'),\n",
              "   tensor(0.7492, device='cuda:0'),\n",
              "   tensor(0.7397, device='cuda:0'),\n",
              "   tensor(0.7264, device='cuda:0'),\n",
              "   tensor(0.7249, device='cuda:0'),\n",
              "   tensor(0.7228, device='cuda:0')]],\n",
              " 14: [[tensor(0.4317, device='cuda:0'),\n",
              "   tensor(0.6027, device='cuda:0'),\n",
              "   tensor(0.7413, device='cuda:0'),\n",
              "   tensor(0.8033, device='cuda:0'),\n",
              "   tensor(0.8322, device='cuda:0'),\n",
              "   tensor(0.8212, device='cuda:0'),\n",
              "   tensor(0.8183, device='cuda:0'),\n",
              "   tensor(0.8159, device='cuda:0'),\n",
              "   tensor(0.8095, device='cuda:0'),\n",
              "   tensor(0.8065, device='cuda:0'),\n",
              "   tensor(0.8039, device='cuda:0'),\n",
              "   tensor(0.8013, device='cuda:0'),\n",
              "   tensor(0.7972, device='cuda:0'),\n",
              "   tensor(0.7966, device='cuda:0'),\n",
              "   tensor(0.7939, device='cuda:0'),\n",
              "   tensor(0.8054, device='cuda:0'),\n",
              "   tensor(0.8021, device='cuda:0'),\n",
              "   tensor(0.7990, device='cuda:0'),\n",
              "   tensor(0.7964, device='cuda:0'),\n",
              "   tensor(0.7963, device='cuda:0'),\n",
              "   tensor(0.7715, device='cuda:0'),\n",
              "   tensor(0.7631, device='cuda:0'),\n",
              "   tensor(0.7551, device='cuda:0'),\n",
              "   tensor(0.7492, device='cuda:0'),\n",
              "   tensor(0.7502, device='cuda:0')]],\n",
              " 15: [[tensor(0.6353, device='cuda:0'),\n",
              "   tensor(0.6930, device='cuda:0'),\n",
              "   tensor(0.7540, device='cuda:0'),\n",
              "   tensor(0.8098, device='cuda:0'),\n",
              "   tensor(0.8404, device='cuda:0'),\n",
              "   tensor(0.8308, device='cuda:0'),\n",
              "   tensor(0.8318, device='cuda:0'),\n",
              "   tensor(0.8300, device='cuda:0'),\n",
              "   tensor(0.8276, device='cuda:0'),\n",
              "   tensor(0.8270, device='cuda:0'),\n",
              "   tensor(0.8139, device='cuda:0'),\n",
              "   tensor(0.8135, device='cuda:0'),\n",
              "   tensor(0.8114, device='cuda:0'),\n",
              "   tensor(0.8095, device='cuda:0'),\n",
              "   tensor(0.8092, device='cuda:0'),\n",
              "   tensor(0.8040, device='cuda:0'),\n",
              "   tensor(0.7997, device='cuda:0'),\n",
              "   tensor(0.7966, device='cuda:0'),\n",
              "   tensor(0.7979, device='cuda:0'),\n",
              "   tensor(0.7956, device='cuda:0'),\n",
              "   tensor(0.7803, device='cuda:0'),\n",
              "   tensor(0.7732, device='cuda:0'),\n",
              "   tensor(0.7673, device='cuda:0'),\n",
              "   tensor(0.7597, device='cuda:0'),\n",
              "   tensor(0.7536, device='cuda:0')]],\n",
              " 16: [[tensor(0.5149, device='cuda:0'),\n",
              "   tensor(0.6923, device='cuda:0'),\n",
              "   tensor(0.7705, device='cuda:0'),\n",
              "   tensor(0.8122, device='cuda:0'),\n",
              "   tensor(0.8391, device='cuda:0'),\n",
              "   tensor(0.8259, device='cuda:0'),\n",
              "   tensor(0.8248, device='cuda:0'),\n",
              "   tensor(0.8225, device='cuda:0'),\n",
              "   tensor(0.8209, device='cuda:0'),\n",
              "   tensor(0.8179, device='cuda:0'),\n",
              "   tensor(0.8093, device='cuda:0'),\n",
              "   tensor(0.8074, device='cuda:0'),\n",
              "   tensor(0.8053, device='cuda:0'),\n",
              "   tensor(0.8046, device='cuda:0'),\n",
              "   tensor(0.8032, device='cuda:0'),\n",
              "   tensor(0.8045, device='cuda:0'),\n",
              "   tensor(0.8016, device='cuda:0'),\n",
              "   tensor(0.8012, device='cuda:0'),\n",
              "   tensor(0.8019, device='cuda:0'),\n",
              "   tensor(0.8003, device='cuda:0'),\n",
              "   tensor(0.7813, device='cuda:0'),\n",
              "   tensor(0.7705, device='cuda:0'),\n",
              "   tensor(0.7664, device='cuda:0'),\n",
              "   tensor(0.7582, device='cuda:0'),\n",
              "   tensor(0.7510, device='cuda:0')]],\n",
              " 17: [[tensor(0.4748, device='cuda:0'),\n",
              "   tensor(0.6718, device='cuda:0'),\n",
              "   tensor(0.7349, device='cuda:0'),\n",
              "   tensor(0.7920, device='cuda:0'),\n",
              "   tensor(0.8281, device='cuda:0'),\n",
              "   tensor(0.8165, device='cuda:0'),\n",
              "   tensor(0.8186, device='cuda:0'),\n",
              "   tensor(0.8165, device='cuda:0'),\n",
              "   tensor(0.8160, device='cuda:0'),\n",
              "   tensor(0.8158, device='cuda:0'),\n",
              "   tensor(0.8056, device='cuda:0'),\n",
              "   tensor(0.8027, device='cuda:0'),\n",
              "   tensor(0.7985, device='cuda:0'),\n",
              "   tensor(0.7985, device='cuda:0'),\n",
              "   tensor(0.7972, device='cuda:0'),\n",
              "   tensor(0.7880, device='cuda:0'),\n",
              "   tensor(0.7847, device='cuda:0'),\n",
              "   tensor(0.7807, device='cuda:0'),\n",
              "   tensor(0.7800, device='cuda:0'),\n",
              "   tensor(0.7783, device='cuda:0'),\n",
              "   tensor(0.7639, device='cuda:0'),\n",
              "   tensor(0.7551, device='cuda:0'),\n",
              "   tensor(0.7470, device='cuda:0'),\n",
              "   tensor(0.7434, device='cuda:0'),\n",
              "   tensor(0.7408, device='cuda:0')]],\n",
              " 18: [[tensor(0.6407, device='cuda:0'),\n",
              "   tensor(0.7220, device='cuda:0'),\n",
              "   tensor(0.7735, device='cuda:0'),\n",
              "   tensor(0.8147, device='cuda:0'),\n",
              "   tensor(0.8386, device='cuda:0'),\n",
              "   tensor(0.8274, device='cuda:0'),\n",
              "   tensor(0.8244, device='cuda:0'),\n",
              "   tensor(0.8224, device='cuda:0'),\n",
              "   tensor(0.8179, device='cuda:0'),\n",
              "   tensor(0.8175, device='cuda:0'),\n",
              "   tensor(0.8160, device='cuda:0'),\n",
              "   tensor(0.8138, device='cuda:0'),\n",
              "   tensor(0.8145, device='cuda:0'),\n",
              "   tensor(0.8124, device='cuda:0'),\n",
              "   tensor(0.8089, device='cuda:0'),\n",
              "   tensor(0.8097, device='cuda:0'),\n",
              "   tensor(0.8104, device='cuda:0'),\n",
              "   tensor(0.8077, device='cuda:0'),\n",
              "   tensor(0.8066, device='cuda:0'),\n",
              "   tensor(0.8045, device='cuda:0'),\n",
              "   tensor(0.7818, device='cuda:0'),\n",
              "   tensor(0.7736, device='cuda:0'),\n",
              "   tensor(0.7690, device='cuda:0'),\n",
              "   tensor(0.7619, device='cuda:0'),\n",
              "   tensor(0.7571, device='cuda:0')]],\n",
              " 19: [[tensor(0.5875, device='cuda:0'),\n",
              "   tensor(0.6898, device='cuda:0'),\n",
              "   tensor(0.7569, device='cuda:0'),\n",
              "   tensor(0.8093, device='cuda:0'),\n",
              "   tensor(0.8401, device='cuda:0'),\n",
              "   tensor(0.8296, device='cuda:0'),\n",
              "   tensor(0.8275, device='cuda:0'),\n",
              "   tensor(0.8269, device='cuda:0'),\n",
              "   tensor(0.8234, device='cuda:0'),\n",
              "   tensor(0.8214, device='cuda:0'),\n",
              "   tensor(0.8139, device='cuda:0'),\n",
              "   tensor(0.8131, device='cuda:0'),\n",
              "   tensor(0.8124, device='cuda:0'),\n",
              "   tensor(0.8120, device='cuda:0'),\n",
              "   tensor(0.8125, device='cuda:0'),\n",
              "   tensor(0.8058, device='cuda:0'),\n",
              "   tensor(0.8050, device='cuda:0'),\n",
              "   tensor(0.8017, device='cuda:0'),\n",
              "   tensor(0.7993, device='cuda:0'),\n",
              "   tensor(0.7983, device='cuda:0'),\n",
              "   tensor(0.7728, device='cuda:0'),\n",
              "   tensor(0.7639, device='cuda:0'),\n",
              "   tensor(0.7561, device='cuda:0'),\n",
              "   tensor(0.7507, device='cuda:0'),\n",
              "   tensor(0.7474, device='cuda:0')]],\n",
              " 20: [[tensor(0.4649, device='cuda:0'),\n",
              "   tensor(0.6647, device='cuda:0'),\n",
              "   tensor(0.7554, device='cuda:0'),\n",
              "   tensor(0.8160, device='cuda:0'),\n",
              "   tensor(0.8422, device='cuda:0'),\n",
              "   tensor(0.8297, device='cuda:0'),\n",
              "   tensor(0.8283, device='cuda:0'),\n",
              "   tensor(0.8252, device='cuda:0'),\n",
              "   tensor(0.8247, device='cuda:0'),\n",
              "   tensor(0.8250, device='cuda:0'),\n",
              "   tensor(0.8142, device='cuda:0'),\n",
              "   tensor(0.8120, device='cuda:0'),\n",
              "   tensor(0.8115, device='cuda:0'),\n",
              "   tensor(0.8092, device='cuda:0'),\n",
              "   tensor(0.8098, device='cuda:0'),\n",
              "   tensor(0.8049, device='cuda:0'),\n",
              "   tensor(0.8038, device='cuda:0'),\n",
              "   tensor(0.8026, device='cuda:0'),\n",
              "   tensor(0.8005, device='cuda:0'),\n",
              "   tensor(0.8006, device='cuda:0'),\n",
              "   tensor(0.7825, device='cuda:0'),\n",
              "   tensor(0.7760, device='cuda:0'),\n",
              "   tensor(0.7696, device='cuda:0'),\n",
              "   tensor(0.7684, device='cuda:0'),\n",
              "   tensor(0.7621, device='cuda:0')]],\n",
              " 21: [[tensor(0.5638, device='cuda:0'),\n",
              "   tensor(0.6533, device='cuda:0'),\n",
              "   tensor(0.7375, device='cuda:0'),\n",
              "   tensor(0.8016, device='cuda:0'),\n",
              "   tensor(0.8399, device='cuda:0'),\n",
              "   tensor(0.8204, device='cuda:0'),\n",
              "   tensor(0.8193, device='cuda:0'),\n",
              "   tensor(0.8217, device='cuda:0'),\n",
              "   tensor(0.8197, device='cuda:0'),\n",
              "   tensor(0.8204, device='cuda:0'),\n",
              "   tensor(0.8068, device='cuda:0'),\n",
              "   tensor(0.8032, device='cuda:0'),\n",
              "   tensor(0.8021, device='cuda:0'),\n",
              "   tensor(0.8015, device='cuda:0'),\n",
              "   tensor(0.8016, device='cuda:0'),\n",
              "   tensor(0.7993, device='cuda:0'),\n",
              "   tensor(0.7968, device='cuda:0'),\n",
              "   tensor(0.7939, device='cuda:0'),\n",
              "   tensor(0.7913, device='cuda:0'),\n",
              "   tensor(0.7906, device='cuda:0'),\n",
              "   tensor(0.7827, device='cuda:0'),\n",
              "   tensor(0.7793, device='cuda:0'),\n",
              "   tensor(0.7739, device='cuda:0'),\n",
              "   tensor(0.7658, device='cuda:0'),\n",
              "   tensor(0.7658, device='cuda:0')]],\n",
              " 22: []}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GO4-Co0Y3dZx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO4-Co0Y3dZx",
        "outputId": "bcec5aae-cbf3-4f1d-9bc3-7b5aac420088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [[tensor(0.6465, device='cuda:0'),\n",
              "   tensor(0.6742, device='cuda:0'),\n",
              "   tensor(0.7534, device='cuda:0'),\n",
              "   tensor(0.8107, device='cuda:0'),\n",
              "   tensor(0.8396, device='cuda:0'),\n",
              "   tensor(0.8220, device='cuda:0'),\n",
              "   tensor(0.8168, device='cuda:0'),\n",
              "   tensor(0.8097, device='cuda:0'),\n",
              "   tensor(0.8058, device='cuda:0'),\n",
              "   tensor(0.8002, device='cuda:0'),\n",
              "   tensor(0.7844, device='cuda:0'),\n",
              "   tensor(0.7795, device='cuda:0'),\n",
              "   tensor(0.7768, device='cuda:0'),\n",
              "   tensor(0.7735, device='cuda:0'),\n",
              "   tensor(0.7680, device='cuda:0'),\n",
              "   tensor(0.7729, device='cuda:0'),\n",
              "   tensor(0.7690, device='cuda:0'),\n",
              "   tensor(0.7669, device='cuda:0'),\n",
              "   tensor(0.7647, device='cuda:0'),\n",
              "   tensor(0.7676, device='cuda:0'),\n",
              "   tensor(0.7401, device='cuda:0'),\n",
              "   tensor(0.7223, device='cuda:0'),\n",
              "   tensor(0.7249, device='cuda:0'),\n",
              "   tensor(0.7192, device='cuda:0'),\n",
              "   tensor(0.7145, device='cuda:0')]],\n",
              " 1: [[tensor(0.5775, device='cuda:0'),\n",
              "   tensor(0.6984, device='cuda:0'),\n",
              "   tensor(0.7311, device='cuda:0'),\n",
              "   tensor(0.8011, device='cuda:0'),\n",
              "   tensor(0.8351, device='cuda:0'),\n",
              "   tensor(0.8091, device='cuda:0'),\n",
              "   tensor(0.8061, device='cuda:0'),\n",
              "   tensor(0.8039, device='cuda:0'),\n",
              "   tensor(0.7984, device='cuda:0'),\n",
              "   tensor(0.7939, device='cuda:0'),\n",
              "   tensor(0.7864, device='cuda:0'),\n",
              "   tensor(0.7834, device='cuda:0'),\n",
              "   tensor(0.7781, device='cuda:0'),\n",
              "   tensor(0.7755, device='cuda:0'),\n",
              "   tensor(0.7743, device='cuda:0'),\n",
              "   tensor(0.7795, device='cuda:0'),\n",
              "   tensor(0.7750, device='cuda:0'),\n",
              "   tensor(0.7713, device='cuda:0'),\n",
              "   tensor(0.7667, device='cuda:0'),\n",
              "   tensor(0.7642, device='cuda:0'),\n",
              "   tensor(0.7437, device='cuda:0'),\n",
              "   tensor(0.7307, device='cuda:0'),\n",
              "   tensor(0.7240, device='cuda:0'),\n",
              "   tensor(0.7196, device='cuda:0'),\n",
              "   tensor(0.7136, device='cuda:0')]],\n",
              " 2: [[tensor(0.5291, device='cuda:0'),\n",
              "   tensor(0.6587, device='cuda:0'),\n",
              "   tensor(0.7279, device='cuda:0'),\n",
              "   tensor(0.8016, device='cuda:0'),\n",
              "   tensor(0.8274, device='cuda:0'),\n",
              "   tensor(0.8069, device='cuda:0'),\n",
              "   tensor(0.8034, device='cuda:0'),\n",
              "   tensor(0.7999, device='cuda:0'),\n",
              "   tensor(0.7924, device='cuda:0'),\n",
              "   tensor(0.7887, device='cuda:0'),\n",
              "   tensor(0.7862, device='cuda:0'),\n",
              "   tensor(0.7850, device='cuda:0'),\n",
              "   tensor(0.7819, device='cuda:0'),\n",
              "   tensor(0.7793, device='cuda:0'),\n",
              "   tensor(0.7779, device='cuda:0'),\n",
              "   tensor(0.7820, device='cuda:0'),\n",
              "   tensor(0.7776, device='cuda:0'),\n",
              "   tensor(0.7762, device='cuda:0'),\n",
              "   tensor(0.7713, device='cuda:0'),\n",
              "   tensor(0.7679, device='cuda:0'),\n",
              "   tensor(0.7441, device='cuda:0'),\n",
              "   tensor(0.7306, device='cuda:0'),\n",
              "   tensor(0.7223, device='cuda:0'),\n",
              "   tensor(0.7169, device='cuda:0'),\n",
              "   tensor(0.7162, device='cuda:0')]],\n",
              " 3: [[tensor(0.5309, device='cuda:0'),\n",
              "   tensor(0.6914, device='cuda:0'),\n",
              "   tensor(0.7657, device='cuda:0'),\n",
              "   tensor(0.8118, device='cuda:0'),\n",
              "   tensor(0.8398, device='cuda:0'),\n",
              "   tensor(0.8240, device='cuda:0'),\n",
              "   tensor(0.8189, device='cuda:0'),\n",
              "   tensor(0.8153, device='cuda:0'),\n",
              "   tensor(0.8103, device='cuda:0'),\n",
              "   tensor(0.8075, device='cuda:0'),\n",
              "   tensor(0.7993, device='cuda:0'),\n",
              "   tensor(0.7952, device='cuda:0'),\n",
              "   tensor(0.7895, device='cuda:0'),\n",
              "   tensor(0.7863, device='cuda:0'),\n",
              "   tensor(0.7800, device='cuda:0'),\n",
              "   tensor(0.7824, device='cuda:0'),\n",
              "   tensor(0.7819, device='cuda:0'),\n",
              "   tensor(0.7787, device='cuda:0'),\n",
              "   tensor(0.7759, device='cuda:0'),\n",
              "   tensor(0.7775, device='cuda:0'),\n",
              "   tensor(0.7446, device='cuda:0'),\n",
              "   tensor(0.7283, device='cuda:0'),\n",
              "   tensor(0.7223, device='cuda:0'),\n",
              "   tensor(0.7167, device='cuda:0'),\n",
              "   tensor(0.7117, device='cuda:0')]],\n",
              " 4: [[tensor(0.6134, device='cuda:0'),\n",
              "   tensor(0.7042, device='cuda:0'),\n",
              "   tensor(0.7581, device='cuda:0'),\n",
              "   tensor(0.8137, device='cuda:0'),\n",
              "   tensor(0.8396, device='cuda:0'),\n",
              "   tensor(0.8249, device='cuda:0'),\n",
              "   tensor(0.8216, device='cuda:0'),\n",
              "   tensor(0.8181, device='cuda:0'),\n",
              "   tensor(0.8071, device='cuda:0'),\n",
              "   tensor(0.8017, device='cuda:0'),\n",
              "   tensor(0.7913, device='cuda:0'),\n",
              "   tensor(0.7860, device='cuda:0'),\n",
              "   tensor(0.7840, device='cuda:0'),\n",
              "   tensor(0.7811, device='cuda:0'),\n",
              "   tensor(0.7744, device='cuda:0'),\n",
              "   tensor(0.7946, device='cuda:0'),\n",
              "   tensor(0.7918, device='cuda:0'),\n",
              "   tensor(0.7879, device='cuda:0'),\n",
              "   tensor(0.7874, device='cuda:0'),\n",
              "   tensor(0.7834, device='cuda:0'),\n",
              "   tensor(0.7652, device='cuda:0'),\n",
              "   tensor(0.7514, device='cuda:0'),\n",
              "   tensor(0.7436, device='cuda:0'),\n",
              "   tensor(0.7311, device='cuda:0'),\n",
              "   tensor(0.7318, device='cuda:0')]],\n",
              " 5: [[tensor(0.5045, device='cuda:0'),\n",
              "   tensor(0.6717, device='cuda:0'),\n",
              "   tensor(0.7473, device='cuda:0'),\n",
              "   tensor(0.8107, device='cuda:0'),\n",
              "   tensor(0.8414, device='cuda:0'),\n",
              "   tensor(0.8204, device='cuda:0'),\n",
              "   tensor(0.8178, device='cuda:0'),\n",
              "   tensor(0.8134, device='cuda:0'),\n",
              "   tensor(0.8080, device='cuda:0'),\n",
              "   tensor(0.8077, device='cuda:0'),\n",
              "   tensor(0.7946, device='cuda:0'),\n",
              "   tensor(0.7968, device='cuda:0'),\n",
              "   tensor(0.7960, device='cuda:0'),\n",
              "   tensor(0.7935, device='cuda:0'),\n",
              "   tensor(0.7876, device='cuda:0'),\n",
              "   tensor(0.7911, device='cuda:0'),\n",
              "   tensor(0.7882, device='cuda:0'),\n",
              "   tensor(0.7819, device='cuda:0'),\n",
              "   tensor(0.7806, device='cuda:0'),\n",
              "   tensor(0.7800, device='cuda:0'),\n",
              "   tensor(0.7607, device='cuda:0'),\n",
              "   tensor(0.7511, device='cuda:0'),\n",
              "   tensor(0.7483, device='cuda:0'),\n",
              "   tensor(0.7414, device='cuda:0'),\n",
              "   tensor(0.7368, device='cuda:0')]],\n",
              " 6: [[tensor(0.6107, device='cuda:0'),\n",
              "   tensor(0.7168, device='cuda:0'),\n",
              "   tensor(0.7548, device='cuda:0'),\n",
              "   tensor(0.8054, device='cuda:0'),\n",
              "   tensor(0.8345, device='cuda:0'),\n",
              "   tensor(0.8179, device='cuda:0'),\n",
              "   tensor(0.8168, device='cuda:0'),\n",
              "   tensor(0.8140, device='cuda:0'),\n",
              "   tensor(0.8096, device='cuda:0'),\n",
              "   tensor(0.8063, device='cuda:0'),\n",
              "   tensor(0.8002, device='cuda:0'),\n",
              "   tensor(0.7972, device='cuda:0'),\n",
              "   tensor(0.7959, device='cuda:0'),\n",
              "   tensor(0.7942, device='cuda:0'),\n",
              "   tensor(0.7901, device='cuda:0'),\n",
              "   tensor(0.7912, device='cuda:0'),\n",
              "   tensor(0.7881, device='cuda:0'),\n",
              "   tensor(0.7868, device='cuda:0'),\n",
              "   tensor(0.7873, device='cuda:0'),\n",
              "   tensor(0.7846, device='cuda:0'),\n",
              "   tensor(0.7651, device='cuda:0'),\n",
              "   tensor(0.7568, device='cuda:0'),\n",
              "   tensor(0.7478, device='cuda:0'),\n",
              "   tensor(0.7422, device='cuda:0'),\n",
              "   tensor(0.7347, device='cuda:0')]],\n",
              " 7: [[tensor(0.6180, device='cuda:0'),\n",
              "   tensor(0.6424, device='cuda:0'),\n",
              "   tensor(0.7320, device='cuda:0'),\n",
              "   tensor(0.7996, device='cuda:0'),\n",
              "   tensor(0.8365, device='cuda:0'),\n",
              "   tensor(0.8177, device='cuda:0'),\n",
              "   tensor(0.8134, device='cuda:0'),\n",
              "   tensor(0.8110, device='cuda:0'),\n",
              "   tensor(0.8067, device='cuda:0'),\n",
              "   tensor(0.8029, device='cuda:0'),\n",
              "   tensor(0.7980, device='cuda:0'),\n",
              "   tensor(0.7922, device='cuda:0'),\n",
              "   tensor(0.7907, device='cuda:0'),\n",
              "   tensor(0.7902, device='cuda:0'),\n",
              "   tensor(0.7866, device='cuda:0'),\n",
              "   tensor(0.7855, device='cuda:0'),\n",
              "   tensor(0.7838, device='cuda:0'),\n",
              "   tensor(0.7793, device='cuda:0'),\n",
              "   tensor(0.7764, device='cuda:0'),\n",
              "   tensor(0.7745, device='cuda:0'),\n",
              "   tensor(0.7522, device='cuda:0'),\n",
              "   tensor(0.7439, device='cuda:0'),\n",
              "   tensor(0.7396, device='cuda:0'),\n",
              "   tensor(0.7270, device='cuda:0'),\n",
              "   tensor(0.7219, device='cuda:0')]],\n",
              " 8: [[tensor(0.5519, device='cuda:0'),\n",
              "   tensor(0.6575, device='cuda:0'),\n",
              "   tensor(0.7402, device='cuda:0'),\n",
              "   tensor(0.8020, device='cuda:0'),\n",
              "   tensor(0.8380, device='cuda:0'),\n",
              "   tensor(0.8238, device='cuda:0'),\n",
              "   tensor(0.8199, device='cuda:0'),\n",
              "   tensor(0.8172, device='cuda:0'),\n",
              "   tensor(0.8164, device='cuda:0'),\n",
              "   tensor(0.8142, device='cuda:0'),\n",
              "   tensor(0.8072, device='cuda:0'),\n",
              "   tensor(0.8041, device='cuda:0'),\n",
              "   tensor(0.8026, device='cuda:0'),\n",
              "   tensor(0.7994, device='cuda:0'),\n",
              "   tensor(0.7960, device='cuda:0'),\n",
              "   tensor(0.7952, device='cuda:0'),\n",
              "   tensor(0.7926, device='cuda:0'),\n",
              "   tensor(0.7889, device='cuda:0'),\n",
              "   tensor(0.7864, device='cuda:0'),\n",
              "   tensor(0.7835, device='cuda:0'),\n",
              "   tensor(0.7622, device='cuda:0'),\n",
              "   tensor(0.7562, device='cuda:0'),\n",
              "   tensor(0.7492, device='cuda:0'),\n",
              "   tensor(0.7404, device='cuda:0'),\n",
              "   tensor(0.7322, device='cuda:0')]],\n",
              " 9: [[tensor(0.4916, device='cuda:0'),\n",
              "   tensor(0.6362, device='cuda:0'),\n",
              "   tensor(0.7610, device='cuda:0'),\n",
              "   tensor(0.8200, device='cuda:0'),\n",
              "   tensor(0.8448, device='cuda:0'),\n",
              "   tensor(0.8305, device='cuda:0'),\n",
              "   tensor(0.8270, device='cuda:0'),\n",
              "   tensor(0.8236, device='cuda:0'),\n",
              "   tensor(0.8196, device='cuda:0'),\n",
              "   tensor(0.8170, device='cuda:0'),\n",
              "   tensor(0.8097, device='cuda:0'),\n",
              "   tensor(0.8071, device='cuda:0'),\n",
              "   tensor(0.8011, device='cuda:0'),\n",
              "   tensor(0.7987, device='cuda:0'),\n",
              "   tensor(0.7952, device='cuda:0'),\n",
              "   tensor(0.7937, device='cuda:0'),\n",
              "   tensor(0.7888, device='cuda:0'),\n",
              "   tensor(0.7873, device='cuda:0'),\n",
              "   tensor(0.7847, device='cuda:0'),\n",
              "   tensor(0.7816, device='cuda:0'),\n",
              "   tensor(0.7597, device='cuda:0'),\n",
              "   tensor(0.7533, device='cuda:0'),\n",
              "   tensor(0.7456, device='cuda:0'),\n",
              "   tensor(0.7422, device='cuda:0'),\n",
              "   tensor(0.7375, device='cuda:0')]],\n",
              " 10: [[tensor(0.6262, device='cuda:0'),\n",
              "   tensor(0.6840, device='cuda:0'),\n",
              "   tensor(0.7539, device='cuda:0'),\n",
              "   tensor(0.8061, device='cuda:0'),\n",
              "   tensor(0.8363, device='cuda:0'),\n",
              "   tensor(0.8167, device='cuda:0'),\n",
              "   tensor(0.8165, device='cuda:0'),\n",
              "   tensor(0.8170, device='cuda:0'),\n",
              "   tensor(0.8088, device='cuda:0'),\n",
              "   tensor(0.8079, device='cuda:0'),\n",
              "   tensor(0.8090, device='cuda:0'),\n",
              "   tensor(0.8078, device='cuda:0'),\n",
              "   tensor(0.8064, device='cuda:0'),\n",
              "   tensor(0.8072, device='cuda:0'),\n",
              "   tensor(0.8050, device='cuda:0'),\n",
              "   tensor(0.7960, device='cuda:0'),\n",
              "   tensor(0.7926, device='cuda:0'),\n",
              "   tensor(0.7925, device='cuda:0'),\n",
              "   tensor(0.7927, device='cuda:0'),\n",
              "   tensor(0.7924, device='cuda:0'),\n",
              "   tensor(0.7655, device='cuda:0'),\n",
              "   tensor(0.7575, device='cuda:0'),\n",
              "   tensor(0.7525, device='cuda:0'),\n",
              "   tensor(0.7475, device='cuda:0'),\n",
              "   tensor(0.7434, device='cuda:0')]],\n",
              " 11: [[tensor(0.5689, device='cuda:0'),\n",
              "   tensor(0.6753, device='cuda:0'),\n",
              "   tensor(0.7586, device='cuda:0'),\n",
              "   tensor(0.8103, device='cuda:0'),\n",
              "   tensor(0.8390, device='cuda:0'),\n",
              "   tensor(0.8242, device='cuda:0'),\n",
              "   tensor(0.8193, device='cuda:0'),\n",
              "   tensor(0.8189, device='cuda:0'),\n",
              "   tensor(0.8172, device='cuda:0'),\n",
              "   tensor(0.8097, device='cuda:0'),\n",
              "   tensor(0.8061, device='cuda:0'),\n",
              "   tensor(0.8040, device='cuda:0'),\n",
              "   tensor(0.8048, device='cuda:0'),\n",
              "   tensor(0.8032, device='cuda:0'),\n",
              "   tensor(0.8008, device='cuda:0'),\n",
              "   tensor(0.7935, device='cuda:0'),\n",
              "   tensor(0.7893, device='cuda:0'),\n",
              "   tensor(0.7867, device='cuda:0'),\n",
              "   tensor(0.7864, device='cuda:0'),\n",
              "   tensor(0.7834, device='cuda:0'),\n",
              "   tensor(0.7567, device='cuda:0'),\n",
              "   tensor(0.7467, device='cuda:0'),\n",
              "   tensor(0.7436, device='cuda:0'),\n",
              "   tensor(0.7380, device='cuda:0'),\n",
              "   tensor(0.7349, device='cuda:0')]],\n",
              " 12: [[tensor(0.4833, device='cuda:0'),\n",
              "   tensor(0.6708, device='cuda:0'),\n",
              "   tensor(0.7580, device='cuda:0'),\n",
              "   tensor(0.8041, device='cuda:0'),\n",
              "   tensor(0.8351, device='cuda:0'),\n",
              "   tensor(0.8180, device='cuda:0'),\n",
              "   tensor(0.8155, device='cuda:0'),\n",
              "   tensor(0.8160, device='cuda:0'),\n",
              "   tensor(0.8121, device='cuda:0'),\n",
              "   tensor(0.8087, device='cuda:0'),\n",
              "   tensor(0.7990, device='cuda:0'),\n",
              "   tensor(0.7987, device='cuda:0'),\n",
              "   tensor(0.7990, device='cuda:0'),\n",
              "   tensor(0.7950, device='cuda:0'),\n",
              "   tensor(0.7930, device='cuda:0'),\n",
              "   tensor(0.7938, device='cuda:0'),\n",
              "   tensor(0.7945, device='cuda:0'),\n",
              "   tensor(0.7915, device='cuda:0'),\n",
              "   tensor(0.7891, device='cuda:0'),\n",
              "   tensor(0.7855, device='cuda:0'),\n",
              "   tensor(0.7683, device='cuda:0'),\n",
              "   tensor(0.7593, device='cuda:0'),\n",
              "   tensor(0.7540, device='cuda:0'),\n",
              "   tensor(0.7484, device='cuda:0'),\n",
              "   tensor(0.7463, device='cuda:0')]],\n",
              " 13: [[tensor(0.4630, device='cuda:0'),\n",
              "   tensor(0.6692, device='cuda:0'),\n",
              "   tensor(0.7392, device='cuda:0'),\n",
              "   tensor(0.8004, device='cuda:0'),\n",
              "   tensor(0.8305, device='cuda:0'),\n",
              "   tensor(0.8184, device='cuda:0'),\n",
              "   tensor(0.8186, device='cuda:0'),\n",
              "   tensor(0.8134, device='cuda:0'),\n",
              "   tensor(0.8134, device='cuda:0'),\n",
              "   tensor(0.8110, device='cuda:0'),\n",
              "   tensor(0.8020, device='cuda:0'),\n",
              "   tensor(0.7980, device='cuda:0'),\n",
              "   tensor(0.7975, device='cuda:0'),\n",
              "   tensor(0.7945, device='cuda:0'),\n",
              "   tensor(0.7933, device='cuda:0'),\n",
              "   tensor(0.7895, device='cuda:0'),\n",
              "   tensor(0.7859, device='cuda:0'),\n",
              "   tensor(0.7809, device='cuda:0'),\n",
              "   tensor(0.7785, device='cuda:0'),\n",
              "   tensor(0.7771, device='cuda:0'),\n",
              "   tensor(0.7492, device='cuda:0'),\n",
              "   tensor(0.7397, device='cuda:0'),\n",
              "   tensor(0.7264, device='cuda:0'),\n",
              "   tensor(0.7249, device='cuda:0'),\n",
              "   tensor(0.7228, device='cuda:0')]],\n",
              " 14: [[tensor(0.4317, device='cuda:0'),\n",
              "   tensor(0.6027, device='cuda:0'),\n",
              "   tensor(0.7413, device='cuda:0'),\n",
              "   tensor(0.8033, device='cuda:0'),\n",
              "   tensor(0.8322, device='cuda:0'),\n",
              "   tensor(0.8212, device='cuda:0'),\n",
              "   tensor(0.8183, device='cuda:0'),\n",
              "   tensor(0.8159, device='cuda:0'),\n",
              "   tensor(0.8095, device='cuda:0'),\n",
              "   tensor(0.8065, device='cuda:0'),\n",
              "   tensor(0.8039, device='cuda:0'),\n",
              "   tensor(0.8013, device='cuda:0'),\n",
              "   tensor(0.7972, device='cuda:0'),\n",
              "   tensor(0.7966, device='cuda:0'),\n",
              "   tensor(0.7939, device='cuda:0'),\n",
              "   tensor(0.8054, device='cuda:0'),\n",
              "   tensor(0.8021, device='cuda:0'),\n",
              "   tensor(0.7990, device='cuda:0'),\n",
              "   tensor(0.7964, device='cuda:0'),\n",
              "   tensor(0.7963, device='cuda:0'),\n",
              "   tensor(0.7715, device='cuda:0'),\n",
              "   tensor(0.7631, device='cuda:0'),\n",
              "   tensor(0.7551, device='cuda:0'),\n",
              "   tensor(0.7492, device='cuda:0'),\n",
              "   tensor(0.7502, device='cuda:0')]],\n",
              " 15: [[tensor(0.6353, device='cuda:0'),\n",
              "   tensor(0.6930, device='cuda:0'),\n",
              "   tensor(0.7540, device='cuda:0'),\n",
              "   tensor(0.8098, device='cuda:0'),\n",
              "   tensor(0.8404, device='cuda:0'),\n",
              "   tensor(0.8308, device='cuda:0'),\n",
              "   tensor(0.8318, device='cuda:0'),\n",
              "   tensor(0.8300, device='cuda:0'),\n",
              "   tensor(0.8276, device='cuda:0'),\n",
              "   tensor(0.8270, device='cuda:0'),\n",
              "   tensor(0.8139, device='cuda:0'),\n",
              "   tensor(0.8135, device='cuda:0'),\n",
              "   tensor(0.8114, device='cuda:0'),\n",
              "   tensor(0.8095, device='cuda:0'),\n",
              "   tensor(0.8092, device='cuda:0'),\n",
              "   tensor(0.8040, device='cuda:0'),\n",
              "   tensor(0.7997, device='cuda:0'),\n",
              "   tensor(0.7966, device='cuda:0'),\n",
              "   tensor(0.7979, device='cuda:0'),\n",
              "   tensor(0.7956, device='cuda:0'),\n",
              "   tensor(0.7803, device='cuda:0'),\n",
              "   tensor(0.7732, device='cuda:0'),\n",
              "   tensor(0.7673, device='cuda:0'),\n",
              "   tensor(0.7597, device='cuda:0'),\n",
              "   tensor(0.7536, device='cuda:0')]],\n",
              " 16: [[tensor(0.5149, device='cuda:0'),\n",
              "   tensor(0.6923, device='cuda:0'),\n",
              "   tensor(0.7705, device='cuda:0'),\n",
              "   tensor(0.8122, device='cuda:0'),\n",
              "   tensor(0.8391, device='cuda:0'),\n",
              "   tensor(0.8259, device='cuda:0'),\n",
              "   tensor(0.8248, device='cuda:0'),\n",
              "   tensor(0.8225, device='cuda:0'),\n",
              "   tensor(0.8209, device='cuda:0'),\n",
              "   tensor(0.8179, device='cuda:0'),\n",
              "   tensor(0.8093, device='cuda:0'),\n",
              "   tensor(0.8074, device='cuda:0'),\n",
              "   tensor(0.8053, device='cuda:0'),\n",
              "   tensor(0.8046, device='cuda:0'),\n",
              "   tensor(0.8032, device='cuda:0'),\n",
              "   tensor(0.8045, device='cuda:0'),\n",
              "   tensor(0.8016, device='cuda:0'),\n",
              "   tensor(0.8012, device='cuda:0'),\n",
              "   tensor(0.8019, device='cuda:0'),\n",
              "   tensor(0.8003, device='cuda:0'),\n",
              "   tensor(0.7813, device='cuda:0'),\n",
              "   tensor(0.7705, device='cuda:0'),\n",
              "   tensor(0.7664, device='cuda:0'),\n",
              "   tensor(0.7582, device='cuda:0'),\n",
              "   tensor(0.7510, device='cuda:0')]],\n",
              " 17: [[tensor(0.4748, device='cuda:0'),\n",
              "   tensor(0.6718, device='cuda:0'),\n",
              "   tensor(0.7349, device='cuda:0'),\n",
              "   tensor(0.7920, device='cuda:0'),\n",
              "   tensor(0.8281, device='cuda:0'),\n",
              "   tensor(0.8165, device='cuda:0'),\n",
              "   tensor(0.8186, device='cuda:0'),\n",
              "   tensor(0.8165, device='cuda:0'),\n",
              "   tensor(0.8160, device='cuda:0'),\n",
              "   tensor(0.8158, device='cuda:0'),\n",
              "   tensor(0.8056, device='cuda:0'),\n",
              "   tensor(0.8027, device='cuda:0'),\n",
              "   tensor(0.7985, device='cuda:0'),\n",
              "   tensor(0.7985, device='cuda:0'),\n",
              "   tensor(0.7972, device='cuda:0'),\n",
              "   tensor(0.7880, device='cuda:0'),\n",
              "   tensor(0.7847, device='cuda:0'),\n",
              "   tensor(0.7807, device='cuda:0'),\n",
              "   tensor(0.7800, device='cuda:0'),\n",
              "   tensor(0.7783, device='cuda:0'),\n",
              "   tensor(0.7639, device='cuda:0'),\n",
              "   tensor(0.7551, device='cuda:0'),\n",
              "   tensor(0.7470, device='cuda:0'),\n",
              "   tensor(0.7434, device='cuda:0'),\n",
              "   tensor(0.7408, device='cuda:0')]],\n",
              " 18: [[tensor(0.6407, device='cuda:0'),\n",
              "   tensor(0.7220, device='cuda:0'),\n",
              "   tensor(0.7735, device='cuda:0'),\n",
              "   tensor(0.8147, device='cuda:0'),\n",
              "   tensor(0.8386, device='cuda:0'),\n",
              "   tensor(0.8274, device='cuda:0'),\n",
              "   tensor(0.8244, device='cuda:0'),\n",
              "   tensor(0.8224, device='cuda:0'),\n",
              "   tensor(0.8179, device='cuda:0'),\n",
              "   tensor(0.8175, device='cuda:0'),\n",
              "   tensor(0.8160, device='cuda:0'),\n",
              "   tensor(0.8138, device='cuda:0'),\n",
              "   tensor(0.8145, device='cuda:0'),\n",
              "   tensor(0.8124, device='cuda:0'),\n",
              "   tensor(0.8089, device='cuda:0'),\n",
              "   tensor(0.8097, device='cuda:0'),\n",
              "   tensor(0.8104, device='cuda:0'),\n",
              "   tensor(0.8077, device='cuda:0'),\n",
              "   tensor(0.8066, device='cuda:0'),\n",
              "   tensor(0.8045, device='cuda:0'),\n",
              "   tensor(0.7818, device='cuda:0'),\n",
              "   tensor(0.7736, device='cuda:0'),\n",
              "   tensor(0.7690, device='cuda:0'),\n",
              "   tensor(0.7619, device='cuda:0'),\n",
              "   tensor(0.7571, device='cuda:0')]],\n",
              " 19: [[tensor(0.5875, device='cuda:0'),\n",
              "   tensor(0.6898, device='cuda:0'),\n",
              "   tensor(0.7569, device='cuda:0'),\n",
              "   tensor(0.8093, device='cuda:0'),\n",
              "   tensor(0.8401, device='cuda:0'),\n",
              "   tensor(0.8296, device='cuda:0'),\n",
              "   tensor(0.8275, device='cuda:0'),\n",
              "   tensor(0.8269, device='cuda:0'),\n",
              "   tensor(0.8234, device='cuda:0'),\n",
              "   tensor(0.8214, device='cuda:0'),\n",
              "   tensor(0.8139, device='cuda:0'),\n",
              "   tensor(0.8131, device='cuda:0'),\n",
              "   tensor(0.8124, device='cuda:0'),\n",
              "   tensor(0.8120, device='cuda:0'),\n",
              "   tensor(0.8125, device='cuda:0'),\n",
              "   tensor(0.8058, device='cuda:0'),\n",
              "   tensor(0.8050, device='cuda:0'),\n",
              "   tensor(0.8017, device='cuda:0'),\n",
              "   tensor(0.7993, device='cuda:0'),\n",
              "   tensor(0.7983, device='cuda:0'),\n",
              "   tensor(0.7728, device='cuda:0'),\n",
              "   tensor(0.7639, device='cuda:0'),\n",
              "   tensor(0.7561, device='cuda:0'),\n",
              "   tensor(0.7507, device='cuda:0'),\n",
              "   tensor(0.7474, device='cuda:0')]],\n",
              " 20: [[tensor(0.4649, device='cuda:0'),\n",
              "   tensor(0.6647, device='cuda:0'),\n",
              "   tensor(0.7554, device='cuda:0'),\n",
              "   tensor(0.8160, device='cuda:0'),\n",
              "   tensor(0.8422, device='cuda:0'),\n",
              "   tensor(0.8297, device='cuda:0'),\n",
              "   tensor(0.8283, device='cuda:0'),\n",
              "   tensor(0.8252, device='cuda:0'),\n",
              "   tensor(0.8247, device='cuda:0'),\n",
              "   tensor(0.8250, device='cuda:0'),\n",
              "   tensor(0.8142, device='cuda:0'),\n",
              "   tensor(0.8120, device='cuda:0'),\n",
              "   tensor(0.8115, device='cuda:0'),\n",
              "   tensor(0.8092, device='cuda:0'),\n",
              "   tensor(0.8098, device='cuda:0'),\n",
              "   tensor(0.8049, device='cuda:0'),\n",
              "   tensor(0.8038, device='cuda:0'),\n",
              "   tensor(0.8026, device='cuda:0'),\n",
              "   tensor(0.8005, device='cuda:0'),\n",
              "   tensor(0.8006, device='cuda:0'),\n",
              "   tensor(0.7825, device='cuda:0'),\n",
              "   tensor(0.7760, device='cuda:0'),\n",
              "   tensor(0.7696, device='cuda:0'),\n",
              "   tensor(0.7684, device='cuda:0'),\n",
              "   tensor(0.7621, device='cuda:0')]],\n",
              " 21: [[tensor(0.5638, device='cuda:0'),\n",
              "   tensor(0.6533, device='cuda:0'),\n",
              "   tensor(0.7375, device='cuda:0'),\n",
              "   tensor(0.8016, device='cuda:0'),\n",
              "   tensor(0.8399, device='cuda:0'),\n",
              "   tensor(0.8204, device='cuda:0'),\n",
              "   tensor(0.8193, device='cuda:0'),\n",
              "   tensor(0.8217, device='cuda:0'),\n",
              "   tensor(0.8197, device='cuda:0'),\n",
              "   tensor(0.8204, device='cuda:0'),\n",
              "   tensor(0.8068, device='cuda:0'),\n",
              "   tensor(0.8032, device='cuda:0'),\n",
              "   tensor(0.8021, device='cuda:0'),\n",
              "   tensor(0.8015, device='cuda:0'),\n",
              "   tensor(0.8016, device='cuda:0'),\n",
              "   tensor(0.7993, device='cuda:0'),\n",
              "   tensor(0.7968, device='cuda:0'),\n",
              "   tensor(0.7939, device='cuda:0'),\n",
              "   tensor(0.7913, device='cuda:0'),\n",
              "   tensor(0.7906, device='cuda:0'),\n",
              "   tensor(0.7827, device='cuda:0'),\n",
              "   tensor(0.7793, device='cuda:0'),\n",
              "   tensor(0.7739, device='cuda:0'),\n",
              "   tensor(0.7658, device='cuda:0'),\n",
              "   tensor(0.7658, device='cuda:0')]],\n",
              " 22: []}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert(acc):\n",
        "    acc_plot_normal = {}\n",
        "    for i, x in acc.items():\n",
        "        acc_plot_normal[i] = []\n",
        "        acc_plot_normal[i].append(torch.tensor(x).flatten().numpy())\n",
        "    return acc_plot_normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B4HTmfCdXat9",
      "metadata": {
        "id": "B4HTmfCdXat9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "agnostic_rl-main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "6e2ce5fe63b3d5c9dced991702afdfd3ba71a468da6e2b3b1575ee77d6acc276"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04c4e52f9aea4f869ec678c19246e922": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43458cae45314802a58ed05e24a33e47",
              "IPY_MODEL_95887d5eeebd41518f8da1ed5172e008",
              "IPY_MODEL_350e745e1df34139b6a371bdce1857ac"
            ],
            "layout": "IPY_MODEL_533f6f11d3e8458e81cc23f96bcc2eab"
          }
        },
        "16600b22f5ef4e6b88547f18e7c96860": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fde7ada1938404fa1f3d0bd0a6c450b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229467a7f3cc455cafe2e1592992e97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29e6cbd49228457e95073797b6e5c56f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fc22a16b3164e0abd3d7c4ad728c761": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1415c77594f414a8f5de4a00fec93f3",
              "IPY_MODEL_f8b7547fc6b24d73a63800d5def3ce05",
              "IPY_MODEL_6c746cfdad5f4ee0a328e039b97f836a"
            ],
            "layout": "IPY_MODEL_16600b22f5ef4e6b88547f18e7c96860"
          }
        },
        "31f35d2658d94615bd60d2d18d8d31d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b739c15228614c678afef94a14e13b8b",
            "placeholder": "",
            "style": "IPY_MODEL_fb03a2af703f46d99672779c4254a806",
            "value": "100%"
          }
        },
        "350e745e1df34139b6a371bdce1857ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e4f095cd7cf4d3abf1c3a13db47821f",
            "placeholder": "",
            "style": "IPY_MODEL_69580ab47e8f4215951201011e469ea9",
            "value": " 4542/4542 [00:00&lt;00:00, 352617.79it/s]"
          }
        },
        "43458cae45314802a58ed05e24a33e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a894c0f09704541b8f21cf1903f379f",
            "placeholder": "",
            "style": "IPY_MODEL_95105b931a5e43c8861442c57f85b84a",
            "value": "100%"
          }
        },
        "445c868a7e914c47a02a5a655afc984a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783cc61bd86741ceb363a87e3ecedaf4",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_995c9028b5db4a399b9c34954f77b75c",
            "value": 28881
          }
        },
        "531fa795e5ce4b82876504f7e9ee1eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa9592a862a04782a24d731d90689b34",
              "IPY_MODEL_445c868a7e914c47a02a5a655afc984a",
              "IPY_MODEL_69beb033160b402688c97c489cd97c45"
            ],
            "layout": "IPY_MODEL_1fde7ada1938404fa1f3d0bd0a6c450b"
          }
        },
        "533f6f11d3e8458e81cc23f96bcc2eab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "549d26470dc64768ac56f5dbb81488f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550a323bda5444789bcc59ed903b0b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31f35d2658d94615bd60d2d18d8d31d7",
              "IPY_MODEL_d28fe18c4066491591877777b03f8bb6",
              "IPY_MODEL_a1923562a7054eb4ab776d94576dabd9"
            ],
            "layout": "IPY_MODEL_29e6cbd49228457e95073797b6e5c56f"
          }
        },
        "5c1669bd3633468d8c405e6497bb1dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ec86b25a34b4ef983266b9778d59d53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69580ab47e8f4215951201011e469ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69beb033160b402688c97c489cd97c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fec34223fa44ddab4cda7e056f877c",
            "placeholder": "",
            "style": "IPY_MODEL_bb177cea95804a2abe9c45ddb735d7f7",
            "value": " 28881/28881 [00:01&lt;00:00, 25937.32it/s]"
          }
        },
        "6b9801ac1ac74782851718dca9562479": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c746cfdad5f4ee0a328e039b97f836a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f580eecb64e94394b997fb5c36ba001a",
            "placeholder": "",
            "style": "IPY_MODEL_e64cdf0ba4a44369b618e113ad182f78",
            "value": " 1648877/1648877 [00:00&lt;00:00, 20833947.57it/s]"
          }
        },
        "783cc61bd86741ceb363a87e3ecedaf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88342cff85f24d0a906c3e780ee5f623": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a894c0f09704541b8f21cf1903f379f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4f095cd7cf4d3abf1c3a13db47821f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95105b931a5e43c8861442c57f85b84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "958480c361034004a3242b3ab5ffd7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95887d5eeebd41518f8da1ed5172e008": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_958480c361034004a3242b3ab5ffd7e1",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_229467a7f3cc455cafe2e1592992e97e",
            "value": 4542
          }
        },
        "96fec34223fa44ddab4cda7e056f877c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995c9028b5db4a399b9c34954f77b75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bb60b035b3f4a018a1fecc0f2836808": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1923562a7054eb4ab776d94576dabd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b9801ac1ac74782851718dca9562479",
            "placeholder": "",
            "style": "IPY_MODEL_df0414933e6442c0893cf29d72ce4896",
            "value": " 9912422/9912422 [00:00&lt;00:00, 67094001.81it/s]"
          }
        },
        "aa9592a862a04782a24d731d90689b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_549d26470dc64768ac56f5dbb81488f4",
            "placeholder": "",
            "style": "IPY_MODEL_5c1669bd3633468d8c405e6497bb1dff",
            "value": "100%"
          }
        },
        "b739c15228614c678afef94a14e13b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb177cea95804a2abe9c45ddb735d7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce7e6b203e5947c3a89367946c016095": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1415c77594f414a8f5de4a00fec93f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec86b25a34b4ef983266b9778d59d53",
            "placeholder": "",
            "style": "IPY_MODEL_f017d13ab03141fabc8fb001a42efc64",
            "value": "100%"
          }
        },
        "d28fe18c4066491591877777b03f8bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bb60b035b3f4a018a1fecc0f2836808",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce7e6b203e5947c3a89367946c016095",
            "value": 9912422
          }
        },
        "df0414933e6442c0893cf29d72ce4896": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e64cdf0ba4a44369b618e113ad182f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea1caf853dd0443a9ca98d613ea1efd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f017d13ab03141fabc8fb001a42efc64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f580eecb64e94394b997fb5c36ba001a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b7547fc6b24d73a63800d5def3ce05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88342cff85f24d0a906c3e780ee5f623",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea1caf853dd0443a9ca98d613ea1efd5",
            "value": 1648877
          }
        },
        "fb03a2af703f46d99672779c4254a806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
