# Configuration file for training
batch_size_fisher: 32
eval_steps: 100_000
ewc_lambda: 250
ewc_start_timestep_after: 500_000
num_env_steps_compress: 1_000_000
num_env_steps_progress: 2_500_000
num_processes: 4
lr: 0.0007
use_linear_lr_decay: False
visits: 3
device: "mps"
seed: 39
log_wandb: True
num_steps: 20
entropy_coef: 0.01
eps: 0.00001
max_grad_norm: 1
alpha: 0.95