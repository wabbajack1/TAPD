# Configuration file for training
batch_size_fisher: 32
eval_steps: 100_000
ewc_lambda: 250
ewc_start_timestep_after: 100_000
num_env_steps_compress: 300_000
num_env_steps_progress: 2_500_000
num_processes: 8
seed: 42
lr: 0.0007
use_linear_lr_decay: False
visits: 3
mps: True
log_wandb: False
num_steps: 20
entropy_coef: 0.01
max_grad_norm: 0.5
eps: 0.00001